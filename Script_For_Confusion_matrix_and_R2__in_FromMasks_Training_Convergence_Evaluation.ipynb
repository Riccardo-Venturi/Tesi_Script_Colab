{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1nNVErHvgvEymT1k158HCTE9OvhcxXU-H",
      "authorship_tag": "ABX9TyM+R/pVkOI/lxbRAdf0C56G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riccardo-Venturi/Tesi_Tesi-MLOPs-pipeline-industriale-Light/blob/main/Script_For_Confusion_matrix_and_R2__in_FromMasks_Training_Convergence_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'analisi della coerenza del Ground Truth ha evidenziato un errore sistematico di labeling in 49 campioni su 107. Grazie a un algoritmo di verifica basato sulla topologia del foro (analisi del centroide), √® stato possibile correggere automaticamente il dataset di validazione. Questo passaggio non solo ha permesso una valutazione corretta del modello UNet++, ma dimostra la robustezza della pipeline ROIA anche a fronte di dati di supervisione umani rumorosi.\"\n",
        "\n",
        "Si √® proceduto alla pulizia e successivamente al calcolo delle metriche di interesse Recall, confusione, e R2"
      ],
      "metadata": {
        "id": "oO4zECWEpw3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q seaborn matplotlib scikit-learn\n"
      ],
      "metadata": {
        "id": "zCUhctUpDTSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHECK CHE CAZZZO STIAMO FACENDO\n"
      ],
      "metadata": {
        "id": "iC_csD_RhcIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# --- SET PERCORSI ---\n",
        "GT_DIR = Path(\"/content/drive/MyDrive/GOLDEN_GT_FIXED/masks\")\n",
        "PRED_DIR = Path(\"/content/drive/MyDrive/UNETPPMaschereInferenza\")\n",
        "RADIO_DIR = Path(\"/content/drive/MyDrive/GOLDEN_DATASET_CANONICO_RADIOGRAFICO/Full_Images\")\n",
        "\n",
        "# --- PARAMETRI ---\n",
        "n_campioni = 5  # Quanti fori vuoi vedere?\n",
        "\n",
        "def visual_audit():\n",
        "    gt_files = {f.stem.lower(): f for f in GT_DIR.glob(\"*.png\")}\n",
        "    pred_files = {f.stem.lower(): f for f in PRED_DIR.glob(\"*.png\")}\n",
        "\n",
        "    # Cerchiamo l'intersezione reale\n",
        "    stems = sorted(list(set(gt_files.keys()) & set(pred_files.keys())))\n",
        "\n",
        "    if not stems:\n",
        "        print(\"‚ùå Nessun match tra GT e PRED. Controlla i nomi dei file!\")\n",
        "        return\n",
        "\n",
        "    print(f\"üßê Analisi visiva su {n_campioni} campioni casuali...\")\n",
        "\n",
        "    fig, axes = plt.subplots(n_campioni, 3, figsize=(15, 5*n_campioni))\n",
        "\n",
        "    for i, stem in enumerate(stems[:n_campioni]):\n",
        "        # Carica maschere\n",
        "        m_gt = cv2.imread(str(gt_files[stem]), 0)\n",
        "        m_pred = cv2.imread(str(pred_files[stem]), 0)\n",
        "\n",
        "        # Cerca la radio (nome immagine potrebbe essere leggermente diverso)\n",
        "        radio_path = list(RADIO_DIR.glob(f\"*{stem}*\"))\n",
        "        if radio_path:\n",
        "            img = cv2.imread(str(radio_path[0]), 0)\n",
        "            img = cv2.resize(img, (512, 512))\n",
        "        else:\n",
        "            img = np.zeros((512,512)) # Se manca la radio facciamo sfondo nero\n",
        "\n",
        "        # Overlay Danno (Giallo nella GT e nella PRED)\n",
        "        axes[i, 0].imshow(img, cmap='gray')\n",
        "        axes[i, 0].set_title(f\"ID: {stem}\\nImmagine Originale\")\n",
        "\n",
        "        # Visualizzazione GT con etichette chiare\n",
        "        axes[i, 1].imshow(m_gt, cmap='viridis', vmin=0, vmax=2)\n",
        "        axes[i, 1].set_title(f\"GT (Manuale)\\nDanno Area: {np.sum(m_gt==2)} px\")\n",
        "\n",
        "        # Visualizzazione AI\n",
        "        axes[i, 2].imshow(m_pred, cmap='viridis', vmin=0, vmax=2)\n",
        "        axes[i, 2].set_title(f\"PRED (UNet++)\\nDanno Area: {np.sum(m_pred==2)} px\")\n",
        "\n",
        "        for ax in axes[i]: ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visual_audit()"
      ],
      "metadata": {
        "id": "ZvPQvVWIhg-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINE CHECK CHE CAZZO"
      ],
      "metadata": {
        "id": "Ae2LhAgKhfVZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgI31vlHz177",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# --- INSTALLAZIONI NECESSARIE ---\n",
        "# scikit-learn, pandas, matplotlib e opencv sono di solito gi√† su Colab\n",
        "# installiamo seaborn per grafici pi√π belli se serve aggiornarlo\n",
        "#!pip install -q seaborn matplotlib scikit-learn\n",
        "#@title cella che mi dice matrice confusione e R2 estraendo feautures dalle maschere\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, r2_score\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm # Usa la versione notebook per barre di caricamento pi√π carine\n",
        "from google.colab import drive\n",
        "\n",
        "## --- MONTAGGIO DRIVE (Se non lo hai gi√† fatto) ---\n",
        "#if not os.path.exists('/content/drive'):\n",
        "#    drive.mount('/content/drive')\n",
        "\n",
        "# ==============================================================================\n",
        "# CONFIGURAZIONE (I TUOI PERCORSI)\n",
        "# ==============================================================================\n",
        "\n",
        "# Cartella con le 107 maschere \"Golden\" (Ground Truth manuali/corrette)\n",
        "# Assicurati che i file dentro siano .png e abbiano valori 0, 1, 2\n",
        "GT_DIR = Path(\"/content/drive/MyDrive/GOLDEN_GT_FIXED/masks\")\n",
        "\n",
        "# Cartella con tutte le 600 maschere predette dalla UNet\n",
        "PRED_DIR = Path(\"/content/drive/MyDrive/UNETPPMaschereInferenza\")\n",
        "\n",
        "# Dove salvare i grafici risultanti\n",
        "OUTPUT_PLOTS_DIR = Path(\"/content/drive/MyDrive/Tesi_Plots\")\n",
        "OUTPUT_PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Fattore di scala (da Pixel a mm)\n",
        "# Hai detto 512x512 pixel e foro da 6mm (che corrisponde a circa ~14mm di larghezza foto?)\n",
        "# 35.8 px/mm corrisponde a un'immagine larga circa 14.3mm. √à un valore plausibile per un crop 512.\n",
        "SCALA_PX_MM = 35.8\n",
        "\n",
        "# ==============================================================================\n",
        "# LOGICA DI ELABORAZIONE\n",
        "# ==============================================================================\n",
        "\n",
        "def analizza_validazione():\n",
        "    print(\"üöÄ Inizio pipeline di validazione 'Tesi Legend'...\")\n",
        "\n",
        "    # 1. Recupero lista file e calcolo intersezione (match automatico)\n",
        "    gt_files_map = {f.stem: f for f in GT_DIR.glob(\"*.png\")}\n",
        "    pred_files_map = {f.stem: f for f in PRED_DIR.glob(\"*.png\")}\n",
        "\n",
        "    # Intersezione basata sul nome del file (senza estensione)\n",
        "    common_stems = sorted(list(set(gt_files_map.keys()) & set(pred_files_map.keys())))\n",
        "\n",
        "    num_match = len(common_stems)\n",
        "    print(f\"üìÇ File Ground Truth trovati: {len(gt_files_map)}\")\n",
        "    print(f\"üìÇ File Predizioni trovati: {len(pred_files_map)}\")\n",
        "    print(f\"‚úÖ Coppie valide (Intersezione): {num_match}\")\n",
        "\n",
        "    if num_match == 0:\n",
        "        print(\"‚ùå ERRORE CRITICO: Nessuna corrispondenza trovata!\")\n",
        "        print(\"   Controlla che i nomi dei file nelle due cartelle siano identici.\")\n",
        "        print(f\"   Esempio nome GT: {list(gt_files_map.keys())[0] if gt_files_map else 'Nessuno'}\")\n",
        "        print(f\"   Esempio nome Pred: {list(pred_files_map.keys())[0] if pred_files_map else 'Nessuno'}\")\n",
        "        return\n",
        "\n",
        "    # Liste per i dati\n",
        "    # Usiamo liste standard di python per velocit√† nell'append, poi convertiamo in numpy\n",
        "    # NOTA: Per la matrice di confusione su milioni di pixel, le liste potrebbero esplodere la RAM.\n",
        "    # Ottimizzazione: Calcoliamo la matrice di confusione per ogni immagine e le sommiamo.\n",
        "\n",
        "    total_conf_matrix = np.zeros((3, 3), dtype=np.int64) # Matrice accumulatore 3x3\n",
        "\n",
        "    areas_gt = []\n",
        "    areas_pred = []\n",
        "\n",
        "    print(\"\\nüîç Elaborazione immagini...\")\n",
        "\n",
        "    for stem in tqdm(common_stems):\n",
        "        # Carica i path\n",
        "        path_gt = gt_files_map[stem]\n",
        "        path_pred = pred_files_map[stem]\n",
        "\n",
        "        # Lettura Maschere (Flag 0 per scala di grigi pura)\n",
        "        mask_gt = cv2.imread(str(path_gt), 0)\n",
        "        mask_pred = cv2.imread(str(path_pred), 0)\n",
        "\n",
        "        # Check integrit√†\n",
        "        if mask_gt is None or mask_pred is None:\n",
        "            print(f\"‚ö†Ô∏è Errore lettura file per {stem}, salto.\")\n",
        "            continue\n",
        "\n",
        "        if mask_gt.shape != mask_pred.shape:\n",
        "            # Resize predizione se dimensione diversa (non dovrebbe succedere se setup √® corretto)\n",
        "            mask_pred = cv2.resize(mask_pred, (mask_gt.shape[1], mask_gt.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # ---------------------------\n",
        "        # A. AGGIORNAMENTO MATRICE DI CONFUSIONE\n",
        "        # ---------------------------\n",
        "        # Flattening rapido\n",
        "        gt_flat = mask_gt.ravel()\n",
        "        pred_flat = mask_pred.ravel()\n",
        "\n",
        "        # Calcolo confusion matrix del singolo batch/immagine e somma al totale\n",
        "        # labels=[0,1,2] assicura che la matrice sia sempre 3x3 anche se mancano classi in un'immagine\n",
        "        current_cm = confusion_matrix(gt_flat, pred_flat, labels=[0, 1, 2])\n",
        "        total_conf_matrix += current_cm\n",
        "\n",
        "        # ---------------------------\n",
        "        # B. CALCOLO METROLOGIA (AREE)\n",
        "        # ---------------------------\n",
        "        # Area danno (classe 2) in mm^2\n",
        "        px_danno_gt = np.sum(mask_gt == 2)\n",
        "        px_danno_pred = np.sum(mask_pred == 2)\n",
        "\n",
        "        area_mm_gt = px_danno_gt / (SCALA_PX_MM**2)\n",
        "        area_mm_pred = px_danno_pred / (SCALA_PX_MM**2)\n",
        "\n",
        "        areas_gt.append(area_mm_gt)\n",
        "        areas_pred.append(area_mm_pred)\n",
        "\n",
        "    # ==============================================================================\n",
        "    # GENERAZIONE OUTPUT E GRAFICI\n",
        "    # ==============================================================================\n",
        "\n",
        "    # 1. Plot Matrice di Confusione Normalizzata\n",
        "    print(\"üé® Generazione grafici...\")\n",
        "\n",
        "    # Normalizza per riga (somma su riga = 1) -> ci da Recall/Sensibilit√† per classe\n",
        "    cm_norm = total_conf_matrix.astype('float') / total_conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    labels = ['Sfondo', 'Foro', 'Danno']\n",
        "    sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues', cbar=True,\n",
        "                xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(f'Analisi di Consistenza (Matrice Normalizzata)\\nsu {num_match} campioni Golden Dataset', fontsize=14)\n",
        "    plt.ylabel('Ground Truth (Reale)')\n",
        "    plt.xlabel('Predizione UNet++')\n",
        "    plt.tight_layout()\n",
        "    plot_path_cm = OUTPUT_PLOTS_DIR / '01_Matrice_Confusione.png'\n",
        "    plt.savefig(plot_path_cm, dpi=300)\n",
        "    plt.show()\n",
        "    print(f\"üíæ Grafico Matrice salvato in: {plot_path_cm}\")\n",
        "\n",
        "    # 2. Plot Regressione R^2 (Aree Danno)\n",
        "    r2 = r2_score(areas_gt, areas_pred)\n",
        "\n",
        "    plt.figure(figsize=(9, 9))\n",
        "\n",
        "    # Scatter plot dei punti\n",
        "    plt.scatter(areas_gt, areas_pred, alpha=0.6, s=40, color='#2c7bb6', edgecolors='k', linewidth=0.5, label='Campioni Validazione')\n",
        "\n",
        "    # Linea ideale Y = X\n",
        "    limit_max = max(max(areas_gt), max(areas_pred)) * 1.1\n",
        "    plt.plot([0, limit_max], [0, limit_max], color='#d7191c', linestyle='--', linewidth=2, label='Fitting Ideale')\n",
        "\n",
        "    plt.xlim(0, limit_max)\n",
        "    plt.ylim(0, limit_max)\n",
        "    plt.title(f'Capacit√† di Fitting Area Danno\\n$R^2$ Score = {r2:.4f}', fontsize=14)\n",
        "    plt.xlabel('Area Misurata Manualmente ', fontsize=12)\n",
        "    plt.ylabel('Area Predetta dal Modello ', fontsize=12)\n",
        "    plt.legend(loc='upper left', frameon=True)\n",
        "    plt.grid(True, linestyle=':', alpha=0.6)\n",
        "\n",
        "    plot_path_r2 = OUTPUT_PLOTS_DIR / '02_Regressione_Aree.png'\n",
        "    plt.savefig(plot_path_r2, dpi=300)\n",
        "    plt.show()\n",
        "    print(f\"üíæ Grafico R^2 salvato in: {plot_path_r2}\")\n",
        "\n",
        "    print(\"\\n‚úÖ DONE. Sei pronto per la laurea.\")\n",
        "\n",
        "# Esegui tutto\n",
        "analizza_validazione()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cella per esportare i dati di area in CSV\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm # Usa la versione notebook per barre di caricamento pi√π carine\n",
        "import math\n",
        "\n",
        "# --- Riusa le configurazioni definite in precedenza ---\n",
        "# GT_DIR, PRED_DIR, SCALA_PX_MM dovrebbero essere gi√† definiti dalla cella dgI31vlHz177\n",
        "# Se non lo fossero, uncommenta e definiscile qui:\n",
        "# GT_DIR = Path(\"/content/drive/MyDrive/GOLDEN_GT_FIXED/masks\")\n",
        "# PRED_DIR = Path(\"/content/drive/MyDrive/UNETPPMaschereInferenza\")\n",
        "# SCALA_PX_MM = 35.8\n",
        "\n",
        "# Dove salvare i grafici e ora il CSV\n",
        "OUTPUT_PLOTS_DIR = Path(\"/content/drive/MyDrive/Tesi_Plots\")\n",
        "OUTPUT_PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def calculate_circularity(mask, class_val=2):\n",
        "    \"\"\"Calcola la circolarit√† per una specifica classe all'interno di una maschera.\"\"\"\n",
        "    # Assicurati che la maschera sia in formato CV_8UC1 per findContours\n",
        "    binary_mask = (mask == class_val).astype(np.uint8) * 255\n",
        "\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return 0.0 # Nessun danno o contorno rilevato\n",
        "\n",
        "    # Trova il contorno pi√π grande, assumendo che sia il danno principale\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    area = cv2.contourArea(largest_contour)\n",
        "    perimeter = cv2.arcLength(largest_contour, True)\n",
        "\n",
        "    if perimeter == 0:\n",
        "        return 0.0 # Evita la divisione per zero\n",
        "\n",
        "    # Formula della circolarit√† (Shape factor)\n",
        "    circularity = (4 * math.pi * area) / (perimeter * perimeter)\n",
        "    return circularity\n",
        "\n",
        "def export_area_data_to_csv():\n",
        "    print(\"üìä Preparazione dati per l'esportazione CSV con metriche aggiuntive...\")\n",
        "\n",
        "    gt_files_map = {f.stem: f for f in GT_DIR.glob(\"*.png\")}\n",
        "    pred_files_map = {f.stem: f for f in PRED_DIR.glob(\"*.png\")}\n",
        "    common_stems = sorted(list(set(gt_files_map.keys()) & set(pred_files_map.keys())))\n",
        "\n",
        "    if not common_stems:\n",
        "        print(\"‚ùå Nessuna corrispondenza trovata per l'esportazione CSV.\")\n",
        "        return\n",
        "\n",
        "    file_names = []\n",
        "    px_areas_gt = []\n",
        "    px_areas_pred = []\n",
        "    areas_gt_mm2 = []\n",
        "    areas_pred_mm2 = []\n",
        "    circularity_gt = []\n",
        "    circularity_pred = []\n",
        "\n",
        "    print(f\"üîç Rielaborazione {len(common_stems)} immagini per dati di area e circolarit√†...\")\n",
        "\n",
        "    for stem in tqdm(common_stems):\n",
        "        path_gt = gt_files_map[stem]\n",
        "        path_pred = pred_files_map[stem]\n",
        "\n",
        "        mask_gt = cv2.imread(str(path_gt), 0)\n",
        "        mask_pred = cv2.imread(str(path_pred), 0)\n",
        "\n",
        "        if mask_gt is None or mask_pred is None:\n",
        "            print(f\"‚ö†Ô∏è Errore lettura file per {stem}, salto.\")\n",
        "            continue\n",
        "\n",
        "        if mask_gt.shape != mask_pred.shape:\n",
        "            mask_pred = cv2.resize(mask_pred, (mask_gt.shape[1], mask_gt.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # --- Aree in Pixel ---\n",
        "        px_danno_gt = np.sum(mask_gt == 2)\n",
        "        px_danno_pred = np.sum(mask_pred == 2)\n",
        "        px_areas_gt.append(px_danno_gt)\n",
        "        px_areas_pred.append(px_danno_pred)\n",
        "\n",
        "        # --- Aree in mm^2 ---\n",
        "        area_mm_gt = px_danno_gt / (SCALA_PX_MM**2)\n",
        "        area_mm_pred = px_danno_pred / (SCALA_PX_MM**2)\n",
        "        areas_gt_mm2.append(area_mm_gt)\n",
        "        areas_pred_mm2.append(area_mm_pred)\n",
        "\n",
        "        # --- Circolarit√† ---\n",
        "        circ_gt = calculate_circularity(mask_gt, class_val=2)\n",
        "        circ_pred = calculate_circularity(mask_pred, class_val=2)\n",
        "        circularity_gt.append(circ_gt)\n",
        "        circularity_pred.append(circ_pred)\n",
        "\n",
        "        file_names.append(stem)\n",
        "\n",
        "    # Creazione DataFrame\n",
        "    df_export = pd.DataFrame({\n",
        "        'File_ID': file_names,\n",
        "        'Pixel_Area_GT': px_areas_gt,\n",
        "        'Pixel_Area_Predetta': px_areas_pred,\n",
        "        'Area_GT_mm2': areas_gt_mm2,\n",
        "        'Area_Predetta_mm2': areas_pred_mm2,\n",
        "        'Circularity_GT': circularity_gt,\n",
        "        'Circularity_Predetta': circularity_pred\n",
        "    })\n",
        "\n",
        "    # --- Calcolo della deviazione (errore) ---\n",
        "    df_export['Error_Area_mm2'] = df_export['Area_Predetta_mm2'] - df_export['Area_GT_mm2']\n",
        "    df_export['Error_Circularity'] = df_export['Circularity_Predetta'] - df_export['Circularity_GT']\n",
        "\n",
        "    csv_path = OUTPUT_PLOTS_DIR / 'aree_danno_e_metrche_per_foro.csv'\n",
        "    df_export.to_csv(csv_path, index=False)\n",
        "\n",
        "    print(f\"‚úÖ Dati di area e metriche esportati con successo in: {csv_path}\")\n",
        "    print(\"Preview dei dati aggiornati:\")\n",
        "    print(df_export.head())\n",
        "\n",
        "# Esegui la funzione di esportazione\n",
        "export_area_data_to_csv()\n"
      ],
      "metadata": {
        "id": "KBC5-k6EC-V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "doklS3FrDsSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "#ricreiamo dai file corretti le metriche di interesse\n",
        "# --- CONFIGURAZIONE ---\n",
        "GT_DIR = Path(\"/content/drive/MyDrive/GOLDEN_GT_FIXED/masks\")\n",
        "PRED_DIR = Path(\"/content/drive/MyDrive/UNETPPMaschereInferenza\")\n",
        "\n",
        "def detective_completo():\n",
        "    gt_files = sorted(list(GT_DIR.glob(\"*.png\")))\n",
        "    report = []\n",
        "\n",
        "    print(f\"üïµÔ∏è Analisi di {len(gt_files)} file in corso...\")\n",
        "\n",
        "    for f in tqdm(gt_files):\n",
        "        pred_f = PRED_DIR / f.name\n",
        "        if not pred_f.exists():\n",
        "            continue\n",
        "\n",
        "        img_gt = cv2.imread(str(f), 0)\n",
        "        img_pred = cv2.imread(str(pred_f), 0)\n",
        "\n",
        "        # 1. Controllo Valori\n",
        "        vals_gt = np.unique(img_gt)\n",
        "        vals_pred = np.unique(img_pred)\n",
        "\n",
        "        # 2. Calcolo Recall specifica per il DANNO (Classe 2) su questo file\n",
        "        # Recall = (Pixel Danno beccati dall'AI) / (Totale Pixel Danno Reali)\n",
        "        pixel_danno_reali = np.sum(img_gt == 2)\n",
        "        pixel_danno_predetti_correttamente = np.sum((img_gt == 2) & (img_pred == 2))\n",
        "\n",
        "        recall_danno = (pixel_danno_predetti_correttamente / pixel_danno_reali) if pixel_danno_reali > 0 else 1.0\n",
        "\n",
        "        # 3. Controllo Inversione (Il Danno reale √® finito nel Foro dell'AI?)\n",
        "        danno_finito_nel_foro = np.sum((img_gt == 2) & (img_pred == 1))\n",
        "        percentuale_inversione = (danno_finito_nel_foro / pixel_danno_reali) if pixel_danno_reali > 0 else 0\n",
        "\n",
        "        report.append({\n",
        "            'File': f.name,\n",
        "            'GT_Vals': vals_gt,\n",
        "            'PRED_Vals': vals_pred,\n",
        "            'Recall_Danno': round(recall_danno * 100, 2),\n",
        "            'Confusione_Danno_Foro': round(percentuale_inversione * 100, 2)\n",
        "        })\n",
        "\n",
        "    df_report = pd.DataFrame(report)\n",
        "\n",
        "    # Ordiniamo per i peggiori risultati di Recall\n",
        "    peggiori = df_report.sort_values(by='Recall_Danno').head(10)\n",
        "\n",
        "    print(\"\\n--- üìä REPORT DIAGNOSTICO ---\")\n",
        "    print(f\"Media Recall Danno: {df_report['Recall_Danno'].mean():.2f}%\")\n",
        "    print(f\"Media Confusione Danno->Foro: {df_report['Confusione_Danno_Foro'].mean():.2f}%\")\n",
        "\n",
        "    print(\"\\n--- üö® I 10 FILE PEGGIORI (Possibili inversioni o errori gravi) ---\")\n",
        "    print(peggiori[['File', 'Recall_Danno', 'Confusione_Danno_Foro']])\n",
        "\n",
        "    return df_report\n",
        "\n",
        "df_risultati = detective_completo()"
      ],
      "metadata": {
        "id": "gFcL7H0MYtvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURAZIONE ---\n",
        "# Cartella originale (quella con le inversioni)\n",
        "GT_DIR_ORIGINAL = Path(\"/content/drive/MyDrive/GOLDEN_DATASET_CANONICO/Full_Images/masks\")\n",
        "# Nuova cartella su Drive per i file corretti\n",
        "GT_DIR_FIXED = Path(\"/content/drive/MyDrive/GOLDEN_GT_FIXED/masks\")\n",
        "GT_DIR_FIXED.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def fix_ground_truth():\n",
        "    files = sorted(list(GT_DIR_ORIGINAL.glob(\"*.png\")))\n",
        "    swapped_count = 0\n",
        "    copied_count = 0\n",
        "\n",
        "    print(f\"üõ†Ô∏è Inizio correzione su {len(files)} file...\")\n",
        "\n",
        "    for f in tqdm(files):\n",
        "        img = cv2.imread(str(f), 0)\n",
        "        if img is None: continue\n",
        "\n",
        "        h, w = img.shape\n",
        "        center_val = img[h//2, w//2] # Valore al centro (Foro)\n",
        "\n",
        "        final_mask = img.copy()\n",
        "\n",
        "        if center_val == 2:\n",
        "            # INVERSIONE RILEVATA: Scambiamo 1 e 2\n",
        "            # Usiamo un valore temporaneo (es. 99) per non sovrascrivere\n",
        "            final_mask[img == 1] = 2\n",
        "            final_mask[img == 2] = 1\n",
        "            swapped_count += 1\n",
        "        else:\n",
        "            # File gi√† corretto (centro = 1)\n",
        "            copied_count += 1\n",
        "\n",
        "        # Salva nella nuova cartella\n",
        "        cv2.imwrite(str(GT_DIR_FIXED / f.name), final_mask)\n",
        "\n",
        "    print(f\"\\n‚úÖ OPERAZIONE COMPLETATA\")\n",
        "    print(f\"üîÑ File invertiti e corretti: {swapped_count}\")\n",
        "    print(f\"üìÅ File mantenuti originali: {copied_count}\")\n",
        "    print(f\"üìç I file corretti sono in: {GT_DIR_FIXED}\")\n",
        "\n",
        "fix_ground_truth()"
      ],
      "metadata": {
        "id": "3AYkGzOxoyR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cella controllo visualizzazione immagini\n",
        "#import cv2\n",
        "#import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualizza_confronto(index=0):\n",
        "    gt_files = sorted(list(GT_DIR.glob(\"*.png\")))\n",
        "    f = gt_files[index]\n",
        "    pred_f = PRED_DIR / f.name\n",
        "\n",
        "    gt = cv2.imread(str(f), 0)\n",
        "    pred = cv2.imread(str(pred_f), 0)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Mappa colori: 0=Nero, 1=Rosso (Foro), 2=Verde (Danno)\n",
        "    ax[0].imshow(gt, cmap='nipy_spectral', vmin=0, vmax=2)\n",
        "    ax[0].set_title(f\"GROUND TRUTH (Manuale)\\n{f.name}\")\n",
        "\n",
        "    ax[1].imshow(pred, cmap='nipy_spectral', vmin=0, vmax=2)\n",
        "    ax[1].set_title(f\"PREDIZIONE AI\\nValori unici: {np.unique(pred)}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "visualizza_confronto(72) # Cambia indice per vedere altri fori"
      ],
      "metadata": {
        "id": "R_snGzwLZriX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rGCm0ODvGwPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import resample\n",
        "from scipy import stats\n",
        "\n",
        "# ==============================================================================\n",
        "# FASE 4: BOOTSTRAP STOCASTICO DELLE PRESTAZIONI (RECALL DANNO)\n",
        "# ==============================================================================\n",
        "\n",
        "def esegui_bootstrap_analysis(df_report, n_iterations=10000):\n",
        "    \"\"\"\n",
        "    Analisi stocastica basata sui dati estratti dal detective_completo.\n",
        "    Calcola l'intervallo di confidenza al 95% della Recall media.\n",
        "    \"\"\"\n",
        "    # Estraiamo il vettore delle recall individuali (i tuoi 107 risultati)\n",
        "    # Assumiamo che df_report abbia la colonna 'Recall_Danno'\n",
        "    misure = df_report['Recall_Danno'].values / 100.0 # Torniamo in scala 0-1\n",
        "\n",
        "    boot_means = []\n",
        "    print(f\"üé≤ Avvio simulazione stocastica (Bootstrap {n_iterations} iterazioni)...\")\n",
        "\n",
        "    for i in range(n_iterations):\n",
        "        # Campionamento con reinserimento (Stochastic Resampling)\n",
        "        # Alcune immagini vengono contate doppie, altre saltate: simula nuovi dataset\n",
        "        campione = resample(misure, replace=True, n_samples=len(misure))\n",
        "        boot_means.append(np.mean(campione))\n",
        "\n",
        "    boot_means = np.array(boot_means)\n",
        "\n",
        "    # Calcolo Intervallo di Confidenza 95% (Percentile Method)\n",
        "    alpha = 0.95\n",
        "    p_lower = ((1.0 - alpha) / 2.0) * 100\n",
        "    p_upper = (alpha + ((1.0 - alpha) / 2.0)) * 100\n",
        "    ci_lower = np.percentile(boot_means, p_lower)\n",
        "    ci_upper = np.percentile(boot_means, p_upper)\n",
        "\n",
        "    # --- VISUALIZZAZIONE SCIENTIFICA ---\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # KDE plot: La \"forma\" della verit√† del tuo modello\n",
        "    sns.histplot(boot_means, kde=True, color='royalblue', bins=50, stat=\"density\", alpha=0.3)\n",
        "\n",
        "    # Linee di controllo\n",
        "    plt.axvline(np.mean(misure), color='red', linestyle='--', label=f'Media Osservata: {np.mean(misure):.3f}')\n",
        "    plt.axvline(ci_lower, color='darkorange', linestyle=':', label=f'LCL (95%): {ci_lower:.3f}')\n",
        "    plt.axvline(ci_upper, color='darkorange', linestyle=':', label=f'UCL (95%): {ci_upper:.3f}')\n",
        "\n",
        "    # Coloriamo l'area di confidenza (High Value Content per tesi)\n",
        "    x_fill = np.linspace(ci_lower, ci_upper, 100)\n",
        "    plt.fill_between(x_fill, 0, stats.gaussian_kde(boot_means)(x_fill), color='orange', alpha=0.2)\n",
        "\n",
        "    plt.title(f'Distribuzione Campionaria della Recall (Danno)\\nBootstrap Stocastico (B={n_iterations})', fontsize=14)\n",
        "    plt.xlabel('Valore Recall (Sensibilit√†)', fontsize=12)\n",
        "    plt.ylabel('Densit√† di Probabilit√†', fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.2)\n",
        "\n",
        "    plt.savefig(OUTPUT_PLOTS_DIR / 'bootstrap_recall_distribution.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n--- üìà RISULTATI BOOTSTRAP ---\")\n",
        "    print(f\"Recall Media: {np.mean(misure):.4f}\")\n",
        "    print(f\"Intervallo di Confidenza 95% (Stocastico): [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
        "    print(f\"Margine d'errore della misura: ¬±{((ci_upper - ci_lower)/2):.4f}\")\n",
        "\n",
        "    return boot_means\n",
        "\n",
        "# ESECUZIONE (Usa l'output della cella precedente 'df_risultati')\n",
        "bootstrap_stats = esegui_bootstrap_analysis(df_risultati)"
      ],
      "metadata": {
        "id": "o6rwednuGulg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}