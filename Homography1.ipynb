{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1afUjWf455rgKBeTFWYmIaPRFMSjuZisF",
      "authorship_tag": "ABX9TyNH72KxbSeNwIW1ouGch0Dq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riccardo-Venturi/Tesi_Script_Colab/blob/main/Homography1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obiettivo #3: Gestire le Uscite (la Sfida Finale)\n",
        "\n",
        "Questo è un problema complesso, come hai detto tu.\n",
        "> le uscite sono quelle più informative e critiche ma sono prese in verso speculare\n",
        "\n",
        "**La strategia vincente è trattarle come un problema separato ma quasi identico.**\n",
        "\n",
        "1.  **Non Mischiare:** Non mettere gli ingressi e le uscite nello stesso CSV master per l'omografia. Le distorsioni sono diverse.\n",
        "2.  **Crea una Pipeline per le Uscite:** Duplica il tuo notebook di omografia. Chiamalo `Homography_Uscite.ipynb`.\n",
        "3.  **Applica una Trasformazione Iniziale:** La primissima cosa da fare dopo aver caricato l'immagine `uscita.jpg` è **specchiarla orizzontalmente**.\n",
        "    ```python\n",
        "    # All'inizio, dopo aver caricato l'immagine\n",
        "    img_uscita = cv2.imread(PERCORSO_USCITA)\n",
        "    img_uscita_specchiata = cv2.flip(img_uscita, 1) # 1 = flip orizzontale\n",
        "    # Ora usa `img_uscita_specchiata` per tutto il resto del processo\n",
        "    ```\n",
        "4.  **Esegui la Pipeline di Omografia:** Usa la pipeline che abbiamo appena perfezionato (con RANSAC adattivo e filtro dinamico) sulle immagini delle uscite specchiate. Questo dovrebbe allinearle correttamente con le radiografie (che sono \"viste da dietro\").\n",
        "5.  **Crea un Dataset Separato:** Alla fine, avrai uno `unet_dataset_uscite.zip`.\n",
        "6.  **Unisci i Dataset:** Ora hai due dataset di alta qualità: `ingressi.zip` e `uscite.zip`. Puoi unirli in un'unica grande cartella per il training. Il modello ora vedrà entrambi i tipi di danno.\n",
        "\n",
        "**Perché trattarle come nuovi fori:** Unet non sa cosa sia \"l'ingresso\" o \"l'uscita\". Vede solo pixel. Dargli più esempi di danni, anche se da prospettive diverse (che noi abbiamo \"corretto\" con il flip), arricchisce la sua conoscenza e lo rende più robusto.\n",
        "\n",
        "### Piano d'Azione per Oggi\n",
        "\n",
        "1.  **Modifica la Cella 4** del tuo script di omografia per includere il **RANSAC Sweep**.\n",
        "2.  **Modifica la Cella 5** per usare **soglie dinamiche** basate sui quantili (es. `quantile(0.8)`).\n",
        "3.  **Esegui la pipeline** e controlla quanti fori \"buoni\" ottieni. L'obiettivo è arrivare ad almeno 40-45 su 64.\n",
        "4.  Una volta che sei soddisfatto, **genera lo zip finale** e usalo per addestrare di nuovo il tuo modello U-Net. I risultati dovrebbero migliorare drasticamente grazie a un dataset più grande e comunque di alta qualità.\n",
        "5.  Metti da parte il problema delle uscite per ora. Risolviamo prima l'allineamento degli ingressi. Un passo alla volta.\n"
      ],
      "metadata": {
        "id": "TBQSeJPlN-Ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#· Sintesi operativa\n",
        "\n",
        "Il notebook carica le scan ottiche e le corrispondenti scan NDT (radiografiche) di una stessa maschera, legge un master CSV dove per ciascun foro ci sono le coordinate ottiche ↔ NDT, stima la omografia migliore tra i due domini (scandagliando diversi threshold RANSAC), allinea la NDT sull’ottica via warpPerspective, estrae patch per ogni foro, costruisce le maschere ground‑truth (foro + danno) e impacchetta tutto in PNG/ZIP pronti per l’addestramento di una U‑Net di segmentazione. Le parti principali sono:\n",
        "0  setup & import\n",
        "1  path + parametri\n",
        "2  load csv → src/dst\n",
        "3  helper funzioni\n",
        "4  H_glob + KNN\n",
        "5  locale vs globale → overlay & quality.csv\n",
        "6  patch512 generator\n",
        "7  (opt) angle refine\n",
        "8  (opt) z‑score scale\n",
        "9  zip packaging\n",
        "\n",
        "<details>\n",
        "    Setup & prerequisiti – install e import.\n",
        "\n",
        "    I/O & config – path ai CSV, immagini e cartelle di output.\n",
        "\n",
        "    Funzioni geometriche – estrazione dei quattro cardinali di un’ellisse (“pipeline A”) o campionamento uniforme del contorno (“pipeline B”).\n",
        "\n",
        "    Stima di H – cv2.findHomography(..., cv2.RANSAC, th) con grid search sui threshold, scelta di quello con inlier‑ratio migliore.\n",
        "\n",
        "    Warp & debug overlay – allineamento NDT‑>ottico, overlay RGB per controllo visivo.\n",
        "\n",
        "    Crop & patching – ritaglio centrato sul foro (450 × 450 px circa) e salvataggio PNG.\n",
        "\n",
        "    Costruzione maschere GT – Otsu + morphology (erosione & apertura) per separare foro e danno.\n",
        "\n",
        "    Packaging – zipfile.ZipFile di patch e maschere per upload/uso ML."
      ],
      "metadata": {
        "id": "W_SE1ZRjwwwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 What you need\n",
        "\n",
        "| column                  | how to compute                                               | comment                                |\n",
        "| ----------------------- | ------------------------------------------------------------ | -------------------------------------- |\n",
        "| `hole_id`               | the existing `hole_idx`                                      | stays 1 … 64                           |\n",
        "| `optical_x` `optical_y` | `(x1 + x2) // 2`, `(y1 + y2) // 2` **from the ingresso CSV** | centre of the hole in the optical scan |\n",
        "| `ndt_x` `ndt_y`         | same centre but **from the radio CSV**                       | centre of the hole in the NDT scan     |\n"
      ],
      "metadata": {
        "id": "DuVrJOTWgxcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% 0\n",
        "#@title 0 Setup\n",
        "#**Prerequisites:**\n",
        "# %% 0 – Setup & import\n",
        "# - Installa dipendenze se mancano (opencv‑python‑headless, numpy, pandas, scikit‑image…)\n",
        "# - Importa tutte le librerie usate dal resto del notebook\n",
        "# - NON mettere altro codice: così gli import rimangono una sola volta\n",
        "!pip install opencv-python numpy pandas\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors as nn\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "import csv, math\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "oISq5VyhhF8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Il problema principale del tuo script è la **mancanza di un flusso di dati lineare**. Ci sono almeno tre strategie diverse per l'allineamento mescolate insieme:\n",
        "##1.  **Omografia Globale Semplice:** Calcola una `H` per tutta l'immagine e la usa per tutto.\n",
        "##2.  **Omografia Locale per Ogni Foro:** Calcola una `H` specifica per ogni foro usando i suoi vicini (k-NN). Molto più precisa ma complessa.\n",
        "##3.  **Scaling Semplice:** Ignora l'omografia e si limita a riscalare le patch.\n",
        "##"
      ],
      "metadata": {
        "id": "KMjhyuh7FY2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# CELLA 1: CONFIGURAZIONE\n",
        "# ===================================================================\n",
        "print(\"--- [FASE 1] Configurazione del Processo ---\")\n",
        "\n",
        "import cv2, json, pathlib, numpy as np, pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import zipfile\n",
        "#lavoriamo con ingressi che sono più facili da definitre\n",
        "# --- 1. PARAMETRI DELLO SCAN (MODIFICA SOLO QUESTA SEZIONE) ---\n",
        "SCAN_ID = \"1A\" # Esempio: \"1A\", \"1B\", etc.\n",
        "OPTICAL_IMAGE_NAME = f\"T0_90_{SCAN_ID}_ingresso.jpg\"\n",
        "NDT_IMAGE_NAME = f\"Carbon Textile {SCAN_ID}.jpg\"\n",
        "OPTICAL_CSV_NAME = f\"T0_90_{SCAN_ID}_ingresso_ordered_NEW.csv\"\n",
        "NDT_CSV_NAME = f\"Carbon Textile {SCAN_ID}_ordered_NEW.csv\"\n",
        "\n",
        "# --- 2. PERCORSI (MODIFICA SE NECESSARIO) ---\n",
        "DRIVE_BASE_PATH = pathlib.Path(\"/content/drive/MyDrive\")\n",
        "OPTICAL_IMAGE_PATH = DRIVE_BASE_PATH / \"Scan_Orientate\" / OPTICAL_IMAGE_NAME\n",
        "NDT_IMAGE_PATH = DRIVE_BASE_PATH / \"FileTesi/ScanzioneProviniUsura/Radio\" / NDT_IMAGE_NAME\n",
        "OPTICAL_CSV_PATH = DRIVE_BASE_PATH / \"CSV_FINALI/INGRESSI_ORDINATI\" / OPTICAL_CSV_NAME\n",
        "NDT_CSV_PATH = DRIVE_BASE_PATH / \"CSV_FINALI/Radio_first_350 holes\" / NDT_CSV_NAME\n",
        "OUTPUT_BASE_DIR = pathlib.Path(f\"/content/Homography_Output_{SCAN_ID}\")\n",
        "\n",
        "# --- 3. PARAMETRI DI PROCESSO (PUOI TENERE I DEFAULT) ---\n",
        "PATCH_SIZE = 704             # Dimensione finale delle patch\n",
        "K_NEIGHBORS = 9              # N. di vicini per l'omografia locale\n",
        "RANSAC_THRESHOLD = 3.0       # Tolleranza per findHomography\n",
        "# Parametri del filtro di qualità\n",
        "SHIFT_QUANTILE = 0.90        # Scarta il 10% peggiore per lo shift\n",
        "SSIM_QUANTILE = 0.10         # Scarta il 10% peggiore per SSIM\n",
        "MIN_INLIER_RATIO = 0.7       # Almeno il 70% dei vicini deve essere inlier\n",
        "\n",
        "# --- Creazione directory di output --- VUOTE\n",
        "(OUTPUT_BASE_DIR / \"overlays\").mkdir(parents=True, exist_ok=True)\n",
        "(OUTPUT_BASE_DIR / \"final_patches/images\").mkdir(parents=True, exist_ok=True)\n",
        "(OUTPUT_BASE_DIR / \"final_patches/masks\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Configurazione caricata per lo Scan ID: {SCAN_ID}\")"
      ],
      "metadata": {
        "id": "dKcwg10vpvjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Caso foro                   | Funzione                    | Logica                                                                                                                 |\n",
        "| --------------------------- | --------------------------- | ---------------------------------------------------------------------------------------------------------------------- |\n",
        "| Foro ellittico ben definito | `four_cardinals(cnt)`       | Fit di un’ellisse via `cv2.fitEllipse` e calcolo dei 4 assi principali ([tutorialspoint.com][1], [docs.opencv.org][2]) |\n",
        "| Foro irregolare / usurato   | `sample_contour(cnt, k=32)` | Uniform sampling del contorno per robustezza                                                                           |\n",
        "\n",
        "[1]: https://www.tutorialspoint.com/how-to-fit-the-ellipse-to-an-object-in-an-image-using-opencv-python?utm_source=chatgpt.com \"How to fit the ellipse to an object in an image using OpenCV Python?\"\n",
        "[2]: https://docs.opencv.org/4.x/de/d62/tutorial_bounding_rotated_ellipses.html?utm_source=chatgpt.com \"Creating Bounding rotated boxes and ellipses for contours - OpenCV\"\n"
      ],
      "metadata": {
        "id": "DgZtBzSIyE-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# CELLA 2: CARICAMENTO DATI E CREAZIONE MASTER CSV\n",
        "# ===================================================================\n",
        "print(\"--- [FASE 2] Creazione Master CSV ---\")\n",
        "\n",
        "try:\n",
        "    opt_df = pd.read_csv(OPTICAL_CSV_PATH)\n",
        "    ndt_df = pd.read_csv(NDT_CSV_PATH)\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"❌ ERRORE: File non trovato. Controlla i percorsi e lo SCAN_ID nella Cella 1. Dettagli: {e}\")\n",
        "    raise e\n",
        "\n",
        "assert opt_df.shape[0] == ndt_df.shape[0], f\"Disallineamento nel numero di fori: Ottico={len(opt_df)}, NDT={len(ndt_df)}\"\n",
        "\n",
        "opt_df[\"optical_x\"] = (opt_df.x1 + opt_df.x2) // 2\n",
        "opt_df[\"optical_y\"] = (opt_df.y1 + opt_df.y2) // 2\n",
        "ndt_df[\"ndt_x\"] = (ndt_df.x1 + ndt_df.x2) // 2\n",
        "ndt_df[\"ndt_y\"] = (ndt_df.y1 + ndt_df.y2) // 2\n",
        "\n",
        "master_df = (opt_df[[\"hole_idx\", \"optical_x\", \"optical_y\"]]\n",
        "             .merge(ndt_df[[\"hole_idx\", \"ndt_x\", \"ndt_y\"]], on=\"hole_idx\")\n",
        "             .rename(columns={\"hole_idx\": \"hole_id\"})\n",
        "             .sort_values(\"hole_id\"))\n",
        "\n",
        "MASTER_CSV_PATH = OUTPUT_BASE_DIR / f\"{SCAN_ID}_master.csv\"\n",
        "master_df.to_csv(MASTER_CSV_PATH, index=False)\n",
        "\n",
        "print(f\"✅ Master CSV creato in: {MASTER_CSV_PATH} ({len(master_df)} fori)\")"
      ],
      "metadata": {
        "id": "qmwWV1jjp645"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Strategie\n",
        "<details>\n",
        "| Strategia                                   | Quando usarla                                             | Come si costruiscono i punti                                                                                                                                                                                                                                    |\n",
        "| ------------------------------------------- | --------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **A. Fit di ellisse + quattro “cardinali”** | Ovale regolare dovuto a prospettiva; vuoi codice semplice | 1) `cv2.fitEllipse` su ciascun contorno.<br>2) Ricavi centro (C), semiasse maggior/minore (a,b) e angolo θ.<br>3) Calcoli i 4 punti di estremità (sinistra, destra, alto, basso) applicando la rotazione.<br>4) Con questi 4 ⇄ 4 punti chiami `findHomography`. |\n",
        "| **B. Campionamento uniforme**               | Contorni irregolari / profili con schegge                 | 1) Rishapi il contorno a (N,2).<br>2) Usa `np.linspace` per prendere es. 32 indici equidistanti su *entrambi* i contorni.<br>3) Rimodella in (N,1,2) `float32` e passa a `findHomography` (RANSAC 5 px).                                                        |\n"
      ],
      "metadata": {
        "id": "vhA25hxGyR2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>| Situazione                             | Pipeline A (cardinali)      | Pipeline B (campionamento) |\n",
        "| -------------------------------------- | --------------------------- | -------------------------- |\n",
        "| Foro ellittico regolare                | ✅ sub-pixel                 | ✅ ma inutile               |\n",
        "| Foro con bave locali                   | ✅ (fitEllipse attenua)      | ⚠ necessita pre-filtrare   |\n",
        "| Foro parziale tagliato dal bordo patch | ⚠ rischio fitEllipse errato | ✅ se punti interni sono ok |\n"
      ],
      "metadata": {
        "id": "lXCi6q4M1ymV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Il Nuovo Codice per Generare le Maschere Corrette\n",
        "<details>\n",
        "Sostituisci la sezione `C` del tuo script di generazione dataset con questo. Questo è il cuore della soluzione.\n",
        "\n",
        "```python\n",
        "# --- C. Crea la maschera del danno (GROUND TRUTH Y) - VERSIONE 2.0 CORRETTA ---\n",
        "rad_warp = cv2.warpPerspective(rad_raw, H_use, (wO, hO))\n",
        "rad_patch = rad_warp[y1:y2, x1:x2]\n",
        "\n",
        "# --- QUESTO È IL NUOVO CUORE ---\n",
        "# 1. Normalizza il contrasto come prima\n",
        "rad_patch_normalized = cv2.normalize(rad_patch, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "\n",
        "# 2. PASSO 1: Trova tutto ciò che è luminoso (Foro + Danno)\n",
        "#    Usiamo una soglia di Otsu che trova il valore ottimale automaticamente\n",
        "soglia_otsu, mask_tutto_il_luminoso = cv2.threshold(rad_patch_normalized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "# 3. PASSO 2: Isola solo il \"cuore\" del foro usando l'erosione\n",
        "#    Creiamo un \"kernel\" (una forma) per l'erosione. Più è grande, più aggressiva sarà l'erosione.\n",
        "kernel_size = 15 # Gioca con questo valore (es. 10, 15, 20)\n",
        "kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
        "mask_solo_foro = cv2.erode(mask_tutto_il_luminoso, kernel, iterations=1)\n",
        "\n",
        "# 4. PASSO 3: Sottrai il foro dal totale per ottenere SOLO IL DANNO\n",
        "damage_mask = cv2.subtract(mask_tutto_il_luminoso, mask_solo_foro)\n",
        "\n",
        "# (OPZIONALE MA CONSIGLIATO) Pulizia finale per rimuovere piccoli artefatti\n",
        "# Rimuove piccoli puntini di rumore\n",
        "kernel_pulizia = np.ones((3,3), np.uint8)\n",
        "damage_mask = cv2.morphologyEx(damage_mask, cv2.MORPH_OPEN, kernel_pulizia)\n",
        "\n",
        "# D. Salva i due file\n",
        "filename = f\"hole_{hole_id:04d}.png\"\n",
        "cv2.imwrite(str(IMAGES_DIR / filename), opt_patch)\n",
        "cv2.imwrite(str(MASKS_DIR / filename), damage_mask)\n",
        "\n",
        "# --- (OPZIONALE) AGGIUNGI QUESTO PER UN CHECK VISIVO ---\n",
        "# Salva le maschere intermedie per capire cosa sta succedendo\n",
        "# DEBUG_DIR = Path(\"/content/debug_masks\"); DEBUG_DIR.mkdir(exist_ok=True)\n",
        "# cv2.imwrite(str(DEBUG_DIR / f\"{filename}_1_tutto.png\"), mask_tutto_il_luminoso)\n",
        "# cv2.imwrite(str(DEBUG_DIR / f\"{filename}_2_solo_foro.png\"), mask_solo_foro)\n",
        "# cv2.imwrite(str(DEBUG_DIR / f\"{filename}_3_risultato.png\"), damage_mask)"
      ],
      "metadata": {
        "id": "n5kfMy6cgCRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Sintomo (quello che vedi)                                                           | Causa più probabile                                                              | Dove intervenire                                                          |\n",
        "| ----------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |\n",
        "| Ellisse ruotata ma **non centrata**                                                 | fitEllipse corretto → crop centrato *prima* del warp, non **dopo**               | usa il centro **dell’ellisse warppata** per ritagliare                    |\n",
        "| Bordo ottico ok ma la radiografia forma un **“cuscino”** pentagonale (angoli scuri) | punti cardinali scelti bene, ma raggio NDT troppo piccolo ⇒ scala in H sbagliata | aumenta **MARGIN** (es. 200 → 300) così il warp ha spazio                 |\n",
        "| Foro sembra **oblungo** solo in alto                                                | inlier ratio < 0,6 nella fallback B → RANSAC ha eliminato troppi punti           | abbassa la soglia RANSAC da 5 px a 3 px **e** campiona più punti (es. 60) |\n",
        "| Corte bande nere diagonali agli angoli                                              | il warp ritaglia dove non c’è informazione                                       | dopo `warpPerspective` fai `cv2.copyMakeBorder(aligned, ⟂)` con nero      |\n"
      ],
      "metadata": {
        "id": "-xoCmWCLCEUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Cella 3: Toolbox di Funzioni Helper\n",
        "\n",
        "'''Qui definiamo tutte le funzioni di supporto. Nessuna esecuzione, solo definizioni.\n",
        "'''\n",
        "# ===================================================================\n",
        "# CELLA 3: TOOLBOX DI FUNZIONI HELPER\n",
        "# ===================================================================\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def crop_patch(img, cx, cy, size):\n",
        "    x1, y1 = int(cx - size//2), int(cy - size//2)\n",
        "    return img[max(y1,0):y1+size, max(x1,0):x1+size]\n",
        "\n",
        "def create_ground_truth_mask(rad_patch):\n",
        "    normalized = cv2.normalize(rad_patch, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "    _, mask_all = cv2.threshold(normalized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    kernel_erosion = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
        "    mask_hole = cv2.erode(mask_all, kernel_erosion, iterations=1)\n",
        "\n",
        "    mask_damage = cv2.subtract(mask_all, mask_hole)\n",
        "\n",
        "    kernel_clean = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    mask_damage_clean = cv2.morphologyEx(mask_damage, cv2.MORPH_OPEN, kernel_clean)\n",
        "\n",
        "    final_mask = np.zeros_like(rad_patch, dtype=np.uint8)\n",
        "    final_mask[mask_hole > 0] = 1\n",
        "    final_mask[mask_damage_clean > 0] = 2\n",
        "\n",
        "    return final_mask\n",
        "\n",
        "print(\"✅ Funzioni helper definite.\")\n",
        "\n",
        "def largest_cnt(img):\n",
        "    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim==3 else img\n",
        "    _,th = cv2.threshold(g,0,255,cv2.THRESH_OTSU)\n",
        "    cnts,_ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    return max(cnts, key=cv2.contourArea) if cnts else None\n",
        "\n",
        "def ellipse_pts(cnt):\n",
        "    (cx,cy),(MA,ma),ang = cv2.fitEllipse(cnt)\n",
        "    a,b = MA/2, ma/2\n",
        "    R   = np.deg2rad(ang); ca,sa = np.cos(R), np.sin(R)\n",
        "    base= np.float32([[ a,0],[-a,0],[0,b],[0,-b]])\n",
        "    rot = np.array([[ca,-sa],[sa,ca]], np.float32)\n",
        "    return (rot @ base.T).T + (cx,cy)\n",
        "\n",
        "def sample_by_angle(cnt, k=40):\n",
        "    (cx,cy),_ = cv2.minEnclosingCircle(cnt)\n",
        "    pts = cnt.reshape(-1,2)-[cx,cy]\n",
        "    ang = np.arctan2(pts[:,1], pts[:,0])\n",
        "    order = ang.argsort()\n",
        "    pts = pts[order]+[cx,cy]\n",
        "    idx = np.linspace(0,len(pts)-1,k,dtype=int)\n",
        "    return pts[idx].astype(np.float32)\n",
        "\n",
        "def make_mask(img):\n",
        "    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim==3 else img\n",
        "    _,th = cv2.threshold(g,0,255,cv2.THRESH_OTSU)\n",
        "    return cv2.medianBlur(th,5)\n",
        "\n",
        "def micro_refine(opt_patch, rad_patch, delta=2.0, step=0.1):\n",
        "    \"\"\"piccola rotazione ±delta° che minimizza lo XOR foro–foro\"\"\"\n",
        "    h,w   = rad_patch.shape[:2]\n",
        "    centre= (w/2, h/2)\n",
        "    mask_o= make_mask(opt_patch)\n",
        "    best_loss, best_ang, best_out = 1e12, 0.0, rad_patch\n",
        "    for ang in np.arange(-delta, delta+step, step):\n",
        "        M   = cv2.getRotationMatrix2D(centre, ang, 1.)\n",
        "        rot = cv2.warpAffine(rad_patch, M, (w,h),\n",
        "                             flags=cv2.INTER_LINEAR,\n",
        "                             borderMode=cv2.BORDER_CONSTANT,\n",
        "                             borderValue=0)\n",
        "        loss= cv2.countNonZero(cv2.bitwise_xor(mask_o, make_mask(rot)))\n",
        "        if loss < best_loss:\n",
        "            best_loss, best_ang, best_out = loss, ang, rot\n",
        "    return best_out, best_ang, best_loss"
      ],
      "metadata": {
        "id": "eluqxbFgwXxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Osservazione                                                                                                        | Diagnosi tecnica                                                                                                                                                                                                                                                                                           |\n",
        "| ------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| L’overlay mostra la radiografia girata rispetto all’ottica (bordi diagonali, ellisse “capovolta”).                  | Il file **Carbon Textile 1A.jpg** è stato acquisito con un’inclinazione globale diversa (angolo di plate o testa di scansione). Quando applichi i 4 punti “cardinali” dell’ellisse, l’ordine di quei punti (±a, ±b) **non corrisponde** all’ordine nell’ottica, quindi `findHomography` compensa ruotando. |\n",
        "| `detH ≈ 3.09`, scaleX ≈ 1.80, scaleY ≈ 1.71: valori plausibili.<br>Ma l’ellisse ottica risultante è ancora obliqua. | La H ha risolto scala + shear, **ma** manca un pre-allineamento di rotazione globale, perciò il foro è centrato ma l’intero patch appare ruotato.                                                                                                                                                          |\n"
      ],
      "metadata": {
        "id": "BbK4L9s6OqQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| colonna    | cosa significa                                          | tipico range “buono” |\n",
        "| ---------- | ------------------------------------------------------- | -------------------- |\n",
        "| `detH`     | determinante di *H* (≈ area scale)                      | 0.1 – 10             |\n",
        "| `scaleX/Y` | norma prima riga / seconda riga di *H* (zoom)           | 0.3 – 3              |\n",
        "| `inlier`   | frazione punti inlier (metodo B)                        | ≥ 0.6                |\n",
        "| `axesA/B`  | semi‑assi ottica (px)                                   | ≈ diametro foro      |\n",
        "| `ok`       | 1 = patch accettata (regola empirica su scale + inlier) | —                    |\n"
      ],
      "metadata": {
        "id": "-5c9m_L65FI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===================================================================\n",
        "# CELLA 4.4 (MODIFICATA): OMOGRAFIA LOCALE ADATTIVA - nuova da usare\n",
        "# ===================================================================\n",
        "print(\"--- [FASE 4] Calcolo Omografia Adattiva e Metriche ---\")\n",
        "# ... (caricamento dati iniziale, H_glob, knn, etc. come prima) ...\n",
        "#--- Carica dati ---\n",
        "coord_df = pd.read_csv(MASTER_CSV_PATH)\n",
        "opt_img = cv2.imread(str(OPTICAL_IMAGE_PATH))\n",
        "rad_img = cv2.imread(str(NDT_IMAGE_PATH), 0)\n",
        "hO, wO = opt_img.shape[:2]\n",
        "\n",
        "src_pts = coord_df[['ndt_x', 'ndt_y']].to_numpy(np.float32)\n",
        "dst_pts = coord_df[['optical_x', 'optical_y']].to_numpy(np.float32)\n",
        "\n",
        "# --- Calcola H Globale una volta ---\n",
        "H_glob, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "knn = NearestNeighbors(n_neighbors=K_NEIGHBORS).fit(src_pts)\n",
        "\n",
        "quality_metrics = []\n",
        "ransac_thresholds_to_try = [1.0, 3.0, 5.0, 7.0] # Proveremo queste soglie\n",
        "\n",
        "for i, row in tqdm(coord_df.iterrows(), total=len(coord_df), desc=\"Analizzando fori\"):\n",
        "    src0 = src_pts[i].reshape(1,-1)\n",
        "    _, indices = knn.kneighbors(src0)\n",
        "    indices = indices.flatten()\n",
        "\n",
        "    best_H_loc = None\n",
        "    best_inliers = -1\n",
        "\n",
        "    # --- RANSAC SWEEP ---\n",
        "    # Per ogni foro, proviamo diverse soglie RANSAC e teniamo la migliore\n",
        "    for threshold in ransac_thresholds_to_try:\n",
        "        H_loc_candidate, mask = cv2.findHomography(\n",
        "            src_pts[indices], dst_pts[indices],\n",
        "            cv2.RANSAC, threshold\n",
        "        )\n",
        "\n",
        "        current_inliers = mask.ravel().sum() if mask is not None else 0\n",
        "\n",
        "        if current_inliers > best_inliers:\n",
        "            best_inliers = current_inliers\n",
        "            best_H_loc = H_loc_candidate\n",
        "\n",
        "    # Ora usiamo la H locale migliore trovata\n",
        "    inliers = best_inliers\n",
        "    H_loc = best_H_loc\n",
        "\n",
        "    # ... (il resto della logica: calcolo shift, scelta H_use, calcolo ssim, etc. rimane identico) ...\n",
        "    # ... (usa H_loc per calcolare lo shift, poi decidi se usare H_loc o H_glob) ...\n",
        "    # Scegli la H migliore (locale o globale)\n",
        "    use_local = (inliers >= MIN_INLIER_RATIO * K_NEIGHBORS) and (shift < 10) # Soglia fissa per lo shift\n",
        "    H_use = H_loc if use_local else H_glob\n",
        "\n",
        "    # Calcola SSIM per la qualità dell'allineamento\n",
        "    rad_warped = cv2.warpPerspective(rad_img, H_use, (wO, hO))\n",
        "    opt_patch_gray = cv2.cvtColor(crop_patch(opt_img, row.optical_x, row.optical_y, PATCH_SIZE), cv2.COLOR_BGR2GRAY)\n",
        "    rad_patch = crop_patch(rad_warped, row.optical_x, row.optical_y, PATCH_SIZE)\n",
        "    ssim_val = ssim(opt_patch_gray, rad_patch, data_range=rad_patch.max() - rad_patch.min())\n",
        "\n",
        "    quality_metrics.append({\n",
        "        'hole_id': row.hole_id, 'shift': shift, 'ssim': ssim_val,\n",
        "        'inliers': inliers, 'chosen_H': \"LOCAL\" if use_local else \"GLOBAL\",\n",
        "        **row.to_dict() # Aggiunge tutte le altre colonne\n",
        "    })\n",
        "    # Il resto del codice per calcolare shift, ssim e salvare le metriche rimane uguale\n",
        "    # ...\n",
        "\n",
        "metrics_df = pd.DataFrame(quality_metrics)\n",
        "print(\"✅ Calcolo metriche con RANSAC adattivo completato.\")"
      ],
      "metadata": {
        "id": "XlPVg_twFLtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# CELLA 4: CALCOLO OMOGRAFIA E METRICHE DI QUALITÀ(vecchia Soglia fissa)\n",
        "# ===================================================================\n",
        "print(\"--- [FASE 4] Calcolo Omografia e Metriche di Qualità ---\")\n",
        "\n",
        "# --- Carica dati ---\n",
        "coord_df = pd.read_csv(MASTER_CSV_PATH)\n",
        "opt_img = cv2.imread(str(OPTICAL_IMAGE_PATH))\n",
        "rad_img = cv2.imread(str(NDT_IMAGE_PATH), 0)\n",
        "hO, wO = opt_img.shape[:2]\n",
        "\n",
        "src_pts = coord_df[['ndt_x', 'ndt_y']].to_numpy(np.float32)\n",
        "dst_pts = coord_df[['optical_x', 'optical_y']].to_numpy(np.float32)\n",
        "\n",
        "# --- Calcola H Globale una volta ---\n",
        "H_glob, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "knn = NearestNeighbors(n_neighbors=K_NEIGHBORS).fit(src_pts)\n",
        "\n",
        "quality_metrics = []\n",
        "for i, row in tqdm(coord_df.iterrows(), total=len(coord_df), desc=\"Analizzando fori\"):\n",
        "    # Trova vicini e calcola H Locale\n",
        "    src0 = src_pts[i].reshape(1,-1)\n",
        "    _, indices = knn.kneighbors(src0)\n",
        "    indices = indices.flatten()\n",
        "    H_loc, mask = cv2.findHomography(src_pts[indices], dst_pts[indices], cv2.RANSAC, RANSAC_THRESHOLD)\n",
        "\n",
        "    inliers = mask.ravel().sum() if mask is not None else 0\n",
        "\n",
        "    # Calcola lo shift per H Locale\n",
        "    proj = (H_loc @ np.append(src0,1).T).ravel(); proj /= proj[2]\n",
        "    shift = np.hypot(proj[0] - row.optical_x, proj[1] - row.optical_y)\n",
        "\n",
        "    # Scegli la H migliore (locale o globale)\n",
        "    use_local = (inliers >= MIN_INLIER_RATIO * K_NEIGHBORS) and (shift < 10) # Soglia fissa per lo shift\n",
        "    H_use = H_loc if use_local else H_glob\n",
        "\n",
        "    # Calcola SSIM per la qualità dell'allineamento\n",
        "    rad_warped = cv2.warpPerspective(rad_img, H_use, (wO, hO))\n",
        "    opt_patch_gray = cv2.cvtColor(crop_patch(opt_img, row.optical_x, row.optical_y, PATCH_SIZE), cv2.COLOR_BGR2GRAY)\n",
        "    rad_patch = crop_patch(rad_warped, row.optical_x, row.optical_y, PATCH_SIZE)\n",
        "    ssim_val = ssim(opt_patch_gray, rad_patch, data_range=rad_patch.max() - rad_patch.min())\n",
        "\n",
        "    quality_metrics.append({\n",
        "        'hole_id': row.hole_id, 'shift': shift, 'ssim': ssim_val,\n",
        "        'inliers': inliers, 'chosen_H': \"LOCAL\" if use_local else \"GLOBAL\",\n",
        "        **row.to_dict() # Aggiunge tutte le altre colonne\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(quality_metrics)\n",
        "print(\"✅ Calcolo metriche completato.\")"
      ],
      "metadata": {
        "id": "xkK77mxzrlBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Cella 5.1 Filtraggio adattato dinamico con ransac sweep: Filtro di Qualità e Creazione `good_holes.csv`\n",
        "\n",
        "'''Questa cella prende le metriche, applica un filtro intelligente e salva la lista dei fori che verranno usati per il dataset finale.\n",
        "'''\n",
        "# ===================================================================\n",
        "# CELLA 5: FILTRO DI QUALITÀ\n",
        "# ===================================================================\n",
        "print(\"--- [FASE 5] Filtraggio dei fori di alta qualità ---\")\n",
        "\n",
        "## --- Calcola soglie dinamiche basate sui quantili ---\n",
        "# Vogliamo tenere circa l'80% dei fori migliori\n",
        "#**Perché funziona:** Invece di usare soglie fisse che potrebbero essere troppo severe, usiamo i quantili. Questo approccio ci garantisce di tenere una **percentuale fissa** dei migliori allineamenti. Se impostiamo il quantile a 0.80, stiamo dicendo: \"Prendi l'80% dei fori con lo shift più basso e l'80% dei fori con l'SSIM più alto\". Questo ci dà un controllo diretto sulla dimensione del dataset finale.\n",
        "\n",
        "SHIFT_MAX = metrics_df['shift'].quantile(0.80) # Scarta il 20% peggiore per shift\n",
        "SSIM_MIN = metrics_df['ssim'].quantile(0.20)  # Scarta il 20% peggiore per SSIM\n",
        "#dinamico fine- continua normale adesso\n",
        "print(f\"Soglie dinamiche calcolate: Shift <= {SHIFT_MAX:.2f}, SSIM >= {SSIM_MIN:.2f}\")\n",
        "\n",
        "# --- Applica filtro ---\n",
        "good_mask = (\n",
        "    (metrics_df['shift'] <= SHIFT_MAX) &\n",
        "    (metrics_df['ssim'] >= SSIM_MIN) &\n",
        "    (metrics_df['inliers'] >= MIN_INLIER_RATIO * K_NEIGHBORS)\n",
        ")\n",
        "good_holes_df = metrics_df[good_mask]\n",
        "\n",
        "GOOD_HOLES_CSV_PATH = OUTPUT_BASE_DIR / f\"quality_{SCAN_ID}.csv\"\n",
        "good_holes_df.to_csv(GOOD_HOLES_CSV_PATH, index=False)\n",
        "\n",
        "print(f\"✅ Fori di alta qualità filtrati: {len(good_holes_df)} / {len(metrics_df)}. Salvati in {GOOD_HOLES_CSV_PATH}\")"
      ],
      "metadata": {
        "id": "3-7iBVldrstK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Cella 6: Generazione Finale delle Patch e ZIP\n",
        "\n",
        "'''L'ultima cella. Legge `good_holes.csv` e crea le immagini, le maschere, gli overlay e lo zip finale.\n",
        "'''\n",
        "# ===================================================================\n",
        "# CELLA 6: GENERAZIONE PATCH FINALI E ZIP\n",
        "# ===================================================================\n",
        "print(\"--- [FASE 6] Generazione Patch e Packaging ---\")\n",
        "\n",
        "good_holes_df = pd.read_csv(GOOD_HOLES_CSV_PATH)\n",
        "\n",
        "for i, row in tqdm(good_holes_df.iterrows(), total=len(good_holes_df), desc=\"Creando patch finali\"):\n",
        "    H_use = H_glob # Per semplicità usiamo sempre la H globale per il warp finale, ma potremmo ricalcolare H_loc\n",
        "\n",
        "    rad_warped = cv2.warpPerspective(rad_img, H_use, (wO, hO))\n",
        "\n",
        "    opt_patch = crop_patch(opt_img, row.optical_x, row.optical_y, PATCH_SIZE)\n",
        "    rad_patch = crop_patch(rad_warped, row.optical_x, row.optical_y, PATCH_SIZE)\n",
        "\n",
        "    # Crea la maschera a 3 classi (0, 1, 2)\n",
        "    final_mask = create_ground_truth_mask(rad_patch)\n",
        "\n",
        "    # Salva immagine e maschera\n",
        "    filename_base = f\"hole_{int(row.hole_id):04d}\"\n",
        "    cv2.imwrite(str(OUTPUT_BASE_DIR / \"final_patches/images\" / f\"{filename_base}.png\"), opt_patch)\n",
        "    cv2.imwrite(str(OUTPUT_BASE_DIR / \"final_patches/masks\" / f\"{filename_base}.png\"), final_mask)\n",
        "\n",
        "    # Crea e salva overlay di debug\n",
        "    rad_bgr = cv2.cvtColor(rad_patch, cv2.COLOR_GRAY2BGR)\n",
        "    overlay = cv2.addWeighted(opt_patch, 0.6, rad_bgr, 0.4, 0)\n",
        "    cv2.imwrite(str(OUTPUT_BASE_DIR / \"overlays\" / f\"{filename_base}_overlay.png\"), overlay)\n",
        "\n",
        "# --- Packaging ---\n",
        "ZIP_PATH = OUTPUT_BASE_DIR / f\"unet_dataset_{SCAN_ID}.zip\"\n",
        "with zipfile.ZipFile(ZIP_PATH, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    for folder in [\"images\", \"masks\"]:\n",
        "        for file_path in (OUTPUT_BASE_DIR / \"final_patches\" / folder).glob(\"*.png\"):\n",
        "            zf.write(file_path, f\"{folder}/{file_path.name}\")\n",
        "\n",
        "print(f\"\\n✅ Processo completato! Dataset pronto per il training in '{ZIP_PATH}'\")"
      ],
      "metadata": {
        "id": "fEiQ6UeHsS03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##codice vecchio##"
      ],
      "metadata": {
        "id": "z9QHD-xUsSu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcolo fori e fattore di scala"
      ],
      "metadata": {
        "id": "8DLB_35-LOAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Per statistiche/Histogramma Scale ## %% 7 – Scale, overlay e statistiche preliminari controlla coerenza scans\n",
        "# %% 7 – Scale, overlay e statistiche preliminari\n",
        "# • Definisce percorsi CSV master, immagini full scan e directory overlay\n",
        "# • Crea directory per overlay per foro\n",
        "# • Parametri di rough‑crop e fallback diametri\n",
        "# • Carica DataFrame di coordinate (index=hole_id), ottica e radio full\n",
        "# • Loop su ogni foro con tqdm:\n",
        "#     – rough‑crop ottico e radio per calcolare diametri\n",
        "#     – funzione diam(): binarizza, chiude, trova contorno, fitEllipse → diametro medio\n",
        "#     – usa fallback se nessun contorno trovato\n",
        "#     – calcola scale S = diam_opt/diam_rad\n",
        "#     – aggiunge record a lista rows\n",
        "#     – crea overlay per debug: ridimensiona radio con S, applica colormap jet, alpha‑blend con ottica\n",
        "#     – salva overlay PNG in overlay_per_hole\n",
        "# • Alla fine scrive CSV scale_per_hole.csv con hole_id, diam_opt, diam_rad, scale_S\n",
        "# • Plotta istogramma di scale_S con linea media\n",
        "\n",
        "# Config\n",
        "CSV_C    = \"/content/Homography_Output_1A/1A_master.csv\"\n",
        "OPT_SCAN = OPTICAL_IMAGE_PATH\n",
        "RAD_SCAN = NDT_IMAGE_PATH\n",
        "OUT_S    = \"scale_per_hole.csv\"\n",
        "OVL_DIR  = Path(\"overlay_per_hole\"); OVL_DIR.mkdir(exist_ok=True)\n",
        "CROP_O   = 400; CROP_R = 200\n",
        "FALL_O   = 283; FALL_R = 142\n",
        "ALPHA=0.4\n",
        "df = pd.read_csv(CSV_C).set_index('hole_id')\n",
        "opt_full = cv2.imread(OPT_SCAN)\n",
        "rad_full = cv2.imread(RAD_SCAN,0)\n",
        "\n",
        "rows = []\n",
        "for hid, r in tqdm(df.iterrows(), total=len(df)):\n",
        "    ox, oy, rx, ry = r.optical_x, r.optical_y, r.ndt_x, r.ndt_y\n",
        "    def diam(patch, fallback):\n",
        "        cnts, _ = cv2.findContours(\n",
        "            cv2.threshold(\n",
        "                cv2.cvtColor(patch,cv2.COLOR_BGR2GRAY)\n",
        "                if patch.ndim==3 else patch,\n",
        "                0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU\n",
        "            )[1],\n",
        "            cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "        if not cnts: return fallback\n",
        "        (_, _),(MA,ma),_ = cv2.fitEllipse(max(cnts, key=cv2.contourArea))\n",
        "        return (MA+ma)/2\n",
        "\n",
        "    d_o = diam(crop_patch(opt_full,ox,oy,CROP_O), FALL_O)\n",
        "    d_r = diam(crop_patch(rad_full,rx,ry,CROP_R), FALL_R)\n",
        "    S   = round(d_o/d_r,4)\n",
        "    rows.append([hid, round(d_o,2), round(d_r,2), S])\n",
        "\n",
        "    # overlay debug\n",
        "    opt_p = crop_patch(opt_full,ox,oy,CROP_O)\n",
        "    rad_p = cv2.resize(crop_patch(rad_full,rx,ry,CROP_R),\n",
        "                       None, fx=S, fy=S, interpolation=cv2.INTER_LINEAR)\n",
        "    rad_p = cv2.resize(rad_p,(CROP_O,CROP_O))\n",
        "    cm = cv2.applyColorMap(\n",
        "        cv2.normalize(rad_p,None,0,255,cv2.NORM_MINMAX).astype('uint8'),\n",
        "        cv2.COLORMAP_JET\n",
        "    )\n",
        "    ov = cv2.addWeighted(opt_p,1-ALPHA,cm,ALPHA,0)\n",
        "    cv2.imwrite(str(OVL_DIR/f\"{hid:03d}_ovl.png\"), ov)\n",
        "\n",
        "with open(OUT_S,'w',newline='') as f:\n",
        "    csv.writer(f).writerows([['hole_id','diam_opt_px','diam_rad_px','scale_S']]+rows)\n",
        "\n",
        "print(f\"✓ Celle 7 eseguite: CSV in {OUT_S}, overlay in {OVL_DIR}\")\n",
        "plt.hist([r[3] for r in rows], bins=15)\n",
        "plt.title(\"Distribuzione scale_S\")\n",
        "plt.show()\n",
        "'''\n",
        "Cosa fa\n",
        "1. Ritaglia un rough crop_patch di ciascun foro su ottica (CROP_O) e radio (CROP_R).\n",
        "2. Binarizza, chiude, fitEllipse → diametro medio.\n",
        "3. scale_S = diam_opt / diam_rad → fattore di scala geometrico.\n",
        "4. Genera overlay JET (debug visivo) senza omografia, solo riscalando radialmente.\n",
        "5. Scrive scale_per_hole.csv; fa istogramma e z‑score.\n",
        "\n",
        "Quando ti serve\n",
        "* Per capire se la radiografia intera è già grossomodo scalata come l’ottica.\n",
        "* Per individuare outlier geometrici (fori deformi o segmentati male) prima di investire tempo in omografie locali.\n",
        "\n",
        "    Non è collegata ad H locali/globali; funziona “a monte”.\n",
        "'''"
      ],
      "metadata": {
        "id": "LgY4sutGm_Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title %% 8 – Analisi z‑score su scale_S\n",
        "# %% 8 – Analisi z‑score su scale_S\n",
        "# • Carica CSV scale_per_hole.csv\n",
        "# • Estrae vettore S delle scale per foro\n",
        "# • Calcola media e deviazione standard\n",
        "# • Aggiunge colonna z_score = (S−mean)/std\n",
        "# • Stampa media, σ e eventuali outlier con |z|>2\n",
        "# • Plotta istogramma di S con linea punteggiata alla media\n",
        "\n",
        "dfz = pd.read_csv(\"scale_per_hole.csv\")\n",
        "S = dfz['scale_S']\n",
        "mean, std = S.mean(), S.std()\n",
        "dfz['z_score'] = (S-mean)/std\n",
        "\n",
        "print(f\"Media S̄ = {mean:.4f}, σ = {std:.4f}\")\n",
        "out = dfz[dfz.z_score.abs()>2]\n",
        "if not out.empty:\n",
        "    print(\"Outlier (|z|>2):\")\n",
        "    print(out[['hole_id','scale_S','z_score']])\n",
        "\n",
        "plt.hist(S, bins=15)\n",
        "plt.axvline(mean, linestyle='--')\n",
        "plt.title(\"z‑score delle scale\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1mV6mEUJnF0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Che cosa fa la cella 12 riga‑per‑riga\n",
        "<details>\n",
        "    Crea/assicia cartella OUT = Path(\"/content/out_overlay\").\n",
        "\n",
        "    Per ogni foro\n",
        "\n",
        "        calcola H_loc (K = 9 + RANSAC 3 px);\n",
        "\n",
        "        stima lo shift di quel foro ⇒ decide LOCAL vs GLOBAL;\n",
        "\n",
        "        warpa la radiografia intera con H_use;\n",
        "\n",
        "        ritaglia patch ottico & radio col tuo crop() (garantito 704×704);\n",
        "\n",
        "        colormap + alpha‑blend → overlay_${hole}.png;\n",
        "\n",
        "        calcola SSIM e accumula in rows.\n",
        "\n",
        "    Alla fine (cella 13) salva:\n",
        "\n",
        "df = pd.DataFrame(rows)                    # DataFrame vero\n",
        "df.to_csv(OUT / \"quality.csv\", index=False)\n",
        "\n",
        "e stampa l’elenco “⚠️ Fori da controllare” (shift > 5 px o SSIM < 0.30)"
      ],
      "metadata": {
        "id": "iWH5WodTFEkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (CORE) %% 12  – Loop principale per omografia locale e overlay qualità. Loop locale vs globale + overlay & SSIM\tUSA (core)\t• Usa H_glob, nn, QUALITY_THR, MIN_INLIERS, CROP.\n",
        "#• Salva overlay e popola rows\n",
        "rows = []\n",
        "from pathlib import Path\n",
        "OUT = Path(\"/content/out_overlay\")    # <‑‑ adesso è Path\n",
        "OUT.mkdir(exist_ok=True)              # cartella se non esiste\n",
        "for i,row in coord.iterrows():\n",
        "    src0 = src[i].reshape(1,-1)\n",
        "    _,idx = nn.kneighbors(src0); idx = idx.flatten()\n",
        "\n",
        "    H_loc, msk = cv2.findHomography(src[idx], dst[idx], cv2.RANSAC, 3)\n",
        "    inl = int(msk.sum()) if msk is not None else 0\n",
        "\n",
        "    # stima shift del centro\n",
        "    proj  = (H_loc @ np.append(src0,1).T).ravel(); proj /= proj[2]\n",
        "    shift = np.hypot(proj[0]-row.optical_x, proj[1]-row.optical_y)\n",
        "\n",
        "    use_local = inl>=MIN_INLIERS and shift<=QUALITY_THR\n",
        "    H_use = H_loc if use_local else H_glob\n",
        "    tag   = \"LOCAL\" if use_local else \"GLOBAL\"\n",
        "\n",
        "    # ---- ritaglia ROI ottica ----------------------------\n",
        "    cx,cy = int(row.optical_x), int(row.optical_y)\n",
        "    x1,y1 = cx-CROP//2, cy-CROP//2 ; x2,y2 = x1+CROP, y1+CROP\n",
        "    opt_patch = crop(opt_img, cx, cy, CROP)\n",
        "\n",
        "    # ---- warp radiografia SOLO per quest’area -----------\n",
        "    #   trucco: applichiamo H_use all’intera immagine, è <0.1 s con 8 MP\n",
        "    rad_warp = cv2.warpPerspective(rad_raw, H_use, (wO,hO))\n",
        "    rad_patch = crop(rad_warp, cx, cy, CROP)     # garantisce dimensione CROP×CROP\n",
        "\n",
        "\n",
        "    # ---- overlay + colormap -----------------------------\n",
        "    rad_col = cv2.applyColorMap(cv2.normalize(rad_patch,None,0,255,cv2.NORM_MINMAX)\n",
        "                                .astype('uint8'), cv2.COLORMAP_JET) # docs :contentReference[oaicite:3]{index=3}\n",
        "    over = cv2.addWeighted(opt_patch, 1-ALPHA, rad_col, ALPHA, 0)\n",
        "\n",
        "    # ---- SSIM (qualità texture) -------------------------\n",
        "    #ssim_val = ssim(cv2.cvtColor(opt_patch,cv2.COLOR_BGR2GRAY), rad_patch,\n",
        "    #                data_range=rad_patch.ptp())            # docs :contentReference[oaicite:4]{index=4}\n",
        "    # choice A – use the functional call (clean & portable)\n",
        "    ssim_val = ssim(cv2.cvtColor(opt_patch, cv2.COLOR_BGR2GRAY),\n",
        "                    rad_patch,\n",
        "                    data_range=np.ptp(rad_patch))          # <- np.ptp !\n",
        "    # choice B – spell it out, no ptp() at all\n",
        "    \"\"\"ssim_val = ssim(cv2.cvtColor(opt_patch, cv2.COLOR_BGR2GRAY),\n",
        "                rad_patch,\n",
        "                data_range=rad_patch.max() - rad_patch.min())\"\"\"\n",
        "    cv2.putText(over, f\"id:{row.hole_id}  shift:{shift:.2f}px  SSIM:{ssim_val:.3f}  {tag}\",\n",
        "                (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(255,255,255),2,cv2.LINE_AA)\n",
        "    cv2.imwrite(str(OUT/f\"overlay_{row.hole_id:04d}.png\"), over)\n",
        "\n",
        "    rows.append(dict(hole=row.hole_id, shift=shift, ssim=ssim_val,\n",
        "                     inliers=inl, chosen=tag,optical_x=row.optical_x, optical_y=row.optical_y,\n",
        "                     ndt_x=row.ndt_x, ndt_y=row.ndt_y))\n",
        "\n",
        "df_metrics = pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "oVwwF8JRw-_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% 12‑bis – calcolo soglie auto POI SUBITO DOPO 13 PER IL FILTRAGGIO\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df_metrics = pd.DataFrame(rows)\n",
        "\n",
        "SHIFT_MAX   = 2 * df_metrics['shift'].median()                     #  ≈ 2·mediana\n",
        "SSIM_MIN    = max(0.15, df_metrics['ssim'].mean()\n",
        "                         - 2*df_metrics['ssim'].std())             #  mai sotto 0.15\n",
        "MIN_INLIERS = int(round(0.7 * 9))                                  #  70 % di 9\n",
        "#Nota: non ridefinire più QUALITY_THR, SSIM_THR ecc.; usa queste tre nuove costanti (SHIFT_MAX, SSIM_MIN, MIN_INLIERS) in tutte le celle successive.\n",
        "print(f\"Soglie → shift ≤ {SHIFT_MAX:.1f} px   SSIM ≥ {SSIM_MIN:.3f}   inliers ≥ {MIN_INLIERS}\")\n",
        "df.to_csv(OUT / \"quality.csv\", index=False)\n",
        "\n",
        "print(\"written:\", (OUT / \"quality.csv\").exists())\n",
        "bad = [r['hole'] for r in rows if r['shift']>QUALITY_THR or r['ssim']<.3]\n",
        "print(\"⚠️  Fori da controllare:\", bad)"
      ],
      "metadata": {
        "id": "1SQ9aJ4nxeEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "dfm = pd.DataFrame(rows)\n",
        "\n",
        "fig, axs = plt.subplots(1,3, figsize=(12,3))\n",
        "axs[0].hist(dfm['shift'], bins=20); axs[0].set_title(\"shift [px]\")\n",
        "axs[1].hist(dfm['ssim'],  bins=20); axs[1].set_title(\"SSIM\")\n",
        "axs[2].hist(dfm['inliers'], bins=10); axs[2].set_title(\"inlier K={VAR}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rgp2JOl7Lhk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% 13 – quality.csv + good_holes.csv\n",
        "df_metrics['good'] = (df_metrics['shift']  <= SHIFT_MAX) & \\\n",
        "                     (df_metrics['ssim']   >= SSIM_MIN)  & \\\n",
        "                     (df_metrics['inliers']>= MIN_INLIERS)\n",
        "\n",
        "df_metrics.to_csv(OUT / \"quality.csv\", index=False)\n",
        "\n",
        "good = df_metrics[df_metrics['good']]\n",
        "print(f\"Fori OK: {len(good)}/{len(df_metrics)}\")\n",
        "\n",
        "good_holes = (good[['hole','chosen']]          # hole_id + tag LOCAL/GLOBAL\n",
        "              .rename(columns={'hole':'hole_id'})\n",
        "              .merge(coord_df, on='hole_id'))  # aggiunge tutte le coordinate\n",
        "\n",
        "good_holes.to_csv(\"good_holes.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "eoruya0qK4Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_metrics = DataFrame già calcolato (hole, shift, ssim, inliers, chosen…)\n",
        "\n",
        "MIN_OK      = 0.9          # voglio almeno il 70 % di fori buoni\n",
        "MAX_ITER    = 100           # non iterare all’infinito\n",
        "K           = 6            # vicini usati per H_loc\n",
        "\n",
        "for it in range(MAX_ITER):\n",
        "    # 1) calcola soglie a partire dai quantili attuali\n",
        "    SHIFT_MAX  = df_metrics['shift'].quantile(0.90)      # scarta 10 % peggiore\n",
        "    SSIM_MIN   = df_metrics['ssim' ].quantile(0.1)      # scarta 10 % peggiore\n",
        "    INL_MIN    = int(round(0.7 * K))                     # 70 % di inlier\n",
        "\n",
        "    # 2) etichetta i “good”\n",
        "    good_mask = (df_metrics['shift']  <= SHIFT_MAX) & \\\n",
        "                (df_metrics['ssim']   >= SSIM_MIN)  & \\\n",
        "                (df_metrics['inliers']>= INL_MIN)\n",
        "    good_pct  = good_mask.mean()           # frazione [0–1]\n",
        "\n",
        "    print(f\"[iter {it}] ok {good_pct:.2%}  \"\n",
        "          f\"shift≤{SHIFT_MAX:.1f}  SSIM≥{SSIM_MIN:.3f}\")\n",
        "\n",
        "    # 3) se basta, esci\n",
        "    if good_pct >= MIN_OK:\n",
        "        break\n",
        "\n",
        "    # 4) altrimenti allenta progressivamente (p. es. alza quantili)\n",
        "    #    qui un esempio molto semplice:\n",
        "    df_metrics.loc[~good_mask, 'shift']  *= 0.9   # riduco un po' gli shift outlier\n",
        "    df_metrics.loc[~good_mask, 'ssim']   *= 1.05  # aumento leggermente SSIM outlier\n",
        "    # (puoi elaborare logiche più sofisticate)\n"
      ],
      "metadata": {
        "id": "knXIZPKLM0YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# good_mask è già definito nel punto precedente\n",
        "df_metrics['good'] = good_mask\n",
        "df_metrics.to_csv(OUT / \"quality.csv\", index=False)\n",
        "\n",
        "# ── crea il DataFrame BUONO ────────────────────────────────\n",
        "good_holes = (df_metrics[df_metrics['good']]           # tieni solo i buoni\n",
        "              [['hole', 'chosen']]                     # id + LOCAL/GLOBAL\n",
        "              .rename(columns={'hole': 'hole_id'})     # uniforma nome\n",
        "              .merge(coord_df, on='hole_id'))          # aggiungi coordinate\n",
        "\n",
        "good_holes.to_csv(\"good_holes.csv\", index=False)\n",
        "print(\"good_holes.csv salvato, fori OK:\", len(good_holes))\n",
        "print(good_holes.head())\n",
        "print(good_holes.columns)\n"
      ],
      "metadata": {
        "id": "3qNgUMlSNOyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccfd57ff"
      },
      "source": [
        "#@title Avanzato; alla fine; fine tune %% Ransac sweep overlay - overlay critici - report # modifica src\n",
        "#Scopo : trovare a posteriori il threshold RANSAC che massimizza l’inlier‑ratio su tutti i punti — e produrre overlay dei “fori critici” con ogni soglia.\n",
        "#* Imposta ransac_thresholds = np.arange(1.0, 10.1, 0.5) prima del loop.\n",
        "#* Puoi riutilizzarla dopo aver visto che la soglia 5 px della cella 5a non è ottimale.\n",
        "#* Una volta trovato best_H, sostituisci H_glob con best_H e rigenera overlay/patch senza rifare tutto il notebook\n",
        "# --- file già prodotti nel tuo notebook -----------------------------\n",
        "CSV_COORD   = \"/content/T0_90_1A_master.csv\"     # ottico_x/y e ndt_x/y\n",
        "OPT_SCAN    = \"/content/T0_90_1A_ingresso.jpg\"\n",
        "RAD_SCAN    = \"/content/Carbon Textile 1A.jpg\"\n",
        "\n",
        "# Carica le immagini full e le coordinate una volta\n",
        "opt_full = cv2.imread(OPT_SCAN)                     # BGR\n",
        "rad_full = cv2.imread(RAD_SCAN, 0)                  # grey\n",
        "coord_df = pd.read_csv(CSV_COORD)\n",
        "\n",
        "# Estrai i punti sorgente (radio/NDT) e destinazione (ottico)\n",
        "src_points = np.float64(coord_df[['ndt_x', 'ndt_y']].values)\n",
        "dst_points = np.float64(coord_df[['optical_x', 'optical_y']].values)\n",
        "\n",
        "# Define critical hole IDs and overlay parameters\n",
        "critical_hole_ids = [1, 2, 61, 62, 63, 64]\n",
        "ALPHA = 0.40\n",
        "CROP_SIZE = 300\n",
        "\n",
        "# Create output directory for overlays\n",
        "OVERLAY_DIR_BASE = \"/content/overlays_per_threshold\"\n",
        "os.makedirs(OVERLAY_DIR_BASE, exist_ok=True)\n",
        "\n",
        "# Initialize tracking variables\n",
        "best_inlier_ratio = 0\n",
        "best_threshold = None\n",
        "best_H = None\n",
        "\n",
        "# Prepare report data\n",
        "report_data = []\n",
        "\n",
        "# Start the loop through RANSAC thresholds\n",
        "for threshold in tqdm(ransac_thresholds, desc=\"Processing thresholds\"):\n",
        "    # Calculate Homography for the current threshold\n",
        "    H, mask = cv2.findHomography(src_points, dst_points, cv2.RANSAC, threshold, maxIters=10000)\n",
        "\n",
        "    if mask is not None:\n",
        "        inlier_ratio = mask.mean()\n",
        "    else:\n",
        "        inlier_ratio = 0\n",
        "        H = None # Ensure H is None if mask is None\n",
        "\n",
        "    # Update best H and threshold if current inlier ratio is higher\n",
        "    if inlier_ratio > best_inlier_ratio:\n",
        "        best_inlier_ratio = inlier_ratio\n",
        "        best_threshold = threshold\n",
        "        best_H = H.copy() if H is not None else None # Store a copy of H\n",
        "\n",
        "    # Calculate metrics for the current threshold\n",
        "    detH = np.linalg.det(H) if H is not None else np.nan\n",
        "    scale_x = np.linalg.norm(H[0,:2]) if H is not None else np.nan\n",
        "    scale_y = np.linalg.norm(H[1,:2]) if H is not None else np.nan\n",
        "\n",
        "    # Store report data\n",
        "    report_data.append({\n",
        "        \"threshold\": threshold,\n",
        "        \"inlier_ratio\": inlier_ratio,\n",
        "        \"detH\": detH,\n",
        "        \"scale_x\": scale_x,\n",
        "        \"scale_y\": scale_y\n",
        "    })\n",
        "\n",
        "    # Generate overlays for critical holes\n",
        "    if H is not None:\n",
        "        h_opt, w_opt = opt_full.shape[:2]\n",
        "        rad_warped = cv2.warpPerspective(rad_full, H, (w_opt, h_opt))\n",
        "\n",
        "        overlay_subdir = os.path.join(OVERLAY_DIR_BASE, f\"threshold_{threshold:.1f}\")\n",
        "        os.makedirs(overlay_subdir, exist_ok=True)\n",
        "\n",
        "        for hid in critical_hole_ids:\n",
        "            if hid not in coord_df['hole_id'].values:\n",
        "                print(f\"Warning: Hole ID {hid} not found in coordinates CSV. Skipping overlay.\")\n",
        "                continue\n",
        "\n",
        "            # Find the coordinates for the hole\n",
        "            hole_coords = coord_df[coord_df['hole_id'] == hid].iloc[0]\n",
        "            ox, oy = int(hole_coords.optical_x), int(hole_coords.optical_y)\n",
        "\n",
        "            # Crop patches from the full images\n",
        "            opt_patch = crop(opt_full, ox, oy, CROP_SIZE)\n",
        "            rad_patch_aligned = crop(rad_warped, ox, oy, CROP_SIZE)\n",
        "\n",
        "            # Create and save overlay\n",
        "            rad_patch_color = cv2.cvtColor(rad_patch_aligned, cv2.COLOR_GRAY2BGR)\n",
        "            if opt_patch.shape != rad_patch_color.shape:\n",
        "                 print(f\"Warning: Patch shapes mismatch for hole {hid}: {opt_patch.shape} vs {rad_patch_color.shape}. Skipping overlay.\")\n",
        "                 continue\n",
        "            overlay = cv2.addWeighted(opt_patch, 1 - ALPHA, rad_patch_color, ALPHA, 0)\n",
        "            cv2.imwrite(os.path.join(overlay_subdir, f\"overlay_{hid}.png\"), overlay)\n",
        "\n",
        "# After the loop, print the best threshold and generate the full report\n",
        "print(f\"\\nBest threshold found: {best_threshold:.1f} with inlier ratio: {best_inlier_ratio:.2%}\")\n",
        "\n",
        "report_df = pd.DataFrame(report_data)\n",
        "print(\"\\nDetailed Report:\")\n",
        "display(report_df)\n",
        "\n",
        "# Optional: Save the report to a CSV file\n",
        "report_csv_path = \"/content/ransac_threshold_report.csv\"\n",
        "report_df.to_csv(report_csv_path, index=False)\n",
        "print(f\"\\nDetailed report saved to: {report_csv_path}\")\n",
        "\n",
        "# Note: The best_H matrix is stored in the variable best_H"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title esegui su fori SSIM <0.3 ## %% Check angolo su quality – Verifica angoli (fallback B)\n",
        "#• Usa CSV_PATH e NON hard‑code altri CSV.\n",
        "# %%  – Verifica angoli (fallback B)\n",
        "# • Definisce parametri di crop per ottica e radio, intervallo angoli e passo\n",
        "# • Inizializza CSV ang_check.csv con header hole_id, best_angle, xor_loss\n",
        "# • Carica DataFrame dei fori, immagine ottica full e radiografia full\n",
        "# • Definisce mask_img() per binarizzare e smoothare con Otsu+medianBlur\n",
        "# • Definisce xor_loss() per misurare differenza bit‑wise tra maschere\n",
        "# • Loop su ogni foro:\n",
        "#     – estrae patch grezze ottica e radio\n",
        "#     – calcola maschera ottica\n",
        "#     – per ogni angolo in [-Δ,Δ] con passo STEP:\n",
        "#         » ruota patch radio\n",
        "#         » calcola xor_loss con maschera ottica\n",
        "#         » tiene il migliore (min loss)\n",
        "#     – scrive sul CSV hole_id, best_angle e loss minimo\n",
        "\n",
        "# Parametri per angolo\n",
        "PATCH_O = 704; PATCH_R = 256\n",
        "DELTA   = 12.5; STEP   = 0.1\n",
        "CSV_IN  = \"/content/T0_90_1A_master.csv\"\n",
        "CSV_OUT = \"ang_check.csv\"\n",
        "\n",
        "# Init CSV\n",
        "with open(CSV_OUT, 'w', newline='') as f:\n",
        "\n",
        "  csv.writer(f).writerow([\"hole_id\",\"best_angle_deg\",\"xor_loss\"])\n",
        "\n",
        "df_in = pd.read_csv(CSV_IN)\n",
        "opt = cv2.imread(OPTICAL_FULL_PATH)\n",
        "rad = cv2.imread(NDT_FULL_PATH, 0)\n",
        "\n",
        "def mask_img(im):\n",
        "    g = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) if im.ndim==3 else im\n",
        "    _,th = cv2.threshold(g,0,255,cv2.THRESH_OTSU)\n",
        "    return cv2.medianBlur(th,5)\n",
        "\n",
        "def xor_loss(a,b):\n",
        "    h,w = min(a.shape[0],b.shape[0]), min(a.shape[1],b.shape[1])\n",
        "    return cv2.countNonZero(cv2.bitwise_xor(a[:h,:w], b[:h,:w]))\n",
        "\n",
        "for _,r in df_in.iterrows():\n",
        "    hid, ox, oy, rx, ry = r.hole_id, r.optical_x, r.optical_y, r.ndt_x, r.ndt_y\n",
        "    o_p = crop(opt, ox, oy, PATCH_O)\n",
        "    r_p = crop(rad, rx, ry, PATCH_R)\n",
        "    m_o = mask_img(o_p)\n",
        "\n",
        "    best_l, best_a = 1e9, 0\n",
        "    for ang in np.arange(-DELTA, DELTA+STEP, STEP):\n",
        "        M = cv2.getRotationMatrix2D((PATCH_R/2,PATCH_R/2), ang, 1)\n",
        "        rot = cv2.warpAffine(r_p, M, (PATCH_R,PATCH_R),\n",
        "                             flags=cv2.INTER_LINEAR,\n",
        "                             borderMode=cv2.BORDER_CONSTANT)\n",
        "        loss = xor_loss(m_o, mask_img(rot))\n",
        "        if loss < best_l:\n",
        "            best_l, best_a = loss, ang\n",
        "\n",
        "    with open(CSV_OUT,'a',newline='') as f:\n",
        "        csv.writer(f).writerow([hid, round(best_a,2), int(best_l)])\n",
        "\n",
        "print(f\"✓ Celle 6 eseguite: angoli in {CSV_OUT}\")\n"
      ],
      "metadata": {
        "id": "U6PYdL7Km4t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% 25a – fori sospetti da quality.csv\n",
        "qual = pd.read_csv(OUT / \"quality.csv\")\n",
        "suspect = qual.loc[\n",
        "            (qual['shift'] > QUALITY_THR) |\n",
        "            (qual['ssim']  < SSIM_THR), 'hole']\n",
        "suspect.to_csv(\"suspect.csv\", index=False, header=['hole_id'])\n",
        "\n",
        "# %% 6 – angle‑check sui soli fori sospetti\n",
        "CSV_IN  = \"suspect.csv\"     # <‑‑ adesso NON hard‑code\n",
        "CSV_OUT = \"ang_check.csv\"\n"
      ],
      "metadata": {
        "id": "xls8f3d9JeIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEBUG creazioe zip overlays"
      ],
      "metadata": {
        "id": "4MxFN0BZQA8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% 26 – Patch finali + ZIP (allineate)\n",
        "from pathlib import Path\n",
        "import cv2, zipfile, numpy as np, pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "PATCH_DIR   = Path(\"/content/final_patches\"); PATCH_DIR.mkdir(exist_ok=True)\n",
        "PATCH_SIZE  = 704\n",
        "ALPHA       = 0.4\n",
        "\n",
        "# 1) carica dati\n",
        "full      = pd.read_csv(\"good_holes.csv\")           # ⬅️ creato dopo quality.csv\n",
        "angles    = pd.read_csv(\"ang_check.csv\").set_index('hole_id')['best_angle_deg'] if Path(\"ang_check.csv\").exists() else {}\n",
        "opt_full  = cv2.imread(OPTICAL_FULL_PATH)\n",
        "rad_full  = cv2.imread(NDT_FULL_PATH, 0)\n",
        "hO, wO    = opt_full.shape[:2]\n",
        "\n",
        "# 2) opzionale: dizionario H_loc salvati durante la cella 12\n",
        "#    se non l'hai salvato, ricomputalo al volo con la stessa logica\n",
        "H_loc_dict = {}   # {hole_id: H_loc}\n",
        "\n",
        "for _, r in tqdm(full.iterrows(), total=len(full), desc=\"patch\"):\n",
        "    hid = int(r.hole_id)\n",
        "    # --- H da usare --------------------\n",
        "    if r.chosen == \"LOCAL\":\n",
        "        H_use = H_loc_dict.get(hid, H_glob)   # fallback safetynet\n",
        "    else:\n",
        "        H_use = H_glob\n",
        "\n",
        "    # --- warp e crop -------------------\n",
        "    rad_warp = cv2.warpPerspective(rad_full, H_use, (wO, hO))\n",
        "    cx, cy   = int(r.optical_x), int(r.optical_y)\n",
        "    opt_p    = crop(opt_full, cx, cy, PATCH_SIZE)\n",
        "    rad_p    = crop(rad_warp, cx, cy, PATCH_SIZE)\n",
        "\n",
        "    # --- rotazione fine ----------------\n",
        "    ang = angles.get(hid, 0.0)\n",
        "    if abs(ang) > 0.1:\n",
        "        M = cv2.getRotationMatrix2D((PATCH_SIZE/2, PATCH_SIZE/2), ang, 1.0)\n",
        "        rad_p = cv2.warpAffine(rad_p, M, (PATCH_SIZE, PATCH_SIZE),\n",
        "                               flags=cv2.INTER_LINEAR,\n",
        "                               borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
        "\n",
        "    # --- salva -------------------------\n",
        "    cv2.imwrite(str(PATCH_DIR/f\"{hid:03d}_opt.png\"), opt_p)\n",
        "    cv2.imwrite(str(PATCH_DIR/f\"{hid:03d}_msk.png\"), rad_p)\n",
        "    # >>> GARANZIA SHAPE <<< ---------------------------------\n",
        "    if rad_p.shape[:2] != opt_p.shape[:2]:\n",
        "      print(f\"⚠️  {hid:03d}   mismatch {rad_p.shape} vs {opt_p.shape}\")\n",
        "      h,w   = opt_p.shape[:2]\n",
        "      rad_p = cv2.resize(rad_p, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "    rad_bgr = cv2.cvtColor(rad_p, cv2.COLOR_GRAY2BGR)\n",
        "    ovl = cv2.addWeighted(opt_p, 1-ALPHA,\n",
        "                          cv2.cvtColor(rad_p, cv2.COLOR_GRAY2BGR),\n",
        "                          ALPHA, 0)\n",
        "    cv2.imwrite(str(PATCH_DIR/f\"{hid:03d}_ovl.png\"), ovl)\n",
        "\n",
        "# 3) zip\n",
        "zip_path = \"/content/patches_unet_ready.zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    for p in PATCH_DIR.glob(\"*.png\"):\n",
        "        zf.write(p, p.name)\n",
        "\n",
        "print(\"✔ Patch pronte e zip create:\", zip_path)\n"
      ],
      "metadata": {
        "id": "zba53UnwJZ83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% FULL‑SCAN OVERLAY – una sola riga di output\n",
        "# ①  warp dell’intera radiografia con l’omografia scelta\n",
        "rad_full_warp = cv2.warpPerspective(rad_full, H_glob, (wO, hO))\n",
        "\n",
        "# ②  alpha‑blend: 60 % ottica + 40 % radio colore (colormap JET o bordi Canny)\n",
        "rad_color = cv2.applyColorMap(\n",
        "               cv2.normalize(rad_full_warp, None, 0, 255, cv2.NORM_MINMAX)\n",
        "               .astype(\"uint8\"),\n",
        "               cv2.COLORMAP_JET)\n",
        "full_overlay = cv2.addWeighted(opt_full, 0.6, rad_color, 0.4, 0)\n",
        "\n",
        "# ③  salva il PNG\n",
        "cv2.imwrite(\"/content/full_scan_overlay.png\", full_overlay)\n",
        "print(\"✅ full_scan_overlay.png creato\")\n"
      ],
      "metadata": {
        "id": "z9aVM3SOS-cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "aggiustamento visivo omografia"
      ],
      "metadata": {
        "id": "n4VHvvXoU7Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calcola shift locale usando H_glob già stimata\n",
        "#Se vedi due blocchi con errori diversi (sinistra bassa, destra alta) ⇒ prova una omografia per metà pannello (vedi punto 3).\n",
        "#\n",
        "#Se l’errore cresce gradualmente lungo X o Y ⇒ hai una componente affine non modellata (scala non uniforme).\n",
        "# calcola shift_glob UNA volta\n",
        "err=[]\n",
        "for _,r in coord_df.iterrows():\n",
        "    est = (H_glob @ [r.ndt_x, r.ndt_y, 1]).ravel(); est/=est[2]\n",
        "    err.append(np.hypot(est[0]-r.optical_x, est[1]-r.optical_y))\n",
        "coord_df['shift_glob']=err\n",
        "\n",
        "pivot = coord_df.pivot(index='optical_y', columns='optical_x',\n",
        "                       values='shift_glob')\n",
        "mat = pivot.sort_index(ascending=False).values  # capovolgi y\n",
        "\n",
        "plt.imshow(mat, cmap='magma_r', vmax=10, aspect='auto')\n",
        "plt.colorbar(label='shift [px]')\n",
        "plt.title(\"Heat‑map errore H_glob\"); plt.show()\n"
      ],
      "metadata": {
        "id": "UoUvK48-UiJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| colore (con `magma_r`) | shift (px) | lettura pratica                                                 |\n",
        "| ---------------------- | ---------- | --------------------------------------------------------------- |\n",
        "| chiaro / giallo        | ≈ 0 – 2    | allineamento ottimo                                             |\n",
        "| arancio                | 3 – 7      | piccoli errori, micro‑refine o H\\_loc li risolve                |\n",
        "| rosso‑scuro            | 8 – 15     | H\\_glob non basta, serve H\\_loc (o sotto‑pannello)              |\n",
        "| quasi nero (cappuccio) | > 15       | punti chiaramente fuori (scansione doppia, csv invertito, ecc.) |\n",
        "\n",
        "Pattern a blocchi (sinistra buona, destra cattiva) → calcola\n",
        "due H_glob (pannelli).\n",
        "\n",
        "Gradiente regolare (da sinistra a destra) → scala non uniforme: prova cv2.getAffineTransform locale o aumenta n_neighbors.\n",
        "\n",
        "Sporadici punti rossi → tienili in fallback GLOBAL e usa il micro‑refine."
      ],
      "metadata": {
        "id": "Hdhg39-5oKhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(coord_df.ndt_x, coord_df.ndt_y, s=5, label='NDT')\n",
        "plt.scatter(coord_df.optical_x, coord_df.optical_y, s=5, label='Optical')\n",
        "plt.gca().invert_yaxis(); plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "qqfi5eJXU1Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check allineamento per via di omografia problematica"
      ],
      "metadata": {
        "id": "3zA09WliqA6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NDT rows:\", len(ndt_df), \"Optical rows:\", len(opt_df))\n",
        "#Se i numeri differiscono, non stai comparando le stesse entità.\n",
        "merged = opt_df.merge(ndt_df, on='hole_idx', how='inner')\n",
        "print(\"buchi in comune:\", len(merged))\n",
        "#Se “buchi in comune” è ≪ 64 vuol dire che alcuni ID mancano da una parte."
      ],
      "metadata": {
        "id": "wskGuwasqFdW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}