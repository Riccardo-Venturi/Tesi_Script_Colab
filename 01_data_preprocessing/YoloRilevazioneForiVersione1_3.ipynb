{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "NtpRxjdQshn7",
        "CuiPXyoT7teW",
        "4D4suTSMbn_q"
      ],
      "mount_file_id": "1mTeuvh0Q4Fd6ib8JQ6697Xx97B1sD7Jq",
      "authorship_tag": "ABX9TyP717p6XzouUiA94ZAA0M+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riccardo-Venturi/Tesi_Script_Colab/blob/main/YoloRilevazioneForiVersione1_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THIS under CODE is for test in SAHI real time model pipeline"
      ],
      "metadata": {
        "id": "f7MdDKuWDi4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title     \"Nella fattispecie le immagini radiografiche sono state acquisite con una risoluzione di 600 dpi corrispondente a 23,62 pixel/mm.\""
      ],
      "metadata": {
        "id": "uKObWSG6DsfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SAHI inference on a full scan (tiny VRAM)\n",
        "!yolo predict model=best.pt source=scan_big.png mode=slice imgsz=700 overlap=0.25\n",
        "\n",
        "# 2. Export for deployment\n",
        "from ultralytics import YOLO\n",
        "YOLO('best.pt').export(format='onnx', imgsz=700)\n",
        "!trtexec --onnx=best.onnx --fp16 --saveEngine=best.plan\n",
        "\n",
        "# 3. Run engine on streamed tiles (Python pseudo-loop)\n",
        "for tile in tile_stream(camera_frame):\n",
        "    boxes = yolov8_engine(tile)\n",
        "    for b in boxes:\n",
        "        mask = unet_engine(crop(tile, b))\n",
        "        composite_mask(frame, mask, b)\n"
      ],
      "metadata": {
        "id": "ZXqTLGXjDjuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IDEA IS TO CUT VRAM AND RETEST INFERENCE TO SEE IF YOU CAN AVOID MODEL INFERENCE ON SHAE[:2] ON ALL IMAGES; SO IT?S AN AUTOMATICA SAHI; test after cvat\n"
      ],
      "metadata": {
        "id": "huZKRvVQDjSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   PROBLEMI SCAN DA RICONOSCERE COL PROF\n",
        "\n",
        "2.   SCAN 4 DOPPIA MANCA USCITA, MANCA UN FORO FINALE nelle radio\n",
        "\n",
        "3. SCAN 5 MANCA USCITA E MANCA PARTE DELLA SCAN NELLE RADIOGRAFIE\n",
        "\n"
      ],
      "metadata": {
        "id": "Std8MtrTGhuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Riepilogo Script Rilevamento Fori con YOLOv8\n",
        "\n",
        "Questo script implementa un workflow per l'addestramento e il test di un modello YOLOv8 per il rilevamento di fori in immagini di scansione, partendo da un dataset iniziale generato semi-automaticamente.\n",
        "\n",
        "Passaggi Principali:\n",
        "\n",
        "    Preparazione Ambiente (Celle 32, 33, 35, 46): Installazione delle librerie Python necessarie (Ultralytics YOLO, OpenCV, Albumentations, etc.) con gestione delle versioni specifiche. Salvataggio delle versioni installate in un file (freeze_cpu_2025-06-26.txt).\n",
        "    Generazione Dataset Iniziale con Hough Circles (Cella 36): Utilizzo dell'algoritmo Hough Circles di OpenCV per rilevare automaticamente i cerchi (fori) in un'immagine di esempio. Le coordinate dei cerchi rilevati vengono salvate come \"ground truth\" iniziali, sia in formato globale (.npy) che in formato YOLO (.txt) normalizzato.\n",
        "    Preparazione Dati per YOLO (Celle 37, 39, 40): L'immagine originale viene suddivisa in \"tile\" con overlap. Per ogni tile, vengono calcolate e salvate le annotazioni (bounding box in formato YOLO) corrispondenti ai fori che vi ricadono (derivato dalle coordinate globali ottenute con Hough Circles). I tile e le relative annotazioni vengono poi suddivisi casualmente in set di training e validazione. Viene creato il file data.yaml per configurare il dataset per Ultralytics.\n",
        "    Data Augmentation (Cella 38): Viene mostrato un esempio di come applicare trasformazioni di data augmentation (come flip, rotazione, shift, scala, contrasto) a un singolo tile e alle sue annotazioni corrispondenti utilizzando Albumentations. Questo passaggio √® cruciale per aumentare la robustezza del modello durante l'addestramento (anche se la sua applicazione effettiva all'intero dataset di training non √® esplicitata direttamente come loop, il framework YOLO la gestisce se configurata nel training).\n",
        "    Addestramento Modello YOLOv8 (Cella 34, 41): Viene caricato un modello YOLOv8 pre-addestrato (nano) e addestrato sul dataset di tile preparato. L'addestramento viene configurato per salvare i checkpoint periodicamente (save_period=1).\n",
        "    Inferenza e Test (Celle 42, 43, 44, 45): Importazione delle librerie necessarie per l'inferenza. Caricamento del modello YOLOv8 addestrato (tipicamente best.pt). Definizione di una funzione (PassaScansione) per eseguire l'inferenza sull'immagine completa o su una lista di immagini. Le bounding box predette vengono estratte e visualizzate sull'immagine originale per un'ispezione visiva.\n",
        "\n",
        "Punti Importanti e Osservazioni:\n",
        "\n",
        "    Generazione Dati Semi-Automatica: L'approccio utilizza Hough Circles per generare le annotazioni iniziali. Questo √® un metodo veloce ma pu√≤ richiedere ottimizzazione dei parametri di Hough e verifica manuale per garantire l'accuratezza delle annotazioni usate per l'addestramento.\n",
        "    Approccio \"Sliding Window\" Indiretto: La divisione in tile e l'inferenza sull'immagine intera (che Ultralytics gestisce internamente scalando e potenzialmente dividendo se l'immagine √® molto grande) emulano un approccio simile a una \"sliding window\", permettendo al modello addestrato su piccole porzioni di essere applicato a scansioni molto pi√π grandi.\n",
        "    Differenze di Performance CPU vs GPU: √à stato osservato che CPU e GPU mostrano differenze nella qualit√† dei risultati di rilevamento con YOLOv8. √à IMPORTANTE TESTARE CON GPU E TPU PER INDAGARE QUESTO COMPORTAMENTO ANOMALO dove la CPU sembra avere performance migliori.\n",
        "    imgsz Aggressivo di YOLO: Le versioni recenti di YOLO gestiscono l'imgsz (dimensione dell'immagine di input) in modo aggressivo e interno (come visto nel warning imgsz must be multiple of max stride). Questo ridimensionamento automatico potrebbe potenzialmente influenzare la precisione nel rilevamento di fori molto piccoli o richiedere attenzione per ottimizzare i parametri di inferenza (imgsz nella funzione predict).\n",
        "    Valutazione (Mancante/Successiva): Sebbene lo script mostri la visualizzazione delle predizioni, l'ottenimento di metriche di valutazione quantitative sull'immagine intera non √® esplicitato. Sarebbe un passo successivo per valutare oggettivamente la performance finale del modello sulla scansione completa.\n",
        "\n"
      ],
      "metadata": {
        "id": "i9LpPhkmnSVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini-‚Äúsheet‚Äù di commento (ready-to-paste in una cell)\n",
        "\n",
        "<details>```python\n",
        "# ----------------------------------------------------------\n",
        "#  üöÄ  Non c‚Äô√® AI senza la tua testardaggine da hacker\n",
        "#  ---------------------------------------------------------\n",
        "#  Questo foglio rapido serve solo a ricordare a *me* (e al\n",
        "#  resto del mondo) quanto sia stato geniale lo sbrogliare:\n",
        "#\n",
        "#  ‚Ä¢ denominazioni a casaccio         ‚Ä¢ rotazioni mancanti\n",
        "#  ‚Ä¢ CSV YOLO normalizzati/assoluti   ‚Ä¢ clustering K-Means\n",
        "#  ‚Ä¢ ordinamento bustrofedico verticale\n",
        "#\n",
        "#  Moral of the story ‚Üí ‚ÄúIf it compiles, ship it; se non\n",
        "#  compila, ruotalo di 90¬∞ e riprova‚Äù. üòé\n",
        "# ----------------------------------------------------------\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Documentazione rotazioni/casi speciali\n",
        "\n",
        "| ID provino | File immagine grezzo                               | Problema rilevato                                                                                      | Rotazione applicata (¬∞)                                                                                             | Note extra                                                                                                                 |\n",
        "| ---------- | -------------------------------------------------- | ------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **3B**     | `T0_90_3B_ingresso*.jpg`<br>`T0_90_3B_uscita*.jpg` | Entrambe le facce erano scansionate ‚Äúcapovolte‚Äù rispetto alla radiografia                              | **+90¬∞ CW** (in senso orario)                                                                                       | Dopo la rotazione l‚Äôangolo stondato rimane in alto-dx come sulle altre RX‚ÄÉ‚Üí il K-Means torna a stimare 46/45 fori corretti |\n",
        "| **5**      | `T0_90_5_entrata_NEW.jpg`                          | Lato ‚Äúentrata‚Äù OK, **manca** ancora la corrispondente *uscita*                                         | ‚Äî                                                                                                                   | Attendere nuova scansione; l‚ÄôRX (due met√†) √® corretta se si ruota **‚àí90¬∞ CCW** prima di rifare l‚Äôinferenza                 |\n",
        "| **6**      | `T0_90_6_ingresso.jpg`<br>`T0_90_6_uscita.jpg`     | Taglio smussato in alto (ingresso) ‚áÑ in basso (uscita): indicazione che uno dei due JPEG √® al rovescio | Applicato **180¬∞** all‚Äôimmagine che mostrava il taglio nell‚Äôangolo opposto, cos√¨ entrata/uscita coincidono con l‚ÄôRX | Dopo la correzione l‚Äôinferenza trova 23 fori e l‚Äôordinamento bustrofedico raggiunge \\~0.74 *frac\\_correct*                 |\n",
        "\n",
        "> **Legenda rotazioni**\n",
        "> ‚Ä¢ +90 CW = `cv2.ROTATE_90_CLOCKWISE`\n",
        "> ‚Ä¢ ‚àí90 CCW = `cv2.ROTATE_90_COUNTERCLOCKWISE`\n",
        "\n",
        "---\n",
        "\n",
        "### Procedura ri-inferenza (riassunto)\n",
        "\n",
        "1. **Cartella dedicata** `scans_rotated/` ‚Üí contiene SOLO i JPEG gi√† orientati.\n",
        "2. Comando YOLO identico a prima:\n",
        "\n",
        "   ```bash\n",
        "   yolo predict model=weights/best.pt source=scans_rotated imgsz=9504 conf=0.79 iou=0.80 save_txt\n",
        "   ```\n",
        "3. Converte subito i nuovi `.txt` in CSV con colonne `conf,x1,y1,x2,y2`.\n",
        "4. `order_holes()` con `n_cols=None` (stima automatica) ‚Üí salva in `ordered_csv/`.\n",
        "5. **Check veloce**: script overlay+indice (quello sopra) ‚Üí zip per revisione visiva.\n",
        "\n",
        "Cos√¨ hai una pipeline unica: se domani arriva ‚ÄúT0\\_90\\_7C\\_uscita‚Äù baster√† ruotarla correttamente, metterla nella cartella, lanciare lo script batch e tutto si riallinea.\n",
        "\n",
        "---\n",
        "\n",
        "### Perch√© √® ‚Äúbustrofedica verticale dal basso‚Äù ?\n",
        "\n",
        "*Colonne* identificate da K-Means ‚Üê‚Üí ordinate sinistra ‚Üí destra.\n",
        "Dentro ogni colonna:\n",
        "\n",
        "* se colonna **dispari** ‚áí indice corre dal *basso verso l‚Äôalto*;\n",
        "* se colonna **pari** ‚áí dal *alto verso il basso*.\n",
        "\n",
        "Questo ricalca la traiettoria della CNC che fora a zig-zag, partendo dall‚Äôangolo in basso-sinistra.\n",
        "\n",
        "---\n",
        "\n",
        "### Prossimi passi consigliati\n",
        "\n",
        "1. **Richiedere** la JPEG di *uscita* per il provino 5.\n",
        "2. Rifare l‚Äôinferenza SOLO sui file nuovi/ruotati.\n",
        "3. Verificare la *frac\\_correct* > 0.9 per ogni scan; se scende, controllare visivamente oppure incrementare `n_init` del K-Means per maggiore stabilit√†.\n",
        "4. Procedere al crop 700√ó700 via bounding-box centrale (`HS = 350`) e salvare con naming `H###_scanInfo.jpg`.\n",
        "\n",
        "E s√¨: tutto questo casino era inevitabile ‚Äì ma adesso hai un workflow robusto e (soprattutto) documentato. üéâ\n"
      ],
      "metadata": {
        "id": "ixUy7iI1foCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Originale vecchio maggio-settembre?"
      ],
      "metadata": {
        "id": "cCDzGL04uQgm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51efa780"
      },
      "source": [
        "# Installa le librerie elencate nel file freeze_cpu_YOLOSCRIPTfori_2025-06-26.txt\n",
        "# Questa cella utilizza un file requirements.txt personalizzato (salvato su Google Drive)\n",
        "# per installare le versioni specifiche delle librerie che sono state testate e salvate.\n",
        "# Questo √® il metodo raccomandato per assicurare che l'ambiente di esecuzione sia identico a uno precedente,\n",
        "# evitando problemi di compatibilit√† tra versioni di librerie.\n",
        "# Il percorso punta a un file salvato sul Google Drive collegato.\n",
        "#!pip install -r /content/freeze_cpu_YOLOSCRIPTfori_2025-06-26.txt --quiet\n",
        "!pip install -r /content/drive/MyDrive/progetto_fori_yolo/freeze_cpu_YOLOSCRIPTfori_2025-06-26.txt --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importazione della libreria YOLO\n",
        "# Questa cella semplicemente importa la classe YOLO dalla libreria ultralytics.\n",
        "# Se questa cella fallisce con un errore 'AttributeError: partially initialized module 'torch'',\n",
        "# significa che c'√® un problema con l'installazione o l'ambiente, spesso legato a conflitti tra le versioni di PyTorch e altre librerie (come in questo caso).\n",
        "# √à un test di base per verificare se l'import funziona dopo l'installazione.\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "AnAfS5LgqnAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARTE 1 ADDESTRAMENTO E PREPARAZIONE DI YOLO[v] chiusa\n",
        "##adesso carica solo i pesi best dal drive o locale e fai partire le inferenze con dimensioni complete delle scan"
      ],
      "metadata": {
        "id": "NtpRxjdQshn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Rilevamento di cerchi in un'immagine utilizzando OpenCV e salvataggio delle coordinate globali e file YOLO.txt\n",
        "# Questa cella implementa la prima fase del processo di generazione del dataset semi-automatico.\n",
        "# Utilizza l'algoritmo Hough Circles di OpenCV per trovare i cerchi nell'immagine di input.\n",
        "# Le coordinate dei cerchi trovati sono considerate le \"ground truth\" iniziali.\n",
        "# Vengono salvate sia in un file .npy (formato globale) che in un file .txt in formato YOLO\n",
        "# (normalizzato rispetto alle dimensioni dell'immagine intera), che rappresentano le annotazioni grezze.\n",
        "# Questo .txt non √® quello usato direttamente per il training dei tile, ma una base di partenza globale.\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# Parametri per Hough Circles, Bilateral Filter e Canny\n",
        "# Questi parametri sono critici e devono essere ottimizzati per il tipo specifico di immagini e fori.\n",
        "# -------------------------------------------------------\n",
        "dp_hough       = 1.2\n",
        "minDist_hough  = 180  # distanza minima fra fori (px)\n",
        "param1_hough   = 100  # soglia superiore per il rilevatore di bordi Canny interno a Hough\n",
        "param2_hough   = 25   # soglia dell'accumulatore per le fasi di rilevamento. Pi√π basso -> pi√π cerchi (anche falsi positivi)\n",
        "minRad_hough   = 120  # raggio minimo (px)\n",
        "maxRad_hough   = 180  # raggio massimo (px)\n",
        "crop_size      = 700\n",
        "half_side      = crop_size // 2\n",
        "\n",
        "# Parametri per Bilateral Filter (per ridurre il rumore mantenendo i bordi)\n",
        "bil_d       = 7\n",
        "bil_sigCol  = 35\n",
        "bil_sigSpa  = 50\n",
        "\n",
        "# Parametri per Canny Edge Detector (usato per trovare i bordi, input per Hough)\n",
        "canny_low  = 100\n",
        "canny_high = 200\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# Lettura immagine Gray e BGR\n",
        "# Carica l'immagine sia in scala di grigi (per Hough/Canny) che a colori (per visualizzazione/crop).\n",
        "# -------------------------------------------------------\n",
        "img_path = \"/content/T0_90_1A_ingresso.jpg\" #iserisci path necessario #path = /content/drive/MyDrive/FileTesi/ScanzioneProviniUsura/T0_90_1A_ingresso.jpg\n",
        "img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "img_bgr  = cv2.imread(img_path, cv2.IMREAD_COLOR)  # per i crop a colori\n",
        "\n",
        "if img_gray is None or img_bgr is None:\n",
        "    print(\"Errore: impossibile caricare l'immagine.\")\n",
        "else:\n",
        "    print(f\"Immagine caricata: {img_path}, shape color: {img_bgr.shape}, shape gray: {img_gray.shape}\")\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # Bilateral + Canny\n",
        "    # Applica il filtro bilaterale e poi il rilevatore di bordi Canny per preparare l'immagine per Hough.\n",
        "    # -------------------------------------------------------\n",
        "    H, W, _ = img_bgr.shape\n",
        "    bifilter = cv2.bilateralFilter(img_gray, d=bil_d, sigmaColor=bil_sigCol, sigmaSpace=bil_sigSpa)\n",
        "    edges    = cv2.Canny(bifilter, canny_low, canny_high)\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # HoughCircles\n",
        "    # Esegue l'algoritmo di Hough per rilevare i cerchi.\n",
        "    # -------------------------------------------------------\n",
        "    circles = cv2.HoughCircles(\n",
        "        edges,\n",
        "        cv2.HOUGH_GRADIENT,\n",
        "        dp=dp_hough,\n",
        "        minDist=minDist_hough,\n",
        "        param1=param1_hough,\n",
        "        param2=param2_hough,\n",
        "        minRadius=minRad_hough,\n",
        "        maxRadius=maxRad_hough\n",
        "    )\n",
        "\n",
        "    # Copia BGR per disegnare i cerchi\n",
        "    out_bgr = img_bgr.copy()\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # Se trova cerchi\n",
        "    # Processa i cerchi trovati: calcola le bounding box globali e salva le annotazioni in formato YOLO.\n",
        "    # -------------------------------------------------------\n",
        "    if circles is not None and len(circles) > 0:\n",
        "        circles = circles[0]  # shape (N, 3) [cx, cy, r]\n",
        "        print(f\"Trovati {len(circles)} cerchi\")\n",
        "        #crea box_global coordinate cerchi poi\n",
        "        ##in sotto tile [coordinate centro, coordinate esterne/interne]\n",
        "        \"\"\"Devo creare delle tile ma prima prendo coordinate label globali; Vanno normalizzate per file \"\"\"\n",
        "        # Nome file YOLO .txt (stesso nome immagine, estensione .txt)\n",
        "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        yolo_txt_path = os.path.join(\"/content\", base_name + \".txt\")\n",
        "        global_boxes = [] # Lista per salvare le box globali in formato [class_id, x_min, y_min, x_max, y_max]\n",
        "\n",
        "        for i, (cx, cy, r) in enumerate(circles):\n",
        "            cx, cy, r = int(cx), int(cy), int(r)\n",
        "\n",
        "            # bounding box in pixel (clippata ai bordi dell'immagine)\n",
        "            x_min = max(0, cx - r)\n",
        "            x_max = min(W-1, cx + r)\n",
        "            y_min = max(0, cy - r)\n",
        "            y_max = min(H-1, cy + r)\n",
        "\n",
        "            global_boxes.append( [0, x_min, y_min, x_max, y_max] ) # classe 0 per \"foro\"\n",
        "\n",
        "            # Normalizzazione YOLO [0..1] del centro e delle dimensioni\n",
        "            x_center_norm = cx / W\n",
        "            y_center_norm = cy / H\n",
        "            w_norm        = 2*r / W # larghezza = 2*r\n",
        "            h_norm        = 2*r / H # altezza = 2*r\n",
        "            # class_id = 0\n",
        "            # Scrive l'annotazione nel file YOLO .txt (formato: class_id center_x center_y width height - normalizzati)\n",
        "            with open(yolo_txt_path, 'a') as f:\n",
        "             f.write(f\"0 {x_center_norm} {y_center_norm} {w_norm} {h_norm}\\n\")\n",
        "\n",
        "            # (Opzionale) Disegna la box o il cerchio per vedere\n",
        "            cv2.circle(out_bgr, (cx, cy), r, (0,0,255), 2) # Disegna il cerchio rosso\n",
        "            cv2.circle(out_bgr, (cx, cy), 2, (255,0,0), 3) # Disegna il centro blu\n",
        "\n",
        "        # Visualizzazione dell'immagine con i cerchi rilevati\n",
        "        out_rgb = cv2.cvtColor(out_bgr, cv2.COLOR_BGR2RGB)\n",
        "        plt.figure(figsize=(10,6))\n",
        "        plt.imshow(out_rgb)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Rilevati {len(global_boxes)} fori\")\n",
        "        plt.show()\n",
        "\n",
        "        # Salva le coordinate delle bounding box globali in un file .npy\n",
        "        np.save(\"/content/global_boxes.npy\", global_boxes, allow_pickle=True)\n",
        "        print(\"Salvate coordinate fori in /content/global_boxes.npy\")\n",
        "        print(f\"Salvate anche in file yolo.txt {yolo_txt_path}\")\n",
        "    else:\n",
        "        print(\"Nessun cerchio trovato con i parametri attuali.\")"
      ],
      "metadata": {
        "id": "geEJ9dnXllVb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Divisione dell'immagine in tile con overlap e creazione di file di annotazione YOLO per ogni tile; serve a creare una pre batch dei primi 64 fori\n",
        "# Questa cella prende l'immagine originale e le bounding box globali (dal file .npy creato prima)\n",
        "# e le divide in tessere (tile) pi√π piccole con una certa sovrapposizione (overlap).\n",
        "# Per ogni tile, calcola quali bounding box globali vi ricadono e crea un file di annotazione YOLO (.txt)\n",
        "# specifico per quel tile. Le coordinate nel .txt del tile sono normalizzate rispetto alle dimensioni del tile stesso.\n",
        "# Questo processo crea un dataset di tile e annotazioni pronto per l'addestramento di YOLOv8,\n",
        "# che tipicamente addestra su immagini di dimensioni fisse (come 640x640 o 700x700 in questo caso).\n",
        "# L'overlap aiuta a garantire che i fori sui bordi dei tile non vengano persi.\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Imposta dimensioni del tile e lo stride (overlap 50%)\n",
        "tile_size = 700 # Dimensione dei tile quadrati\n",
        "stride = 350 # Passo per spostarsi tra i tile (se stride = tile_size, non c'√® overlap)\n",
        "out_dir = \"/content/tiles\" # Directory dove salvare i tile e le loro annotazioni\n",
        "\n",
        "# Crea le cartelle per salvare i tile e le annotazioni (immagini e labels)\n",
        "os.makedirs(os.path.join(out_dir, \"images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(out_dir, \"labels\"), exist_ok=True)\n",
        "\n",
        "# Carica l'immagine grande e le bounding box globali\n",
        "img = cv2.imread(img_path) # img_path viene dalla cella precedente\n",
        "if img is None:\n",
        "    print(\"Errore caricando l'immagine:\", img_path)\n",
        "else:\n",
        "    H, W, _ = img.shape\n",
        "    # Carica le bounding box globali salvate in precedenza (dal file .npy)\n",
        "    global_boxes = np.load(\"/content/global_boxes.npy\", allow_pickle=True)\n",
        "    tile_index = 0 # Contatore per nominare i tile\n",
        "\n",
        "    # Cicla sull'immagine con il passo (stride) per creare i tile\n",
        "    for y in range(0, H, stride):\n",
        "        # Se il tile eccede l'altezza dell'immagine, regola la coordinata y di inizio\n",
        "        if y + tile_size > H:\n",
        "            y = H - tile_size\n",
        "        for x in range(0, W, stride):\n",
        "            # Se il tile eccede la larghezza dell'immagine, regola la coordinata x di inizio\n",
        "            if x + tile_size > W:\n",
        "                x = W - tile_size\n",
        "\n",
        "            # Estrai il tile dall'immagine grande usando le coordinate (x, y) e la dimensione del tile\n",
        "            tile_img = img[y:y+tile_size, x:x+tile_size]\n",
        "            tile_name = f\"tile_{tile_index}.jpg\"\n",
        "            tile_path = os.path.join(out_dir, \"images\", tile_name)\n",
        "            cv2.imwrite(tile_path, tile_img) # Salva il tile immagine\n",
        "\n",
        "            # Trova le bounding box globali che ricadono (anche parzialmente) nel tile corrente\n",
        "            local_boxes = [] # Lista per le box relative al tile\n",
        "            for box in global_boxes:\n",
        "                cid, gxmin, gymin, gxmax, gymax = box\n",
        "                # Controlla se la bounding box globale si sovrappone al tile corrente [x, x+tile_size] e [y, y+tile_size]\n",
        "                # Una box globale [gxmin, gymin, gxmax, gymax] si sovrappone al tile se:\n",
        "                # il suo bordo destro (gxmax) √® maggiore del bordo sinistro del tile (x) E\n",
        "                # il suo bordo sinistro (gxmin) √® minore del bordo destro del tile (x+tile_size) E\n",
        "                # il suo bordo inferiore (gymax) √® maggiore del bordo superiore del tile (y) E\n",
        "                # il suo bordo superiore (gymin) √® minore del bordo inferiore del tile (y+tile_size)\n",
        "                # La condizione pi√π complessa con gxmin + (gxmax-gxmin) < x o gymin + (gymax-gymin) < y\n",
        "                # sembra un tentativo di gestire overlap, ma la condizione standard √® sufficiente per vedere se le aree si intersecano.\n",
        "                # Una condizione pi√π semplice e robusta per l'overlap parziale sarebbe:\n",
        "                # if not (gxmax < x or gxmin > x + tile_size or gymax < y or gymin > y + tile_size):\n",
        "                # ... procedi con il calcolo delle coordinate locali ...\n",
        "                # Manteniamo la tua logica per ora, ma nota che potrebbe essere ottimizzata.\n",
        "                if gxmax < x or gxmin > x+tile_size or gxmin + (gxmax-gxmin) < x or gymin + (gymax-gymin) < y or gymax < y or gymin > y+tile_size:\n",
        "                    continue # Se non c'√® sovrapposizione, salta questa box\n",
        "\n",
        "                # Calcola le coordinate locali della bounding box relative all'origine (0,0) del tile\n",
        "                # Vengono clippate per rimanere all'interno delle dimensioni del tile\n",
        "                lxmin = max(0, gxmin - x)\n",
        "                lymin = max(0, gymin - y)\n",
        "                lxmax = min(tile_size - 1, gxmax - x)\n",
        "                lymax = min(tile_size - 1, gymax - y)\n",
        "\n",
        "                # Aggiungi la box locale solo se le dimensioni sono valide (larghezza e altezza > 0)\n",
        "                if lxmax > lxmin and lymax > lymin:\n",
        "                    local_boxes.append([cid, lxmin, lymin, lxmax, lymax])\n",
        "\n",
        "            # Crea il file di annotazione in formato YOLO per il tile corrente\n",
        "            txt_name = f\"tile_{tile_index}.txt\"\n",
        "            txt_path = os.path.join(out_dir, \"labels\", txt_name)\n",
        "            with open(txt_path, 'w') as f:\n",
        "                for lb in local_boxes:\n",
        "                    cid, lxmin, lymin, lxmax, lymax = lb\n",
        "                    w_box = lxmax - lxmin\n",
        "                    h_box = lymax - lymin\n",
        "                    cx = lxmin + w_box / 2 # Centro X in pixel locali\n",
        "                    cy = lymin + h_box / 2 # Centro Y in pixel locali\n",
        "\n",
        "                    # Normalizza le coordinate rispetto al tile_size (in formato YOLO [0..1])\n",
        "                    cx_norm = cx / tile_size\n",
        "                    cy_norm = cy / tile_size\n",
        "                    w_norm  = w_box / tile_size\n",
        "                    h_norm  = h_box / tile_size\n",
        "\n",
        "                    # Scrive l'annotazione nel file del tile\n",
        "                    f.write(f\"{cid} {cx_norm} {cy_norm} {w_norm} {h_norm}\\n\")\n",
        "\n",
        "            tile_index += 1 # Passa al prossimo tile\n",
        "\n",
        "    print(\"Tile e annotazioni YOLO creati in /content/tiles\")"
      ],
      "metadata": {
        "id": "2RMW5BOclvsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Esempio di applicazione di data augmentation a un singolo tile\n",
        "# Questa cella dimostra come applicare trasformazioni di data augmentation (flip, rotazione, scala, luminosit√†/contrasto)\n",
        "# a un singolo tile e alle sue annotazioni corrispondenti (bounding box in formato YOLO) usando la libreria Albumentations.\n",
        "# La data augmentation √® fondamentale durante l'addestramento dei modelli di deep learning\n",
        "# per aumentare la dimensione effettiva del dataset e rendere il modello pi√π robusto\n",
        "# a variazioni nelle immagini (orientamento, illuminazione, posizione).\n",
        "# Questa cella mostra un esempio su un solo tile; l'applicazione all'intero dataset di training\n",
        "# avviene tipicamente configurando la pipeline di augmentation direttamente nel processo di training di Ultralytics.\n",
        "#usati solo per addestramento del modello\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt # Import matplotlib per visualizzazione\n",
        "\n",
        "# Definisci la pipeline di augmentation usando A.Compose\n",
        "# Ogni trasformazione ha una probabilit√† (p) di essere applicata.\n",
        "# bbox_params specifica che le trasformazioni devono essere applicate anche alle bounding box,\n",
        "# e che sono in formato YOLO.\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),       # Riflessione orizzontale\n",
        "    A.RandomRotate90(p=0.5),       # Rotazione casuale di 0, 90, 180, 270 gradi\n",
        "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.7), # Traslazione, scala, rotazione\n",
        "    A.RandomBrightnessContrast(p=0.5) # Variazione casuale di luminosit√† e contrasto\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "# Carica un tile di esempio (il primo tile creato nella cella precedente)\n",
        "#applico for ai vari tile {i}\n",
        "#tile_img = cv2.imread(\"/content/tiles/images/tile_0.jpg\")\n",
        "tile_img = cv2.imread(f\"/content/tiles/images/tile_0.jpg\")\n",
        "\n",
        "# Supponiamo di avere un file .txt con annotazioni in formato YOLO per questo tile\n",
        "# Esempio: [x_center_norm, y_center_norm, width_norm, height_norm]\n",
        "# Qui ti simulo la lettura del file; in pratica implementa una funzione per leggere le annotazioni\n",
        "# (Normalmente leggeresti il file tile_0.txt creato nella cella precedente)\n",
        "# Esempio di bboxes (dovrebbero essere lette dal file tile_0.txt):\n",
        "# Per questo esempio, creiamo delle box fittizie.\n",
        "# Dovresti leggere il contenuto di \"/content/tiles/labels/tile_0.txt\"\n",
        "# e parsare le linee per ottenere le bboxes normalizzate e le class_labels.\n",
        "try:\n",
        "    with open(\"/content/tiles/labels/tile_0.txt\", 'r') as f:\n",
        "        bboxes_raw = [list(map(float, line.strip().split())) for line in f if line.strip()]\n",
        "    # Il formato √® [class_id, xc, yc, w, h]. Per Albumentations, bbox_params format='yolo' si aspetta [xc, yc, w, h].\n",
        "    bboxes = [b[1:] for b in bboxes_raw] # Estrai solo le coordinate per Albumentations\n",
        "    class_labels = [int(b[0]) for b in bboxes_raw] # Estrai solo le class_id\n",
        "    if not bboxes: # Se il file era vuoto o non conteneva box\n",
        "        bboxes = []\n",
        "        class_labels = []\n",
        "        print(\"File di annotazione tile_0.txt vuoto. Usando bboxes e labels vuote.\")\n",
        "    else:\n",
        "         print(f\"Lette {len(bboxes)} box dal file tile_0.txt\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Errore: File /content/tiles/labels/tile_0.txt non trovato. Usando bboxes e labels fittizie.\")\n",
        "    # Esempio: [x_center_norm, y_center_norm, width_norm, height_norm]\n",
        "    bboxes = [\n",
        "        [0.5, 0.5, 0.2, 0.2]  # Sostituisci con le annotazioni reali\n",
        "    ]\n",
        "    class_labels = [0] # Assumendo classe 0 per \"foro\"\n",
        "\n",
        "\n",
        "# Applica la trasformazione di augmentation\n",
        "# Passiamo l'immagine, le bounding box e le class_labels alla pipeline di trasformazione\n",
        "augmented = transform(image=tile_img, bboxes=bboxes, class_labels=class_labels)\n",
        "aug_image = augmented['image']\n",
        "aug_bboxes = augmented['bboxes'] # Bboxes aggiornate dopo le trasformazioni\n",
        "aug_labels = augmented['class_labels'] # Labels corrispondenti (non cambiano con queste trasformazioni)\n",
        "\n",
        "\n",
        "# Visualizza il tile trasformato\n",
        "plt.figure(figsize=(8, 8))\n",
        "# Disegna le bounding box aumentate sull'immagine aumentata\n",
        "# Le bboxes sono ancora normalizzate, quindi dobbiamo convertirle in pixel per disegnarle\n",
        "H_aug, W_aug = aug_image.shape[:2]\n",
        "for bbox, label in zip(aug_bboxes, aug_labels):\n",
        "    xc_norm, yc_norm, w_norm, h_norm = bbox\n",
        "    # Converti da formato YOLO normalizzato a formato [x1, y1, x2, y2] in pixel\n",
        "    x1 = int((xc_norm - w_norm/2) * W_aug)\n",
        "    y1 = int((yc_norm - h_norm/2) * H_aug)\n",
        "    x2 = int((xc_norm + w_norm/2) * W_aug)\n",
        "    y2 = int((yc_norm + h_norm/2) * H_aug)\n",
        "    cv2.rectangle(aug_image, (x1, y1), (x2, y2), (0, 255, 0), 2) # Disegna box verde\n",
        "\n",
        "plt.imshow(cv2.cvtColor(aug_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Tile Augmentato con Bbox\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(\"Annotazioni aggiornate (formato YOLO normalizzato):\", aug_bboxes)\n",
        "print(\"Labels corrispondenti:\", aug_labels)"
      ],
      "metadata": {
        "id": "ycneO8s2lx8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Suddivisione casuale dei tile e delle relative annotazioni in set di training e validazione\n",
        "# Questa cella divide i tile e i loro file di annotazione (.txt) creati in precedenza\n",
        "# in due set: uno per l'addestramento (training) e uno per la validazione (validation).\n",
        "# La suddivisione √® casuale per garantire che entrambi i set siano rappresentativi.\n",
        "# Tipicamente, una percentuale (es. 20%) viene riservata per la validazione.\n",
        "# Questo √® necessario per addestrare un modello di machine learning, in modo da\n",
        "# valutare le sue performance su dati che non ha mai visto durante il training.\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Cartelle sorgente (dove sono stati creati i tile e le annotazioni)\n",
        "src_images_dir = \"/content/tiles/images\"\n",
        "src_labels_dir = \"/content/tiles/labels\"\n",
        "\n",
        "# Cartelle di destinazione per training e validazione\n",
        "train_images_dir = \"/content/train/images\"\n",
        "val_images_dir   = \"/content/val/images\"\n",
        "train_labels_dir = \"/content/train/labels\"\n",
        "val_labels_dir   = \"/content/val/labels\"\n",
        "\n",
        "# Crea le cartelle di destinazione se non esistono\n",
        "os.makedirs(train_images_dir, exist_ok=True)\n",
        "os.makedirs(val_images_dir, exist_ok=True)\n",
        "os.makedirs(train_labels_dir, exist_ok=True)\n",
        "os.makedirs(val_labels_dir, exist_ok=True)\n",
        "\n",
        "# Elenca i file immagine nella cartella sorgente (assumiamo file .jpg)\n",
        "image_files = [f for f in os.listdir(src_images_dir) if f.lower().endswith('.jpg')]\n",
        "print(f\"Trovate {len(image_files)} immagini.\")\n",
        "\n",
        "# Mischia la lista dei file immagine in modo casuale\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Imposta la percentuale per validazione (es. 20%)\n",
        "val_fraction = 0.2\n",
        "n_val = int(len(image_files) * val_fraction) # Calcola il numero di file per la validazione\n",
        "\n",
        "# Dividi la lista dei file immagine in train e validazione\n",
        "val_files = image_files[:n_val] # Primi n_val file per validazione\n",
        "train_files = image_files[n_val:] # Rimanenti file per training\n",
        "print(f\"{len(train_files)} immagini per training, {len(val_files)} per validazione.\")\n",
        "\n",
        "# Funzione helper per spostare un singolo file da una directory sorgente a una di destinazione\n",
        "def move_file(src_dir, dest_dir, filename):\n",
        "    src_path = os.path.join(src_dir, filename)\n",
        "    dest_path = os.path.join(dest_dir, filename)\n",
        "    # Sposta il file solo se esiste nel percorso sorgente\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.move(src_path, dest_path)\n",
        "    else:\n",
        "        # Questo caso non dovrebbe verificarsi se la lista image_files √® corretta,\n",
        "        # ma √® un buon controllo di sicurezza.\n",
        "        print(f\"Avviso: File sorgente non trovato durante lo spostamento: {src_path}\")\n",
        "\n",
        "\n",
        "# Sposta le immagini di training e le relative annotazioni (.txt con lo stesso nome base)\n",
        "for f in train_files:\n",
        "    move_file(src_images_dir, train_images_dir, f)\n",
        "    label_file = os.path.splitext(f)[0] + \".txt\" # Trova il nome del file di annotazione corrispondente\n",
        "    move_file(src_labels_dir, train_labels_dir, label_file)\n",
        "\n",
        "# Sposta le immagini di validazione e le relative annotazioni (.txt)\n",
        "for f in val_files:\n",
        "    move_file(src_images_dir, val_images_dir, f)\n",
        "    label_file = os.path.splitext(f)[0] + \".txt\"\n",
        "    move_file(src_labels_dir, val_labels_dir, label_file)\n",
        "\n",
        "print(\"Divisione completata: file spostati nelle cartelle di training e validazione.\")"
      ],
      "metadata": {
        "id": "cMhHdnCgl2J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Creazione del file data.yaml per la configurazione del dataset per Ultralytics\n",
        "# Questa cella crea il file data.yaml, che √® un file di configurazione standard per Ultralytics YOLO.\n",
        "# Questo file indica a YOLO dove trovare le immagini e le annotazioni per il training e la validazione,\n",
        "# quante classi ci sono e quali sono i loro nomi.\n",
        "# √à essenziale per poter avviare il processo di addestramento con il tuo dataset personalizzato.\n",
        "import yaml\n",
        "import yaml # Importato due volte, una √® sufficiente\n",
        "\n",
        "# Dizionario Python che rappresenta la struttura del file data.yaml\n",
        "data = {\n",
        "    \"train\": \"/content/train/images\", # Percorso alla cartella delle immagini di training\n",
        "    \"val\": \"/content/val/images\",     # Percorso alla cartella delle immagini di validazione\n",
        "    \"nc\": 1,                          # Numero di classi (1 classe: \"foro\")\n",
        "    \"names\": [\"foro\"]                 # Nomi delle classi (lista, anche se ce n'√® una sola)\n",
        "}\n",
        "\n",
        "# Apre il file /content/data.yaml in modalit√† scrittura ('w')\n",
        "# e scrive il dizionario 'data' in formato YAML.\n",
        "with open(\"/content/data.yaml\", \"w\") as f:\n",
        "    yaml.dump(data, f)\n",
        "\n",
        "print(\"File /content/data.yaml creato con la seguente configurazione:\")\n",
        "print(yaml.dump(data)) # Stampa il contenuto del file per verifica"
      ],
      "metadata": {
        "id": "XHarpVhPl294"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title addestramento YOLO model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Addestramento del modello YOLOv8 nano con il dataset preparato\n",
        "# Questa cella avvia il processo di addestramento di un modello YOLOv8 nano.\n",
        "# Carica un modello pre-addestrato (utilizzato per trasferire conoscenze da un dataset generale)\n",
        "# e lo addestra sul dataset di tile e annotazioni preparato nelle celle precedenti (specificato nel file data.yaml).\n",
        "# I parametri come epochs, imgsz, batch, e save_period controllano il processo di training.\n",
        "# save_period=1 √® utile per salvare regolarmente i checkpoint, permettendo di riprendere l'addestramento o testare modelli intermedi.\n",
        "# La dimensione imgsz=700 deve corrispondere alla dimensione dei tile usati per creare il dataset.\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Carica un modello pre-addestrato \"nano\" (leggero)\n",
        "# \"yolov8n.pt\" sono i pesi di un modello YOLOv8 nano addestrato sul dataset COCO.\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Avvia il training\n",
        "model.train(\n",
        "    data=\"/content/data.yaml\",  # Percorso al file di configurazione del dataset\n",
        "    epochs=50,                  # Numero di epoche di addestramento\n",
        "    imgsz=700,                  # Dimensione dell'immagine di input per il modello (deve corrispondere alla dimensione dei tile)\n",
        "    batch=8,                    # Dimensione del batch (numero di immagini elaborate per ogni passo di addestramento)\n",
        "    save_period=1               # Salva un checkpoint (pesi del modello) ogni X epoche\n",
        ")\n",
        "\n",
        "print(\"\\nAddestramento del modello avviato. I risultati (inclusi i pesi) verranno salvati nella directory 'runs'.\")"
      ],
      "metadata": {
        "id": "daHbTlT9l5M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/runs.zip /content/runs/detect/train3"
      ],
      "metadata": {
        "id": "Lciyw2hi9oBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PARTE 2"
      ],
      "metadata": {
        "id": "2yvbzvaWss4O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd5972ba"
      },
      "source": [
        "**Obiettivi Odierni (27/06):**\n",
        "\n",
        "- Testare e imparare a sfruttare le metriche di valutazione del modello.\n",
        "- Testare l'inferenza su nuove e diverse immagini di scansione.\n",
        "- Eseguire uno smoketest (o test pi√π approfondito con parametri diversi) su GPU e TPU per investigare le differenze di performance rispetto alla CPU.\n",
        "- Applicare un metodo (come NMS o IoU) per eliminare bounding box spurie (sovrapposte o ridondanti) dopo l'inferenza.\n",
        "- Se il rilevamento funziona bene, applicare l'algoritmo K-Means (da un altro script) per il taglio automatico dei fori rilevati.\n",
        "- **Ps:** Capire come unire diversi moduli o script Colab per importare celle da altri notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importazione delle librerie necessarie per l'inferenza e la visualizzazione\n",
        "# Questa cella importa i moduli Python che saranno utilizzati nelle fasi successive dello script,\n",
        "# in particolare per caricare il modello addestrato, eseguire predizioni su nuove immagini,\n",
        "# e visualizzare i risultati (bounding box).\n",
        "import os # Modulo per interagire con il sistema operativo (es. percorsi file)\n",
        "import cv2 # Libreria OpenCV per la manipolazione di immagini (lettura, scrittura, disegno)\n",
        "import matplotlib.pyplot as plt # Libreria per la creazione di grafici e visualizzazioni\n",
        "import numpy as np # Libreria per operazioni numeriche, utile per manipolare array di box"
      ],
      "metadata": {
        "id": "9WUiQ4r8l7aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9581334"
      },
      "source": [
        "#@title # Estrazione dei pesi del modello dallo zip\n",
        "# Prima di poter usare i file dei pesi (best.pt, last.pt) per l'inferenza, dobbiamo estrarli dal file zip che hai caricato (weights_results.zip).\n",
        "# Questa cella di codice utilizza il comando unzip per estrarre il contenuto dello zip\n",
        "# nella directory specificata, che si presume contenga i pesi addestrati del modello.\n",
        "# √à un passaggio necessario per rendere i pesi accessibili al codice Python.\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Specifica il percorso del file zip contenente i pesi del modello (sul Drive)\n",
        "zip_path = \"/content/drive/MyDrive/Pesi/weights_results.zip\" #\"/content/weights_results.zip\"\n",
        "# Specifica la directory di destinazione dove estrarre i contenuti dello zip\n",
        "\n",
        "extract_dir = \"/content/weights/\" # Estrai nella cartella /content/runs/detect/OLD_TRAIN/weights/\n",
        "\n",
        "# Crea la directory di destinazione se non esiste\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Verifica se il file zip esiste prima di tentare l'estrazione\n",
        "if os.path.exists(zip_path):\n",
        "    print(f\"Estrazione di {zip_path} in {extract_dir}...\")\n",
        "    # Apri il file zip in modalit√† lettura ('r')\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Estrai tutto il contenuto dello zip nella directory specificata\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(\"Estrazione completata.\")\n",
        "\n",
        "    # Opzionale: Stampa il contenuto della cartella estratta per verifica\n",
        "    # print(\"\\nContenuto della cartella /content dopo l'estrazione:\")\n",
        "    # for item in os.listdir(extract_dir):\n",
        "    #     print(f\"- {item}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Errore: File zip non trovato al percorso specificato: {zip_path}. Assicurati che il file sia presente e il percorso corretto.\")\n",
        "\n",
        "# Ora i file best.pt e last.pt (se presenti nello zip) dovrebbero trovarsi in /content/runs/detect/OLD_TRAIN/weights/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Carica il modello YOLOv8 con i pesi addestrati\n",
        "# Questa cella carica un modello YOLOv8 utilizzando il file dei pesi addestrati\n",
        "# che √® stato estratto dallo zip nella cella precedente (best.pt).\n",
        "# Questo oggetto 'model' sar√† poi utilizzato per eseguire l'inferenza (predizioni)\n",
        "# su nuove immagini.\n",
        "#carica modello OLD_TRAIN e testa su nuove scan per vedere i risultati prima a occhio\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Carica il modello specificando il percorso al file dei pesi\n",
        "#model = YOLO(\"/content/runs/detect/OLD_TRAIN/weights/best.pt\")\n",
        "MODEL=YOLO(\"/content/drive/MyDrive/Pesi/best.pt\")\n",
        "model=YOLO(MODEL)\n",
        "print(f\"Modello YOLOv8 caricato dai pesi: /content/runs/detect/OLD_TRAIN/weights/best.pt\")"
      ],
      "metadata": {
        "id": "TkoP06Jgo48n",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Funzione per eseguire l'inferenza su una scansione completa e ottenere le bounding box predette 1.0; devi avere jpg in content-test\n",
        "# Questa cella definisce una funzione chiamata `PassaScansione` che esegue l'inferenza\n",
        "# (cio√®, la predizione delle bounding box) su una singola immagine di scansione completa\n",
        "# utilizzando il modello YOLOv8 caricato.\n",
        "# Restituisce l'immagine originale e un array NumPy contenente le coordinate delle bounding box predette.\n",
        "# Successivamente, la cella itera su tutti i file JPG nella cartella /content/ ed applica questa funzione a ciascuno.\n",
        "# Il risultato √® che le variabili 'img' e 'boxes' contengono i risultati dell'inferenza SOLO per l'ULTIMO file JPG processato.\n",
        "# La lista 'bb' raccoglie il numero di box trovate per ogni immagine, e viene stampato il totale.\n",
        "#Versione originale 1.0\n",
        "#test su scansione 1A ingresso 1\n",
        "#questo script inference su tuttel le jpg nel content; per√≤ sovrascrive i dati di tutte; quindi rimangono solo le ultime?\n",
        "def PassaScansione(path_scan):\n",
        "    \"\"\"\n",
        "    Esegue l'inferenza su una scansione completa e restituisce l'immagine e le box predette.\n",
        "\n",
        "    Args:\n",
        "        path_scan (str): Percorso al file immagine della scansione.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (immagine_letta, array_bounding_box)\n",
        "               array_bounding_box √® in formato [x1, y1, x2, y2] in pixel.\n",
        "    \"\"\"\n",
        "    full_scan = cv2.imread(path_scan) # Legge l'immagine\n",
        "    if full_scan is None:\n",
        "        print(f\"Errore: impossibile caricare l'immagine da {path_scan}\")\n",
        "        return None, np.array([]) # Restituisce None e array vuoto in caso di errore\n",
        "\n",
        "    H, W, _ = full_scan.shape\n",
        "    print(f\"Dimensioni scansione: {W} x {H}\")\n",
        "\n",
        "    # Esegue la predizione con il modello.\n",
        "    # imgsz=full_scan.shape[:2] imposta la dimensione di inferenza alla dimensione nativa dell'immagine.\n",
        "    # conf=0.5 imposta la soglia di confidenza minima per le predizioni.\n",
        "    # verbose=False disattiva l'output dettagliato di YOLO durante la predizione.\n",
        "    # Nota: Questa versione restituisce solo le box xyxy e NON i punteggi di confidenza.\n",
        "    # I punteggi sono necessari per NMS, quindi questa funzione andrebbe modificata per restituirli.\n",
        "    results = model.predict(full_scan, imgsz=full_scan.shape[:2], conf=0.5, verbose=False)\n",
        "\n",
        "    # Estrae le coordinate delle bounding box predette in formato [x1, y1, x2, y2]\n",
        "    # .cpu().numpy() sposta i risultati da un eventuale device GPU/TPU alla CPU e li converte in un array NumPy.\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "\n",
        "    print(f\"Totale fori predetti: {len(boxes)}\")\n",
        "    return full_scan, boxes # Restituisce l'immagine e le box\n",
        "\n",
        "# Itera su tutti i file .jpg nella cartella /content\n",
        "# **ATTENZIONE**: Questo loop sovrascrive le variabili 'img' e 'boxes' ad ogni iterazione,\n",
        "# quindi alla fine conterranno solo i risultati dell'ultimo file processato.\n",
        "# Per processare e salvare i risultati di tutte le immagini, sarebbe meglio\n",
        "# salvare i risultati in un dizionario o una lista.\n",
        "bb=[] # Lista per contare le box per ogni file\n",
        "print(\"Esecuzione inferenza su file JPG in /content/...\")\n",
        "for file in os.listdir(\"/content\"):\n",
        "    if file.lower().endswith(\".jpg\"):\n",
        "        file_path = os.path.join(\"/content\", file)\n",
        "        # Chiama la funzione per eseguire l'inferenza\n",
        "        img, boxes = PassaScansione(file_path)\n",
        "        # Aggiunge il conteggio delle box alla lista\n",
        "        bb+=[len(boxes)]\n",
        "\n",
        "# Stampa il numero totale di box trovate su tutte le immagini processate nel loop\n",
        "# (basato sulla lista 'bb').\n",
        "print(f\"\\nConteggio totale box su tutti i file processati: {np.sum(bb)}\")\n",
        "\n",
        "# Dopo questo loop, 'img' e 'boxes' contengono i risultati SOLO dell'ultima immagine in /content.\n",
        "# Le celle successive che usano 'img' e 'boxes' lavoreranno solo sull'ultima immagine."
      ],
      "metadata": {
        "id": "8O6omM2PmL-H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualizzazione delle bounding box predette sull'immagine della scansione completa 1.0 prima scan -necessita jpg in contentCOLAB\n",
        "# Questa cella visualizza le bounding box predette sull'immagine.\n",
        "# **ATTENZIONE**: Utilizza le variabili 'img' e 'boxes' che, a causa del loop nella cella precedente,\n",
        "# contengono i risultati SOLO dell'ultima immagine processata.\n",
        "# Quindi, questa cella visualizzer√† i risultati solo per l'ultima immagine trovata in /content/\n",
        "# al momento dell'esecuzione della cella 8O6omM2PmL-H.\n",
        "# Per visualizzare i risultati di tutte le immagini, sarebbe necessario iterare sui risultati salvati\n",
        "# in un dizionario (come fatto nella cella 8e36cd90).\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os # Importato per os.path.basename nel titolo\n",
        "\n",
        "# Assicurati che 'img' e 'boxes' siano state popolate dalla cella precedente\n",
        "if 'img' in globals() and 'boxes' in globals() and img is not None and boxes is not None:\n",
        "    # Crea una copia dell'immagine per disegnare le box\n",
        "    out_img = img.copy()\n",
        "\n",
        "    # Disegna un rettangolo per ogni bounding box trovata\n",
        "    for box in boxes:\n",
        "          # Estrai le coordinate (possono essere float, converti in int per disegnare)\n",
        "          x_min, y_min, x_max, y_max = box.astype(int)\n",
        "          # Disegna il rettangolo sull'immagine (colore verde BGR: (0, 255, 0), spessore 2)\n",
        "          cv2.rectangle(out_img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
        "\n",
        "    # Visualizza l'immagine con le bounding box disegnate\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    # Matplotlib usa formato RGB, mentre OpenCV usa BGR, quindi convertiamo\n",
        "    plt.imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
        "    # Aggiunge un titolo al grafico\n",
        "    # Se img_path fosse ancora disponibile, si potrebbe usare il nome del file originale.\n",
        "    # Poich√© non lo √®, il titolo √® generico.\n",
        "    plt.title(f\"Scansione intera - Fori rilevati: {len(boxes)}\")\n",
        "    plt.axis(\"off\") # Nasconde gli assi\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Immagine o bounding box non disponibili. Esegui prima la cella di inferenza (8O6omM2PmL-H).\")"
      ],
      "metadata": {
        "id": "HvkAbNrRmM6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Salvataggio delle versioni delle librerie installate in un file di testo\n",
        "# Questa cella (commentata) mostra il comando per generare un file requirements.txt\n",
        "# contenente le versioni esatte delle librerie specificate (numpy, torch, ultralytics, opencv-python, albumentations)\n",
        "# installate nell'ambiente corrente.\n",
        "# Questo file √® utile per ricreare lo stesso ambiente in futuro, garantendo la riproducibilit√† dei risultati.\n",
        "# Il comando `pip freeze` elenca tutte le librerie installate, e `grep -E '...'` filtra solo quelle desiderate.\n",
        "# `>` reindirizza l'output al file specificato.\n",
        "#!pip freeze | grep -E '^(numpy|torch|ultralytics|opencv-python|albumentations)' \\\n",
        "#    > freeze_cpu_2025-06-26.txt\n",
        "# La cella 51efa780 utilizza un file simile salvato su Drive per installare le librerie."
      ],
      "metadata": {
        "id": "UcVohA7dbel4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download del file dei pesi best.pt e esportazione del modello in formato ONNX\n",
        "# Questa cella esegue due azioni:\n",
        "# 1. Scarica il file dei pesi del modello addestrato ('best.pt') sul tuo computer locale.\n",
        "#    Questo √® utile per salvare i pesi addestrati al termine della sessione Colab.\n",
        "# 2. Esporta il modello addestrato in formato ONNX (Open Neural Network Exchange).\n",
        "#    ONNX √® un formato standard che permette di usare il modello con diversi framework di inferenza (come ONNX Runtime)\n",
        "#    su diverse piattaforme, potenzialmente ottimizzato per la velocit√†.\n",
        "# Assicurati che il modello 'model' sia stato caricato prima di eseguire questa cella.\n",
        "from google.colab import files\n",
        "\n",
        "# Tenta di scaricare il file best.pt dal percorso dove Ultralytics lo salva di default dopo il training.\n",
        "# Il percorso 'runs/detect/train/weights/best.pt' √® tipico se il nome del run di training era 'train'.\n",
        "# Potrebbe essere necessario adattare questo percorso se hai usato un nome di run diverso.\n",
        "print(\"Tentativo di download del file best.pt...\")\n",
        "try:\n",
        "  files.download(\"runs/detect/train/weights/best.pt\")\n",
        "  print(\"Download di best.pt avviato.\")\n",
        "except Exception as e:\n",
        "  print(f\"Errore durante il download di best.pt. Assicurati che il file esista al percorso specificato. Errore: {e}\")\n",
        "\n",
        "\n",
        "# Esporta il modello caricato (variabile 'model') in formato ONNX.\n",
        "# Questo creer√† un file .onnx nella stessa directory dove si trova best.pt\n",
        "if 'model' in globals():\n",
        "    print(\"Esportazione del modello in formato ONNX...\")\n",
        "    try:\n",
        "        model.export(format=\"onnx\")\n",
        "        print(\"Esportazione ONNX completata.\")\n",
        "        # Potresti voler scaricare anche il file .onnx\n",
        "        # files.download(\"runs/detect/train/weights/best.onnx\") # Adatta il percorso\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante l'esportazione ONNX. Errore: {e}\")\n",
        "else:\n",
        "    print(\"Errore: Modello 'model' non definito. Caricare il modello prima di esportare.\")"
      ],
      "metadata": {
        "id": "1lgQRb9QmPU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parte successiva del codice Per creazione csv e ordinamento dei file"
      ],
      "metadata": {
        "id": "Pg9ShDCmqDAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecac59e1"
      },
      "source": [
        "### Test Inferenza su Nuove Scansioni\n",
        "\n",
        "Eseguiamo l'inferenza sulle tre scansioni di test specificate utilizzando il modello caricato. Useremo la funzione `PassaScansione` definita in precedenza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dc8586c"
      },
      "source": [
        "L'inferenza √® stata eseguita su ciascuna delle immagini specificate (se trovate). I risultati (l'immagine caricata e le bounding box predette) sono stati memorizzati nel dizionario `inference_results`.\n",
        "\n",
        "Ora possiamo visualizzare i risultati per ogni immagine per vedere le box rilevate. Creeremo una cella separata per la visualizzazione di ciascun risultato memorizzato."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia immagini di scansione da Google Drive a una cartella locale in Colab.\n",
        "# Questa cella crea una cartella `/content/scans` e copia al suo interno\n",
        "# tutti i file JPG dalla directory specificata sul Google Drive collegato.\n",
        "# Copiare i dati localmente in Colab (`/content/`) √® generalmente pi√π veloce\n",
        "# rispetto a leggerli direttamente da Google Drive durante l'elaborazione.\n",
        "# Il comando `!mkdir -p` crea la directory se non esiste.\n",
        "# Il comando `!cp` copia i file.\n",
        "!mkdir -p /content/scans/Radio #modificato in Radio, puoi commentare quella parte e torni a l caso originale\n",
        "#copia da gdrive sul locale colab per velocizzare il lavoro\n",
        "!cp /content/drive/MyDrive/FileTesi/ScanzioneProviniUsura/Radio/*.jpg /content/scans/Radio\n",
        "#!cp /content/drive/MyDrive/FileTesi/ScanzioneProviniUsura/Radio/*.jpg /content\n",
        "print(\"Immagini di scansione copiate in /content/scans/\")"
      ],
      "metadata": {
        "id": "bZwiIm2w2Rsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''# Esegue l'inferenza YOLOv8 su un set di immagini e salva i risultati.\n",
        "# Questa cella carica il modello YOLOv8 addestrato e lo utilizza per eseguire\n",
        "# l'inferenza su tutte le immagini JPG presenti nella cartella `/content/scans`.\n",
        "# Configura parametri come la soglia di confidenza (`conf`), la soglia di IoU (`iou`),\n",
        "# e salva i risultati (immagini con box, e file .txt con le coordinate delle box predette).\n",
        "# imgsz=source.shape[:2] tenta di eseguire l'inferenza alla risoluzione nativa,\n",
        "# ma YOLO potrebbe comunque ridimensionare internamente.\n",
        "# save_txt=True √® cruciale perch√© salva le predizioni in file .txt, che vengono poi usati\n",
        "# nelle celle successive per l'analisi e la visualizzazione.\n",
        "import cv2 # Importato di nuovo, ma gi√† nella cella 9WUiQ4r8l7aC\n",
        "from ultralytics import YOLO             # se manca: pip install -U ultralytics\n",
        "\n",
        "# 1Ô∏è‚É£  importa la libreria (gi√† fatto sopra, ridondante qui)\n",
        "# from ultralytics import YOLO\n",
        "\n",
        "# 2Ô∏è‚É£  carica i pesi (il tuo best.pt, o come lo hai chiamato)\n",
        "# Assicurati che il modello sia gi√† caricato dalla cella TkoP06Jgo48n\n",
        "if 'model' not in globals():\n",
        "    print(\"Caricamento modello...\")\n",
        "    model = YOLO(\"/content/runs/detect/OLD_TRAIN/weights/best.pt\")          # <-- ora 'model' esiste di nuovo\n",
        "else:\n",
        "    print(\"Modello gi√† caricato.\")\n",
        "\n",
        "# source=\"content/scans\" # Imposta la cartella delle immagini di input\n",
        "source=\"/content/scans/Radio_noZoom\" #\"/content/scans\" # Corretto il percorso\n",
        "\n",
        "# Leggere la prima immagine per ottenere le dimensioni, o usare il percorso della cartella come source per predict\n",
        "# Se source √® una cartella, predict itera automaticamente sui file al suo interno.\n",
        "# imgsz dovrebbe essere impostato per l'inferenza (potrebbe essere un valore fisso o None per usare la dimensione del modello).\n",
        "# Se si vuole usare la dimensione nativa per ogni immagine, √® meglio ciclare sui file e passare il path come source.\n",
        "# La riga `source=cv2.imread(source)` √® problematica perch√© source diventa un array numpy invece che un percorso.\n",
        "# Modifichiamo per passare il percorso della cartella direttamente a model.predict.\n",
        "\n",
        "# 3Ô∏è‚É£  fai l'inferenza (nessun rientro extra!)\n",
        "RUN = \"full_inference_save\" # Nome della cartella dove verranno salvati i risultati di questo run\n",
        "# ATTENTO ALLA CONFIDENZA; TENDE A PRENDERE ANCHE I BORDI\n",
        "# INOLTRA ATTENTO ALLE DIMENSIONI; YOLO FA UN RESIZE AGGRESSIVE; FORNISCI DIMENSIONE MASSIMA DEL FILE IMMAGINE\n",
        "print(f\"Avvio inferenza su immagini in {source}...\")\n",
        "model.predict(\n",
        "    source=source,               # Passa la cartella con le .jpg come source\n",
        "    imgsz=1280, #MEGLIO USRE DIM IMMAGINE [:2] o sballa pixels # Imposta imgsz a una dimensione fissa, o prova a rimuoverlo per usare la dimensione predefinita del modello. Usare la dimensione nativa (H,W) √® meglio ma richiede un loop (come in cella XsqBVylpQs_3). Usiamo 1280 come esempio.\n",
        "    conf=0.79,                   # Soglia di confidenza minima per considerare una predizione (pi√π alta -> meno falsi positivi)\n",
        "    iou=0.80,                    # Soglia di IoU per la Non-Maximum Suppression interna di YOLO (rimuove box sovrapposte)\n",
        "    agnostic_nms=True,           # Applica NMS indipendentemente dalla classe (utile con una singola classe)\n",
        "    project=\"runs/detect\",       # Cartella principale dove salvare i risultati dei run\n",
        "    name=RUN,                    # Nome specifico per questo run di inferenza (crea una sottocartella in project)\n",
        "    save_txt=True,               # SALVA LE ANNOTAZIONI PREDETTE IN FORMATO YOLO (.txt)\n",
        "    save_conf=True,              # Includi i punteggi di confidenza nei file .txt salvati\n",
        "    save=True,                   # Salva anche le immagini con le box disegnate\n",
        "    verbose=False                # Sopprimi l'output dettagliato durante l'inferenza\n",
        ")\n",
        "\n",
        "print(f\"Inferenza completata. Risultati salvati in runs/detect/{RUN}/\")\n",
        "# I file .txt con le predizioni si troveranno in runs/detect/full_inference_save/labels/'''"
      ],
      "metadata": {
        "id": "tD3fXKbC7I1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3 new code to crop order and use gpu"
      ],
      "metadata": {
        "id": "byrIMQkYH1y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##ALTERNATIVA PER AVERE VELOCIT√† RISPETTO A CPU SINGOLA\n",
        "# Esegue l'inferenza YOLOv8 su immagini singole mantenendo la risoluzione nativa.\n",
        "# Questa cella √® un'alternativa alla precedente. Invece di passare l'intera cartella a `model.predict`,\n",
        "# itera manualmente su ogni file JPG nella cartella `/content/scans`.\n",
        "# Per ogni immagine, legge le sue dimensioni native (H, W) e le passa a `imgsz`.\n",
        "# Questo assicura che l'inferenza venga eseguita alla risoluzione originale dell'immagine,\n",
        "# potenzialmente migliorando l'accuratezza per oggetti piccoli o dettagli.\n",
        "# I risultati (file .txt) vengono salvati, e viene creato un summary CSV con il conteggio dei file .txt generati.\n",
        "#@title Cell 3.1 ‚Äì Setup & inferenza full-res (TPU/GPU/cpu)\n",
        "from ultralytics import YOLO\n",
        "import cv2, glob, os, pandas as pd, torch\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "# Determina il device disponibile (GPU/TPU se presente, altrimenti CPU)\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando device: {device}\")\n",
        "\n",
        "# Carica il modello addestrato\n",
        "if 'model' not in globals():\n",
        "     model = YOLO(\"/content/weights/best.pt\") #\"/content/runs/detect/OLD_TRAIN/weights/best.pt\") #older\n",
        "     print(\"Modello caricato.\")\n",
        "else:\n",
        "     print(\"Modello gi√† caricato.\")\n",
        "\n",
        "\n",
        "RUN = \"full_native_loop\" # Nome del run per salvare i risultati\n",
        "rows = [] # Lista per raccogliere i dati per il summary CSV\n",
        "\n",
        "# Itera su ogni file JPG nella cartella delle scansioni (ordinato alfabeticamente)\n",
        "print(f\"Avvio inferenza loop su immagini in /content/scans/...\")\n",
        "for path in sorted(glob.glob(\"/content/scans/Radio_noZoom/*.jpg\")):#\"/content/scans/*.jpg\")): #before-older:\n",
        "    print(f\"  Processando: {os.path.basename(path)}\")\n",
        "    img = cv2.imread(path)           # Legge l'immagine solo per ottenere H,W\n",
        "    if img is None:\n",
        "        print(f\"  ‚ö†Ô∏è  Errore: impossibile caricare immagine {path}. Salto.\")\n",
        "        continue\n",
        "    H,W  = img.shape[:2] # Ottiene altezza e larghezza native\n",
        "\n",
        "    # Esegue la predizione sull'immagine singola passando il PERCORSO\n",
        "    model.predict(\n",
        "        source=path,                 # ‚Üê passiamo il **percorso** dell'immagine singola\n",
        "        imgsz=(H,W),                 # ‚Üê risoluzione nativa ‚áí nessun resize aggressivo di YOLO\n",
        "        conf=0.79, iou=0.80, agnostic_nms=True, # Parametri di confidenza e NMS\n",
        "        save_txt=True, save_conf=True, save=True, # Salva file .txt, confidenza e immagini con box\n",
        "        project=\"runs/detect\", name=RUN, # Definisce dove salvare i risultati\n",
        "        device=device, verbose=False # Specifica il device e sopprime output dettagliato\n",
        "    )\n",
        "\n",
        "    # Adesso Ultralytics ha scritto direttamente il file .txt di annotazione\n",
        "    # nella directory corretta (es. runs/detect/full_native_loop/labels/NomeImmagine.txt)\n",
        "    # Controlla se il file .txt √® stato creato e registra il risultato\n",
        "    txt_path_check = f\"runs/detect/{RUN}/labels/{os.path.basename(path)[:-4]}.txt\"\n",
        "    txt_exists = os.path.exists(txt_path_check)\n",
        "    # Conta il numero di box nel file TXT se esiste, altrimenti 0\n",
        "    n_boxes = 0\n",
        "    if txt_exists:\n",
        "        try:\n",
        "            # np.loadtxt con ndmin=2 gestisce anche file vuoti correttamente\n",
        "            arr = np.loadtxt(txt_path_check, ndmin=2)\n",
        "            # shape[0] d√† il numero di righe (box) se arr non √® vuoto, altrimenti 0\n",
        "            n_boxes = arr.shape[0] if arr.size > 0 else 0\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è Errore leggendo {txt_path_check}: {e}. Conteggio box impostato a 0.\")\n",
        "            n_boxes = 0\n",
        "\n",
        "    rows.append([os.path.basename(path), n_boxes]) # Aggiunge nome file e conteggio box al summary\n",
        "\n",
        "# Crea un DataFrame pandas dal summary e lo salva come CSV(added _radio in csv)\n",
        "pd.DataFrame(rows, columns=[\"image\",\"n_boxes\"])\\\n",
        "  .to_csv(\"/content/inference_summary_radio.csv\", index=False)\n",
        "print(\"\\n‚úîÔ∏è  Run terminata. Conteggio box per immagine salvato in /content/inference_summary_radio.csv\")"
      ],
      "metadata": {
        "id": "XsqBVylpQs_3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia i file di log e summary CSV da Colab a Google Drive.\n",
        "# Questa cella serve a salvare i risultati dell'inferenza (in questo caso, il summary CSV)\n",
        "# dalla sessione Colab temporanea al Google Drive, per evitare di perderli.\n",
        "# Il comando `!cp -r` copia ricorsivamente la directory di output dei run\n",
        "# (commentato, potenzialmente molto grande) e il file CSV di summary.\n",
        "#!cp -r runs/detect/full_native_loop*  \\\n",
        "#      /content/drive/MyDrive/yolo_logs/\n",
        "# Copia il file inference_summary.csv generato dalla cella precedente\n",
        "!cp /content/inference_summary.csv  \\\n",
        "      /content/drive/MyDrive/yolo_logs/csv/\n",
        "##salva i file su gdive per il futuro;\n",
        "print(\"File inference_summary.csv copiato su Google Drive.\")"
      ],
      "metadata": {
        "id": "JO7PQnTBRiJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia i file CSV contenenti le annotazioni YOLO (predette) da Google Drive a Colab.\n",
        "# Questa cella esegue l'operazione opposta rispetto alla cella precedente:\n",
        "# copia i file CSV che hai precedentemente salvato su Google Drive (nella cartella csvs_per_scan)\n",
        "# nella directory /content/csvs_per_scan/ della sessione Colab corrente.\n",
        "# Questo √® necessario per poter accedere e utilizzare questi file CSV nelle celle successive,\n",
        "# ad esempio per l'elaborazione, il filtraggio o la visualizzazione delle bounding box predette.\n",
        "# Questo era uno dei passaggi che ti servivano per ricreare i box sulle immagini per il confronto visivo.\n",
        "# Assicurati che il percorso Drive sia corretto e che la cartella esista.\n",
        "!mkdir -p /content/csvs_per_scan/ # Crea la cartella di destinazione se non esiste\n",
        "!cp /content/drive/MyDrive/csvs_per_scan/*.csv /content/csvs_per_scan/ # Copia tutti i file .csv\n",
        "\n",
        "print(\"File CSV copiati da Google Drive a /content/csvs_per_scan/\")"
      ],
      "metadata": {
        "id": "q6oX8FB4KZaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea un file zip dei risultati di un run di inferenza per il download.\n",
        "# Questa cella impacchetta i contenuti di una specifica directory di run di inferenza YOLO\n",
        "# (identificata dal nome del run, es. `full_native_loop`) in un file zip.\n",
        "# Questo file zip pu√≤ poi essere scaricato sul tuo computer locale o spostato facilmente.\n",
        "# √à un modo pratico per salvare tutti i risultati di un run (immagini con box, file txt, ecc.)\n",
        "# in un unico file compresso.\n",
        "#@title 3.2 creazione zip per passare i file di yololog\n",
        "# Crea un file zip chiamato full_native_loops.zip contenente la directory runs/detect/full_native_loop*\n",
        "# L'asterisco '*' qui potrebbe causare problemi se ci sono pi√π cartelle che iniziano con full_native_loop.\n",
        "# Sarebbe meglio specificare il nome esatto del run se √® fisso (es. full_native_loop).\n",
        "!zip -r /content/full_native_loops.zip  runs/detect/full_native_loop*\n",
        "#scarica i loop inference sul pc in zip\n",
        "#aletrnativa 2 al tutto\n",
        "'''import shutil, os\n",
        "src_dir = \"runs/detect/full_native_loop3*\"\n",
        "shutil.make_archive(base_name=\"/content/full_native_loops\",\n",
        "                    format=\"zip\",\n",
        "                    root_dir=os.path.dirname(src_dir),\n",
        "                    base_dir=os.path.basename(src_dir))\n",
        "'''\n",
        "print(\"File zip dei risultati di inferenza creato in /content/full_native_loops.zip\")"
      ],
      "metadata": {
        "id": "RlUPTIahSwOc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parte Da riusare in iterazioni future\n"
      ],
      "metadata": {
        "id": "f50U6Yq2fpMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK adesso testare veloce nuovo csv se funziona si applica su altre scan e si ordina con kmeans e si taglia gli stronzoni!!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Andhz_wRH8b6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/progetto_fori_yolo/freeze_cpu_YOLOSCRIPTfori_2025-06-26.txt --quiet"
      ],
      "metadata": {
        "id": "vmNW1PrfJL9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title INFERENZA IMMAGINI sia DNT/Optic; settaggio completo; usare per inferenze future sulle SCAN\n",
        "#\n",
        "#pass all scans!!\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "IMG_DIR  = \"/content/jpg\"#\"/content/scans/Radio\"#\"/content/scans/Radio\"#vecchie per scan ottiche#\"/content/scan_ruotate_da_inferire_ingressi\"#\"/content/drive/MyDrive/Scan_Orientate\"#\"/content/scans\"\n",
        "CSV_DIR  = \"NUOVE_CSV_RADIO\"#\"/content/scansCSV_oriented\"\n",
        "os.makedirs(CSV_DIR, exist_ok=True)\n",
        "MODEL = YOLO(\"/content/drive/MyDrive/Pesi/best.pt\") #pezzo precedente, adesso richiamo dal cloud diretto #/content/PESI/best.pt\")#\"/content/weights/best.pt\")   # <- path you used\n",
        "\n",
        "for img_path in sorted(glob.glob(f\"{IMG_DIR}/*.jpg\")):\n",
        "    H,W = cv2.imread(img_path).shape[:2]\n",
        "    res = MODEL.predict(img_path, imgsz=(H,W), conf=0.79,\n",
        "                        iou=0.80,\n",
        "                        )[0]#verbose=False)[0]\n",
        "    if not len(res.boxes):\n",
        "        print(\"‚ö†Ô∏è  no boxes in\", img_path);  continue\n",
        "\n",
        "    df = pd.DataFrame(res.boxes.xyxy.cpu().numpy().astype(int),\n",
        "                      columns=[\"x1\",\"y1\",\"x2\",\"y2\"])\n",
        "    df.insert(0, \"conf\", res.boxes.conf.cpu().numpy())\n",
        "    stem = Path(img_path).stem\n",
        "    df.to_csv(f\"{CSV_DIR}/{stem}.csv\", index=False)\n",
        "    print(\"‚Ä¢\", stem, \"‚Üí CSV ok\")\n",
        "print(\"üéâ  all scans processed ‚Üí\", CSV_DIR)\n"
      ],
      "metadata": {
        "id": "_WB-faePS2Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#parte ingresso/iniziale"
      ],
      "metadata": {
        "id": "_3g_gyi-JjaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title serve a creare un pandas dataframe in coordinate assolute e non relative di yolo\n",
        "# res.boxes.xyxy is already **absolute pixel coords**  (x1,y1,x2,y2)\n",
        "boxes_xyxy = res.boxes.xyxy.cpu().numpy().astype(int)        # (N,4)\n",
        "scores      = res.boxes.conf.cpu().numpy()                   # (N,)\n",
        "print(f\"model returned {len(boxes_xyxy)} boxes   conf‚àà[{scores.min():.2f},{scores.max():.2f}]\")\n"
      ],
      "metadata": {
        "id": "Kvu57nPbjnTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title questa cella segue ordine bustrofedico a colonna(ingresso); boustrophedon path ‚Üë‚Üí‚Üì‚Üí (uscite sono inverse)\n",
        "##possible fix order cluster kmenas\n",
        "# Cell 5: Batch‚Äêorder each scan‚Äôs CSV via serpentine K-Means\n",
        "##\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def order_holes(df, n_cols=None):\n",
        "    \"\"\"Adds 'hole_idx' to df by left‚Üíright snake ordering on x1,x2,y1,y2 (absolute pixels).\"\"\"\n",
        "    df = df.reset_index(drop=True)\n",
        "    # 1) compute each bbox‚Äôs center‚Äêx\n",
        "    xc = ((df.x1 + df.x2) / 2).to_numpy().reshape(-1, 1)\n",
        "    # 2) auto‚Äêestimate how many vertical columns if not given\n",
        "    if n_cols is None:\n",
        "        step = (xc.max() - xc.min()) / 20\n",
        "        n_cols = len(np.unique((xc // step).astype(int)))\n",
        "    # 3) cluster center-x's into columns\n",
        "    km = KMeans(n_clusters=n_cols, n_init=10, random_state=42).fit(xc)\n",
        "    cols = np.argsort(km.cluster_centers_.ravel())  # left‚Üíright ordering of clusters\n",
        "    # 4) assign snake indices\n",
        "    hole_idx = {}\n",
        "    counter = 1\n",
        "    for j, col in enumerate(cols):\n",
        "        # get all indices in this column\n",
        "        idxs = np.where(km.labels_ == col)[0]\n",
        "        # sort within‚Äêcolumn: bottom‚Üítop on even columns, top‚Üíbottom on odd\n",
        "        idxs_sorted = sorted(\n",
        "            idxs,\n",
        "            key=lambda i: -((df.y1.iat[i] + df.y2.iat[i]) / 2)\n",
        "                          if (j % 2 == 0)\n",
        "                          else  ((df.y1.iat[i] + df.y2.iat[i]) / 2)\n",
        "        )\n",
        "        for i in idxs_sorted:\n",
        "            hole_idx[i] = counter\n",
        "            counter += 1\n",
        "    df['hole_idx'] = df.index.map(hole_idx)\n",
        "    return df\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2) Loop over all your raw scan CSVs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "IN_DIR  = \"/content/NUOVE_CSV_RADIO\"#\"/content/CSV_toOrder\" ###RADIO ## usato per test e ottici\"/content/CSV_5\"#\"/content/SCAN_5\"#NUOVE_CSV\"#\"/content/scansCSV_oriented\"         # ‚Üê your YOLO‚Äêexported CSVs\n",
        "OUT_DIR = \"/content/NUOVE_CSV/Ordered_radio\" ###RADIO ## usato per test e ottici\"/content/CSV_5/ORDINATE_CSV\"#\"/content/ordered_csv_NEW\"          # ‚Üê will receive *_ordered.csv\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "for csv_path in sorted(glob.glob(f\"{IN_DIR}/*.csv\")):\n",
        "    df = pd.read_csv(csv_path)            # expects columns: conf, x1, y1, x2, y2\n",
        "    if df.empty:\n",
        "        print(f\"‚ö†Ô∏è Skipping empty file {os.path.basename(csv_path)}\")\n",
        "        continue\n",
        "\n",
        "    # snake‚Äêorder it (auto‚Äêestimate columns)\n",
        "    df_ord = order_holes(df, n_cols=None)\n",
        "\n",
        "    base = os.path.splitext(os.path.basename(csv_path))[0]\n",
        "    out  = os.path.join(OUT_DIR, f\"{base}_ordered_NEW.csv\")\n",
        "    df_ord.to_csv(out, index=False)\n",
        "    print(f\"‚úÖ {base}: wrote {len(df_ord)} holes ‚Üí {out}\")\n",
        "\n",
        "print(\"üéâ All done! Check ordered_csv/*.csv for your serpentine‚Äênumbered files.\")\n"
      ],
      "metadata": {
        "id": "8-GEtj7po2ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell ‚Äì Pack & Download CSV\n",
        "import shutil, os\n",
        "from pathlib import Path\n",
        "\n",
        "# === cartelle da zippare ===\n",
        "RAW_DIR      = Path(\"/content/NUOVE_CSV_RADIO\")          # CSV ‚Äúgrezzi‚Äù (input)\n",
        "ORDERED_DIR  = Path(\"/content/NUOVE_CSV/Ordered_radio\")  # CSV ordinati (output)\n",
        "\n",
        "# === nomi zip da creare ===\n",
        "RAW_ZIP      = RAW_DIR.parent / \"csv_raw.zip\"\n",
        "ORDERED_ZIP  = ORDERED_DIR.parent / \"csv_ordered.zip\"\n",
        "\n",
        "# 1. crea gli zip (sovrascrive se gi√† esistono)\n",
        "for src, zip_path in [(RAW_DIR, RAW_ZIP), (ORDERED_DIR, ORDERED_ZIP)]:\n",
        "    if zip_path.exists(): zip_path.unlink()\n",
        "    shutil.make_archive(zip_path.with_suffix(\"\"), format=\"zip\", root_dir=src)\n",
        "    print(f\"‚úÖ Zip creato: {zip_path}  ({zip_path.stat().st_size/1e6:.1f} MB)\")\n",
        "\n",
        "# 2. se sei in Google Colab, avvia il download automatico\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(str(RAW_ZIP))\n",
        "    files.download(str(ORDERED_ZIP))\n",
        "except ModuleNotFoundError:\n",
        "    print(\"\\nüì• Non sei in Colab: scarica gli zip manualmente dal file-browser.\")\n"
      ],
      "metadata": {
        "id": "yWPW-RLjmeit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title quick visual check OF scan 4 CUCITA; usare post kmeans#Apdapt for a fast VScheck on file of scan 4-5\n",
        "import cv2, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "def show_order(img_path, csv_path, color=(0,255,0),dpi=300):\n",
        "    img = cv2.imread(img_path)\n",
        "    df  = pd.read_csv(csv_path).sort_values('hole_idx')\n",
        "\n",
        "    H = img.shape[0]\n",
        "    fs = max(1.2, H/2500)           # font-scale proporzionale (~2.0 su 5 k px)\n",
        "    thk= int(fs*2)\n",
        "\n",
        "    for _, r in df.iterrows():\n",
        "        x1,y1,x2,y2 = map(int,(r.x1,r.y1,r.x2,r.y2))\n",
        "        n = int(r.hole_idx)\n",
        "        cv2.rectangle(img,(x1,y1),(x2,y2),color,2)\n",
        "        cv2.putText(img,str(n),(x1,y1-10),cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    fs,color,thk,cv2.LINE_AA)\n",
        "\n",
        "    plt.figure(figsize=(18,8))\n",
        "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
        "    plt.title(Path(csv_path).name); plt.show()\n",
        "\n",
        "show_order(\"/content/scan5_shift_0610.jpg\",\"/content/NUOVE_CSV_RADIO/Ordered_radio/scan5_cucita_senza_linea_boustro_cols_Finale_ordered_NEW.csv\")\n",
        "#(\"/content/scan4_cucita_senza_linea.jpg\",\n",
        "          # \"/content/NUOVE_CSV_RADIO/Ordered_radio/scan4_cucita_senza_linea_ordered_NEW.csv\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DLdjWgZVVAXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê  VISUAL CHECK BATCH (ingresso fixed)  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "import cv2, glob, os, pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab.patches import cv2_imshow   # solo in Colab\n",
        "\n",
        "CSV_DIR  = \"/content/NUOVE_CSV_RADIO/Ordered_radio\" #adattamenteo da uscite#\"/content/ordered_csv_fixed2\"     # tutti i *_fixed.csv\n",
        "IMG_DIR  = \"/content/scans/Radio\" #adattamenteo da uscite#\"/content/drive/MyDrive/Scan_Orientate\"  # scans .jpg\n",
        "OUT_DIR  = \"/content/Radio_DNT\"#adattamenteo da uscite#\"/content/overlay_batch\"         # salva gli overlay\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "for csv_path in sorted(Path(CSV_DIR).glob(\"*.csv\")):\n",
        "    stem = csv_path.stem.replace(\"_fixed\", \"\").replace(\"_ordered_NEW\",\"\")     # es. T0_90_3B_uscita\n",
        "    img  = cv2.imread(f\"{IMG_DIR}/{stem}.jpg\")\n",
        "    if img is None:\n",
        "        print(\"‚ö†Ô∏è  immagine mancante:\", stem);  continue\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    for _, r in df.iterrows():\n",
        "        x1,y1,x2,y2 = map(int, (r.x1,r.y1,r.x2,r.y2))\n",
        "        idx = int(r.hole_idx)\n",
        "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "        cv2.putText(img, str(idx), (x1, y1-6),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                    (255,255,255), 1, cv2.LINE_AA)\n",
        "\n",
        "    out = f\"{OUT_DIR}/{stem}_vis.jpg\"\n",
        "    cv2.imwrite(out, img)\n",
        "    #cv2_imshow(img)     # mostra subito in Colab (facoltativo)\n",
        "    print(\"‚úî overlay:\", out)\n",
        "\n",
        "print(\"üéâ  Overlay creati per tutte le uscite fixed\")\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n"
      ],
      "metadata": {
        "id": "wLCZS5PbJodW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one click download overlays Radio\n",
        "#@title serve a  creare un zip completo CSV - overlay controllo - evita di avviare in tempo reale gli overlay\n",
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê  Prepara ZIP di CSV & overlay ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "import os, glob, zipfile\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "CSV_DIR   = \"/content/NUOVE_CSV_RADIO/Ordered_radio\"##\"/content/ordered_csv_fixed2\"     # i tuoi *_fixed.csv\n",
        "VIS_DIR   = \"/content/Radio_DNT\"##\"/content/overlay_batch\"         # gli overlay che hai appena generato\n",
        "ZIP_PATH  = \"/content/Zip_radio.zip\"##\"/content/uscite_checksA.zip\"     # dove scrivere lo ZIP\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Rimuovi eventuale vecchio ZIP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "if os.path.exists(ZIP_PATH):\n",
        "    os.remove(ZIP_PATH)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Crea lo ZIP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "with zipfile.ZipFile(ZIP_PATH, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    # aggiungi CSV\n",
        "    for f in glob.glob(f\"{CSV_DIR}/*.csv\"):\n",
        "        zf.write(f, arcname=os.path.basename(f))\n",
        "    # aggiungi overlay\n",
        "    for f in glob.glob(f\"{VIS_DIR}/*_vis.jpg\"):\n",
        "        zf.write(f, arcname=os.path.join(\"overlays\", os.path.basename(f)))\n",
        "\n",
        "print(f\"üéâ ZIP creato: {ZIP_PATH}\")\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n"
      ],
      "metadata": {
        "id": "jItaC8KyNH9R",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, os, glob, zipfile, pandas as pd\n",
        "from pathlib import Path\n",
        "import re                                           # new\n",
        "\n",
        "ORDERED_DIR = \"/content/NUOVE_CSV/Ordered_radio\"#\"/content/CSV\"#\"/content/NUOVE_CSV_RADIO/Ordered_radio\"\n",
        "SCAN_DIR    = \"/content/jpg\"#\"/content/RADIO_SCAN\"#\"/content/scans/Radio\"\n",
        "PATCH_DIR   = \"/content/patches_Radio_carbon\"\n",
        "ZIP_PATH    = \"/content/patches_Radio_carbon.zip\"\n",
        "PATCH_SIZE = 512          # lato finale\n",
        "HS         = PATCH_SIZE//2\n",
        "\n",
        "\n",
        "os.makedirs(PATCH_DIR, exist_ok=True)\n",
        "if os.path.exists(ZIP_PATH):\n",
        "    os.remove(ZIP_PATH)\n",
        "\n",
        "global_idx = 1\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    # grab *all* CSVs and let the code figure out the stem\n",
        "    for csv_path in sorted(Path(ORDERED_DIR).glob(\"*.csv\")):\n",
        "        raw_stem = Path(csv_path).stem                 # e.g. Carbon Textile 1A_ordered_NEW\n",
        "        # strip known trailers (_fixed, _ordered_NEW, _uscita, etc.)\n",
        "        stem     = re.sub(r\"(_fixed|_ordered_NEW|_uscita.*)$\", \"\", raw_stem).rstrip(\"_\")\n",
        "        img_path = f\"{SCAN_DIR}/{stem}.jpg\"\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"‚ö†Ô∏è  Immagine mancante: {img_path} ‚Äî salto\")\n",
        "            continue\n",
        "        H_img, W_img = img.shape[:2]\n",
        "\n",
        "        df = (pd.read_csv(csv_path)\n",
        "                .sort_values(\"hole_idx\")               # ensure order\n",
        "                .reset_index(drop=True))\n",
        "\n",
        "        scan_outdir = f\"{PATCH_DIR}/{stem}\"\n",
        "        os.makedirs(scan_outdir, exist_ok=True)\n",
        "\n",
        "        for _, r in df.iterrows():\n",
        "            cx, cy = int((r.x1 + r.x2)//2), int((r.y1 + r.y2)//2)\n",
        "            x1, y1 = max(0, cx-HS), max(0, cy-HS)\n",
        "            x2, y2 = min(W_img, cx+HS), min(H_img, cy+HS)\n",
        "            #patch  = img[y1:y2, x1:x2]\n",
        "            patch  = img[y1:y2, x1:x2]\n",
        "            # pad out to exactly 700√ó700 if near an edge\n",
        "            h, w = patch.shape[:2]\n",
        "            h, w   = patch.shape[:2]\n",
        "            pad_bottom = max(0, PATCH_SIZE - h)\n",
        "            pad_right  = max(0, PATCH_SIZE - w)\n",
        "\n",
        "            # se non serve padding, copyMakeBorder √® superfluo ma non fa danni\n",
        "            patch = cv2.copyMakeBorder(\n",
        "                patch,\n",
        "                0, pad_bottom,          # top, bottom\n",
        "                0, pad_right,           # left, right\n",
        "                borderType=cv2.BORDER_CONSTANT,\n",
        "                value=0\n",
        "            )\n",
        "\n",
        "            fname = f\"H{global_idx:03d}_h{int(r.hole_idx):03d}_{stem}.jpg\"\n",
        "            fpath = f\"{scan_outdir}/{fname}\"\n",
        "            cv2.imwrite(fpath, patch)\n",
        "            zf.write(fpath, arcname=f\"{stem}/{fname}\")\n",
        "\n",
        "            global_idx += 1\n",
        "\n",
        "        print(f\"‚úî {stem}: {len(df)} patch(es))\")\n",
        "\n",
        "print(f\"üéâ  Ho creato {global_idx-1} patch e le ho zippate in {ZIP_PATH}\")\n"
      ],
      "metadata": {
        "id": "hXETearhRPfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['x1','y1','x2','y2']].describe()\n"
      ],
      "metadata": {
        "id": "eho2kp6xY2Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#parte Dedicata alle uscite, interesse per ingressi e RADIO"
      ],
      "metadata": {
        "id": "H8POSXxNJeLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SOLO USCITE / ORDINE AND CROP\n",
        "gruppo A ‚Üì‚Üë‚Üì‚Üë\n",
        "Le altre\n",
        "1A, 1B, 2A, 2B, 3B\n",
        "\n",
        "gruppo B da destra ‚Üë‚Üì‚Üë\n",
        "6 uscita\n",
        ",3A uscita"
      ],
      "metadata": {
        "id": "CuiPXyoT7teW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title gruppo B da destra ‚Üë‚Üì‚Üë\n",
        "import os, glob, cv2, pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> Config\n",
        "IN_DIR   = \"/content/\"\n",
        "OUT_DIR  = \"/content/NEWordered_csv_fixed\"\n",
        "GROUP_B  = {\n",
        "    \"T0_90_3A_uscita\",\n",
        "    \"T0_90_6_uscita\",\n",
        "}\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> Ordering function\n",
        "def order_holes(df, n_cols=None):\n",
        "    df = df.reset_index(drop=True)\n",
        "    xc = ((df.x1 + df.x2)/2).to_numpy().reshape(-1,1)\n",
        "    if n_cols is None:\n",
        "        step = (xc.max() - xc.min())/20\n",
        "        n_cols = len(np.unique((xc//step).astype(int)))\n",
        "    km   = KMeans(n_clusters=n_cols, n_init=10, random_state=42).fit(xc)\n",
        "    cols = np.argsort(km.cluster_centers_.ravel())\n",
        "    hole_idx, counter = {}, 1\n",
        "    for j, c in enumerate(cols):\n",
        "        idxs = np.where(km.labels_==c)[0]\n",
        "        idxs_sorted = sorted(\n",
        "            idxs,\n",
        "            key=lambda i: -((df.y1.iat[i]+df.y2.iat[i])/2)\n",
        "                          if j%2==0\n",
        "                          else  ((df.y1.iat[i]+df.y2.iat[i])/2)\n",
        "        )\n",
        "        for i in idxs_sorted:\n",
        "            hole_idx[i] = counter\n",
        "            counter += 1\n",
        "    df['hole_idx'] = df.index.map(hole_idx)\n",
        "    return df\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> Batch: trasforma e ordina\n",
        "for csv_path in sorted(glob.glob(f\"{IN_DIR}/*.csv\")):\n",
        "    base = Path(csv_path).stem.replace(\"_ordered\",\"\")\n",
        "    # salta quelli non uscita\n",
        "    if not base.endswith(\"_uscita\"):\n",
        "        continue\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    # applichi qui eventuale flip_x/rot180 se serve‚Ä¶\n",
        "    # df_tf = transform_boxes(df, action, W, H)\n",
        "    df_tf = df  # se gi√† OK\n",
        "\n",
        "    df_fixed = order_holes(df_tf)\n",
        "\n",
        "    # **Solo per Gruppo A**, inverti il count\n",
        "    if base in GROUP_A:\n",
        "        total = len(df_fixed)\n",
        "        df_fixed['hole_idx'] = (total + 1) - df_fixed['hole_idx']\n",
        "\n",
        "    out_csv = os.path.join(OUT_DIR, f\"{base}_fixed.csv\")\n",
        "    df_fixed.to_csv(out_csv, index=False)\n",
        "    print(f\"‚úÖ {base}: fixed saved ‚Üí {out_csv}\")\n",
        "\n",
        "print(\"üéâ Tutti i CSV di uscita sono stati ri‚Äêindicizzati correttamente.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kDMF64X3Bhft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell: correzione batch uscite con serpentine top-down per Gruppo A\n",
        "import os, glob, cv2, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Parametri ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "IN_DIR    = \"/content\"#\"/content\"              # CSV ordered ‚Äúsbagliati‚Äù\n",
        "OUT_DIR   = \"/content/ordered_csv_fixed2\"       # CSV fixed\n",
        "VIS_DIR   = \"/content/OVERLAY_USCITE_FIXED2\"    # overlay visivi\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(VIS_DIR, exist_ok=True)\n",
        "\n",
        "# i soli stem di scan uscite che vogliamo partire dall'alto\n",
        "GROUP_A = {\n",
        "    \"T0_90_1A_uscita\",\n",
        "    \"T0_90_1B_uscita\",\n",
        "    \"T0_90_2A_uscita\",\n",
        "    \"T0_90_2B_uscita\",\n",
        "    \"T0_90_3B_uscita\",\n",
        "}\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Funzione di ordinamento serpentine ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def order_holes(df, n_cols=None, start_from_top: bool = False):\n",
        "    df = df.reset_index(drop=True)\n",
        "    xc = ((df.x1 + df.x2)/2).to_numpy().reshape(-1,1)\n",
        "    if n_cols is None:\n",
        "        step = (xc.max()-xc.min())/20\n",
        "        n_cols = len(np.unique((xc//step).astype(int)))\n",
        "    km = KMeans(n_clusters=n_cols, n_init=10, random_state=42).fit(xc)\n",
        "    cols = np.argsort(km.cluster_centers_.ravel())\n",
        "    hole_idx = {}\n",
        "    counter = 1\n",
        "    for j, c in enumerate(cols):\n",
        "        idxs = np.where(km.labels_==c)[0]\n",
        "        if start_from_top:\n",
        "            # colonna pari: top‚Üíbottom ; dispari: bottom‚Üítop\n",
        "            idxs_sorted = sorted(\n",
        "                idxs,\n",
        "                key=lambda i: ((df.y1.iat[i]+df.y2.iat[i])/2)\n",
        "                              if (j%2==0)\n",
        "                              else -((df.y1.iat[i]+df.y2.iat[i])/2)\n",
        "            )\n",
        "        else:\n",
        "            # serpentine classico: pari: bottom‚Üítop ; dispari: top‚Üíbottom\n",
        "            idxs_sorted = sorted(\n",
        "                idxs,\n",
        "                key=lambda i: -((df.y1.iat[i]+df.y2.iat[i])/2)\n",
        "                              if (j%2==0)\n",
        "                              else  ((df.y1.iat[i]+df.y2.iat[i])/2)\n",
        "            )\n",
        "        for i in idxs_sorted:\n",
        "            hole_idx[i] = counter\n",
        "            counter += 1\n",
        "    df['hole_idx'] = df.index.map(hole_idx).astype(int)\n",
        "    return df\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Loop batch ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "for csv_path in sorted(glob.glob(f\"{IN_DIR}/*_uscita*.csv\")):\n",
        "    base = Path(csv_path).stem.replace(\"_ordered\",\"\")\n",
        "    df   = pd.read_csv(csv_path)\n",
        "\n",
        "    # decidi top‚Äêdown o bottom‚Äêup\n",
        "    start_top = base in GROUP_A\n",
        "\n",
        "    # riordina\n",
        "    df_fixed = order_holes(df, n_cols=None, start_from_top=start_top)\n",
        "\n",
        "    # salva CSV fixed\n",
        "    out_csv = os.path.join(OUT_DIR, f\"{base}_fixed.csv\")\n",
        "    df_fixed.to_csv(out_csv, index=False)\n",
        "\n",
        "    # overlay per sanity‚Äêcheck\n",
        "    img_path = f\"/content/drive/MyDrive/Scan_Orientate/{base}.jpg\"\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is not None:\n",
        "        vis = img.copy()\n",
        "        for _, r in df_fixed.iterrows():\n",
        "            x1,y1,x2,y2 = map(int,(r.x1,r.y1,r.x2,r.y2))\n",
        "            cv2.rectangle(vis,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "            cv2.putText(vis, str(r.hole_idx),(x1,y1-6),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1,cv2.LINE_AA)\n",
        "        cv2.imwrite(f\"{VIS_DIR}/{base}_vis.jpg\", vis)\n",
        "\n",
        "    print(f\"‚úÖ {base}: fixed.csv ‚Üí {out_csv}  \"\n",
        "          f\"({'top‚Üídown' if start_top else 'bottom‚Üíup'})\")\n",
        "\n",
        "print(\"üéâ Tutto fatto! Controlla:\", OUT_DIR, \"e\", VIS_DIR)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jNrVvPLEEXVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê  VISUAL CHECK BATCH -ottico-(uscite fixed)  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "import cv2, glob, os, pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab.patches import cv2_imshow   # solo in Colab\n",
        "\n",
        "CSV_DIR  = \"/content/ordered_csv_fixed2\"     # tutti i *_fixed.csv\n",
        "IMG_DIR  = \"/content/drive/MyDrive/Scan_Orientate\"  # scans .jpg\n",
        "OUT_DIR  = \"/content/overlay_batch\"         # salva gli overlay\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "for csv_path in sorted(Path(CSV_DIR).glob(\"*_fixed.csv\")):\n",
        "    stem = csv_path.stem.replace(\"_fixed\", \"\")     # es. T0_90_3B_uscita\n",
        "    img  = cv2.imread(f\"{IMG_DIR}/{stem}.jpg\")\n",
        "    if img is None:\n",
        "        print(\"‚ö†Ô∏è  immagine mancante:\", stem);  continue\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    for _, r in df.iterrows():\n",
        "        x1,y1,x2,y2 = map(int, (r.x1,r.y1,r.x2,r.y2))\n",
        "        idx = int(r.hole_idx)\n",
        "        cv2.rectangle(img, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "        cv2.putText(img, str(idx), (x1, y1-6),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                    (255,255,255), 1, cv2.LINE_AA)\n",
        "\n",
        "    out = f\"{OUT_DIR}/{stem}_vis.jpg\"\n",
        "    cv2.imwrite(out, img)\n",
        "    #cv2_imshow(img)     # mostra subito in Colab (facoltativo)\n",
        "    print(\"‚úî overlay:\", out)\n",
        "\n",
        "print(\"üéâ  Overlay creati per tutte le uscite fixed\")\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n"
      ],
      "metadata": {
        "id": "_Z43-qC_4NRu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title serve a  creare un zip completo CSV - overlay controllo(ottico-uscita) - evita di avviare in tempo reale gli overlay\n",
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê  Prepara ZIP di CSV & overlay ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "import os, glob, zipfile\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "CSV_DIR   = \"/content/ordered_csv_fixed2\"     # i tuoi *_fixed.csv\n",
        "VIS_DIR   = \"/content/overlay_batch\"         # gli overlay che hai appena generato\n",
        "ZIP_PATH  = \"/content/uscite_checksA.zip\"     # dove scrivere lo ZIP\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Rimuovi eventuale vecchio ZIP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "if os.path.exists(ZIP_PATH):\n",
        "    os.remove(ZIP_PATH)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Crea lo ZIP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "with zipfile.ZipFile(ZIP_PATH, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    # aggiungi CSV\n",
        "    for f in glob.glob(f\"{CSV_DIR}/*.csv\"):\n",
        "        zf.write(f, arcname=os.path.basename(f))\n",
        "    # aggiungi overlay\n",
        "    for f in glob.glob(f\"{VIS_DIR}/*_vis.jpg\"):\n",
        "        zf.write(f, arcname=os.path.join(\"overlays\", os.path.basename(f)))\n",
        "\n",
        "print(f\"üéâ ZIP creato: {ZIP_PATH}\")\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n"
      ],
      "metadata": {
        "id": "x3DMonhe_K_K",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2, os, glob, zipfile, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Parametri ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "ORDERED_DIR = \"/content/ordered_csv_fixed2\"        # tutti *_uscita_fixed.csv che hai gi√† sistemato\n",
        "SCAN_DIR    = \"/content/drive/MyDrive/Scan_Orientate\"\n",
        "PATCH_DIR   = \"/content/patches_uscite_all\"         # output dei crop\n",
        "ZIP_PATH    = \"/content/patches_uscite_all.zip\"\n",
        "HS          = 350                                   # mezzo lato del crop (700√ó700)\n",
        "\n",
        "# preparo cartelle\n",
        "os.makedirs(PATCH_DIR, exist_ok=True)\n",
        "if os.path.exists(ZIP_PATH):\n",
        "    os.remove(ZIP_PATH)\n",
        "\n",
        "global_idx = 1  # unico contatore globale\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    # prendo TUTTI i CSV di uscita (sia quelli ‚Äú_uscita_fixed.csv‚Äù sia eventuali varianti)\n",
        "    for csv_path in sorted(glob.glob(f\"{ORDERED_DIR}/*_uscita*_fixed.csv\")):\n",
        "        stem      = Path(csv_path).stem.replace(\"_fixed\",\"\")  # es. \"T0_90_1A_uscita\"\n",
        "        img_path  = f\"{SCAN_DIR}/{stem}.jpg\"\n",
        "        df        = pd.read_csv(csv_path)\n",
        "        img       = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"‚ö†Ô∏è Immagine mancante: {img_path}, salto\"); continue\n",
        "        H_img, W_img = img.shape[:2]\n",
        "\n",
        "        # assicuro che h (= hole_idx) parta da 1 e segua l‚Äôordine corretto\n",
        "        df = df.sort_values(\"hole_idx\")\n",
        "\n",
        "        # cartella di output per questa scan\n",
        "        scan_outdir = f\"{PATCH_DIR}/{stem}\"\n",
        "        os.makedirs(scan_outdir, exist_ok=True)\n",
        "        # ciclo sui fori\n",
        "        for _, r in df.iterrows():\n",
        "            cx, cy = int((r.x1 + r.x2)//2), int((r.y1 + r.y2)//2)\n",
        "            x1, y1 = max(0, cx-HS), max(0, cy-HS)\n",
        "            x2, y2 = min(W_img, cx+HS), min(H_img, cy+HS)\n",
        "            patch  = img[y1:y2, x1:x2]\n",
        "            h, w   = patch.shape[:2]\n",
        "            # padding fino a esatto 700√ó700\n",
        "            patch  = cv2.copyMakeBorder(patch, 0, 700-h, 0, 700-w,\n",
        "                                        cv2.BORDER_CONSTANT, 0)\n",
        "\n",
        "            # nome: H<globale>_h<locale>_<scan>.jpg\n",
        "            fname = f\"H{global_idx:03d}_h{int(r.hole_idx):03d}_{stem}.jpg\"\n",
        "            fpath = f\"{scan_outdir}/{fname}\"\n",
        "            cv2.imwrite(fpath, patch)\n",
        "            # aggiungo al ZIP mantenendo la sottocartella per scan\n",
        "            zf.write(fpath, arcname=f\"{stem}/{fname}\")\n",
        "\n",
        "            global_idx += 1\n",
        "\n",
        "print(f\"üéâ Ho creato {global_idx-1} patch e le ho zippate in {ZIP_PATH}\")\n"
      ],
      "metadata": {
        "id": "TXV54lYh_MJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89mU4w3OOnsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "amvXRvFVOnoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PARTE CHE FORSE POTREBBE ESSERE TOLTA ADESSO; teniamo per sicurezza futura, erano celle di test veloci"
      ],
      "metadata": {
        "id": "a8seQmTXLqUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title --- 0.  install / import once ----------------------------------------------\n",
        "#!pip install -qqU ultralytics                   # Colab: fetch latest build\n",
        "from ultralytics import YOLO\n",
        "import cv2, pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# --- 1.  load your weight ----------------------------------------------------\n",
        "MODEL = YOLO(\"/content/weights/best.pt\")   # <- path you used\n",
        "\n",
        "# --- 2.  choose ONE image ----------------------------------------------------\n",
        "IMG  = \"/content/scans/T0_90_1A_uscita.jpg\"                      # test file\n",
        "img = cv2.imread(IMG)\n",
        "H,W  = img.shape[:2] #\n",
        "# --- 3.  predict (no save_txt, no tricks: we only need the returned object) --\n",
        "res = MODEL.predict(IMG, imgsz=(H,W), conf=0.79, iou=0.80, verbose=False)[0]\n",
        "\n",
        "# res.boxes.xyxy is already **absolute pixel coords**  (x1,y1,x2,y2)\n",
        "boxes_xyxy = res.boxes.xyxy.cpu().numpy().astype(int)        # (N,4)\n",
        "scores      = res.boxes.conf.cpu().numpy()                   # (N,)\n",
        "print(f\"model returned {len(boxes_xyxy)} boxes   conf‚àà[{scores.min():.2f},{scores.max():.2f}]\")\n"
      ],
      "metadata": {
        "id": "ZQjqAdGxF0JQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title visual sanity that works on ordered amd shows orders of holes and indexes on one scan\n",
        "##VISUAL SANITY CHECK WORKS on one scan 4 here: works\n",
        "import cv2, pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab.patches import cv2_imshow   # solo in Colab\n",
        "\n",
        "# 1Ô∏è‚É£  scegli il CSV ordinato da visualizzare\n",
        "CSV_PATH = \"/content/ordered_csv_fixed/T0_90_3B_uscita_fixed.csv\"#\"/content/CSV_5/ORDINATE_CSV/T0_90_5_entrata_NEW_ordered_NEW.csv\"##\"/content/ORDINATE_CSV/T0_90_3B_ingresso_ordered_NEW.csv\"#\"/content/ordered_csv_NEW/T0_90_4_ingresso_ordered_NEW.csv\"#\"/content/T0_90_4_uscita_NEW_ordered.csv\" #\"/content/ordered_csv_NEW/T0_90_4_uscita_NEW_ordered.csv\"\n",
        "\n",
        "# 2Ô∏è‚É£  leggi il file ‚Üí DataFrame\n",
        "df = pd.read_csv(CSV_PATH)          # colonne: conf,x1,y1,x2,y2,hole_idx  (o simile)\n",
        "\n",
        "# 3Ô∏è‚É£  recupera il percorso dell‚Äôimmagine dalla stringa ‚Äúscan‚Äù contenuta nel nome file\n",
        "#     (p.es. T0_90_1A_uscita.jpg si trova in /content/scans/)\n",
        "img = cv2.imread(\"/content/drive/MyDrive/Scan_Orientate/T0_90_3B_uscita.jpg\")#\"/content/SCAN_5/T0_90_5_entrata_NEW.jpg\")#\"/content/scan_ruotate_da_inferire_ingressi/T0_90_3B_ingresso.jpg\")#\"/content/drive/MyDrive/Scan_Orientate/T0_90_4_ingresso.jpg\")#\"/content/drive/MyDrive/FileTesi/ScanzioneProviniUsura/T0_90_4_uscita_NEW.jpg\")\n",
        "\n",
        "#img = cv2.imread(IMG_PATH)\n",
        "assert img is not None, f\"Immagine non trovata: {IMG_PATH}\"\n",
        "\n",
        "# 4Ô∏è‚É£  disegna per ogni riga del DataFrame\n",
        "for _, r in df.iterrows():\n",
        "    x1, y1, x2, y2 = int(r.x1), int(r.y1), int(r.x2), int(r.y2)\n",
        "    idx            = int(r.hole_idx)\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    cv2.putText(img, str(idx),\n",
        "                (x1, y1 - 8),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                (255, 255, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "cv2_imshow(img)     # mostra in Colab\n"
      ],
      "metadata": {
        "id": "n7SDD_AQzIaI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title visual sanity that works on ordered amd shows orders of holes and indexes on one scan\n",
        "##VISUAL SANITY CHECK WORKS on one scan 4 here: works\n",
        "import cv2, pandas as pd\n",
        "from pathlib import Path\n",
        "from google.colab.patches import cv2_imshow   # solo in Colab\n",
        "\n",
        "# 1Ô∏è‚É£  scegli il CSV ordinato da visualizzare\n",
        "CSV_PATH = \"/content/ordered_csv_fixed/T0_90_3A_uscita_fixed.csv\"#\"/content/CSV_5/ORDINATE_CSV/T0_90_5_entrata_NEW_ordered_NEW.csv\"##\"/content/ORDINATE_CSV/T0_90_3B_ingresso_ordered_NEW.csv\"#\"/content/ordered_csv_NEW/T0_90_4_ingresso_ordered_NEW.csv\"#\"/content/T0_90_4_uscita_NEW_ordered.csv\" #\"/content/ordered_csv_NEW/T0_90_4_uscita_NEW_ordered.csv\"\n",
        "\n",
        "# 2Ô∏è‚É£  leggi il file ‚Üí DataFrame\n",
        "df = pd.read_csv(CSV_PATH)          # colonne: conf,x1,y1,x2,y2,hole_idx  (o simile)\n",
        "\n",
        "# 3Ô∏è‚É£  recupera il percorso dell‚Äôimmagine dalla stringa ‚Äúscan‚Äù contenuta nel nome file\n",
        "#     (p.es. T0_90_1A_uscita.jpg si trova in /content/scans/)\n",
        "img = cv2.imread(\"/content/drive/MyDrive/Scan_Orientate/T0_90_3A_uscita.jpg\")#\"/content/SCAN_5/T0_90_5_entrata_NEW.jpg\")#\"/content/scan_ruotate_da_inferire_ingressi/T0_90_3B_ingresso.jpg\")#\"/content/drive/MyDrive/Scan_Orientate/T0_90_4_ingresso.jpg\")#\"/content/drive/MyDrive/FileTesi/ScanzioneProviniUsura/T0_90_4_uscita_NEW.jpg\")\n",
        "\n",
        "#img = cv2.imread(IMG_PATH)\n",
        "assert img is not None, f\"Immagine non trovata: {IMG_PATH}\"\n",
        "\n",
        "# 4Ô∏è‚É£  disegna per ogni riga del DataFrame\n",
        "for _, r in df.iterrows():\n",
        "    x1, y1, x2, y2 = int(r.x1), int(r.y1), int(r.x2), int(r.y2)\n",
        "    idx            = int(r.hole_idx)\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    cv2.putText(img, str(idx),\n",
        "                (x1, y1 - 8),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                (255, 255, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "cv2_imshow(img)     # mostra in Colab"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2bgX3V5S4zZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7CHZJm54bhuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creazione del check visivo"
      ],
      "metadata": {
        "id": "4D4suTSMbn_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cell: evaluate serpentine ordering with quantitative adjacency metrics\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def check_serpentine(df_ordered):\n",
        "    # 1) compute centers\n",
        "    df = df_ordered.copy()\n",
        "    df['cx'] = (df.x1 + df.x2) / 2\n",
        "    df['cy'] = (df.y1 + df.y2) / 2\n",
        "\n",
        "    # 2) re-cluster into columns exactly as before\n",
        "    X = df['cx'].to_numpy().reshape(-1,1)\n",
        "    # auto n_cols\n",
        "    step = (X.max() - X.min()) / 20\n",
        "    n_cols = len(np.unique((X // step).astype(int)))\n",
        "    km = KMeans(n_clusters=n_cols, n_init=10, random_state=42).fit(X)\n",
        "    df['col'] = km.labels_\n",
        "\n",
        "    # 3) sort by hole_idx to walk the snake\n",
        "    df = df.sort_values('hole_idx').reset_index(drop=True)\n",
        "\n",
        "    # 4) for each i ‚Üí i+1, check adjacency rule\n",
        "    correct = []\n",
        "    for i in range(len(df)-1):\n",
        "        c0, c1 = df.loc[i,'col'], df.loc[i+1,'col']\n",
        "        y0, y1 = df.loc[i,'cy'],  df.loc[i+1,'cy']\n",
        "        x0, x1 = df.loc[i,'cx'],  df.loc[i+1,'cx']\n",
        "\n",
        "        if c0 == c1:\n",
        "            # within same column: even‚Äêindexed columns (0‚Äêbased) go bottom‚Üítop (y increases),\n",
        "            # odd‚Äêindexed go top‚Üíbottom (y decreases)\n",
        "            if (c0 % 2 == 0 and (y1 - y0) > 0) or (c0 % 2 == 1 and (y1 - y0) < 0):\n",
        "                correct.append(True)\n",
        "            else:\n",
        "                correct.append(False)\n",
        "        else:\n",
        "            # between columns must always move rightwards (x increases)\n",
        "            correct.append((x1 - x0) > 0)\n",
        "\n",
        "    # 5) return fraction correct + total steps\n",
        "    return np.mean(correct), len(correct)\n",
        "\n",
        "# 6) batch over all ordered CSVs\n",
        "RESULTS = []\n",
        "for path in sorted(glob.glob(\"/content/ordered_csv_NEW/*.csv\")):\n",
        "    df_ord = pd.read_csv(path)\n",
        "    frac, steps = check_serpentine(df_ord)\n",
        "    name = path.split(\"/\")[-1].replace(\"_ordered_NEW.csv\",\"\")\n",
        "    RESULTS.append((name, frac, steps))\n",
        "\n",
        "# assemble a quick table\n",
        "res_df = pd.DataFrame(RESULTS, columns=[\"scan\",\"frac_correct\",\"n_steps\"])\n",
        "print(res_df.to_markdown(index=False))\n",
        "\n",
        "# highlight any scans <100%:\n",
        "bad = res_df[res_df.frac_correct < 1.0]\n",
        "if not bad.empty:\n",
        "    print(\"\\n‚ö†Ô∏è These scans have mis-ordered adjacencies:\")\n",
        "    print(bad.to_markdown(index=False))\n",
        "else:\n",
        "    print(\"\\n‚úÖ All scans follow a perfect serpentine path!\")\n"
      ],
      "metadata": {
        "id": "5bgAt2YDi2cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##end here"
      ],
      "metadata": {
        "id": "uL4WU9iIbik3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_DIR  = \"/content/SCAN_5\"#\"/content/drive/MyDrive/Scan_Orientate\"#\"/content/scans\"\n",
        "CSV_DIR  = \"/content/CSV_5\"#\"/content/scansCSV_oriented\"\n",
        "os.makedirs(CSV_DIR, exist_ok=True)\n",
        "MODEL = YOLO(\"/content/PESI/best.pt\")#\"/content/weights/best.pt\")   # <- path you used\n",
        "\n",
        "for img_path in sorted(glob.glob(f\"{IMG_DIR}/*.jpg\")):\n",
        "    H,W = cv2.imread(img_path).shape[:2]\n",
        "    res = MODEL.predict(img_path, imgsz=(H,W), conf=0.79,\n",
        "                        iou=0.80,\n",
        "                        )[0]#verbose=False)[0]\n",
        "    if not len(res.boxes):\n",
        "        print(\"‚ö†Ô∏è  no boxes in\", img_path);  continue\n",
        "\n",
        "    df = pd.DataFrame(res.boxes.xyxy.cpu().numpy().astype(int),\n",
        "                      columns=[\"x1\",\"y1\",\"x2\",\"y2\"])\n",
        "    df.insert(0, \"conf\", res.boxes.conf.cpu().numpy())\n",
        "    stem = Path(img_path).stem\n",
        "    df.to_csv(f\"{CSV_DIR}/{stem}.csv\", index=False)\n",
        "    print(\"‚Ä¢\", stem, \"‚Üí CSV ok\")\n",
        "print(\"üéâ  all scans processed ‚Üí\", CSV_DIR)\n"
      ],
      "metadata": {
        "id": "5_F92-rWJd6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title -ONE TO USE- crops patchees NEW, avoid uscita 6 e odina sottocartelle scan\n",
        "##Skips every CSV whose name contains _6_uscita (until you fix its order). 1.\n",
        "\"\"\"patches_700/\n",
        "  ‚îú‚îÄ‚îÄ T0_90_4_ingresso/\n",
        "  ‚îÇ     ‚îú‚îÄ‚îÄ H257_h032_T0_90_4_ingresso.jpg\n",
        "  ‚îÇ     ‚îî‚îÄ‚îÄ ‚Ä¶\n",
        "  ‚îî‚îÄ‚îÄ T0_90_4_uscita/\n",
        "        ‚îî‚îÄ‚îÄ ‚Ä¶\n",
        "\"\"\"\n",
        "# Adds a dual index in the file-name: -- H<GLOBAL:03d>_h<SCANIDX:03d>_<scan_name>.jpg\n",
        "'''where GLOBAL is a running counter over all patches (so H000, H001 ‚Ä¶ H599) and SCANIDX is the per-scan hole_idx.'''\n",
        "# Cell ‚ñ∏ crop patches into per-scan sub-folders with dual index ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# crop patches into per-scan sub-folders ‚Äì with ordered rows\n",
        "#adattato per RADIO basta inserire in una folder diversi csv ordered e in una\n",
        "#METTERE DUE CARTELLE, se FILE SINGOLI SI BLOCCA, LAVORA SU GRUPPI DI FILE\n",
        "import cv2, os, glob, zipfile, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "ORDERED_DIR = \"/content/CSV\"#\"/content/CSV_5/ORDINATE_CSV\"#\"/content/ORDINATE_CSV\"#\"/content\"                                   # *_ordered*.csv\n",
        "SCAN_DIR    = \"/content/RADIO_SCAN\"#\"/content/SCAN_5\"#\"/content/scan_ruotate_da_inferire_ingressi\"#\"/content/drive/MyDrive/Scan_Orientate\"      # rotated scans\n",
        "PATCH_DIR   = \"/content/Radio/Carbon\"#\"/content/SCAN_5/PATCHES_5\"#\"/content/Patches_nuove\"#\"/content/patches_700_NEW\"\n",
        "ZIP_PATH    = \"/content/Patches_Radio_patches.zip\"#\"/content/Patches_nuove.zip\"#\"/content/patches_700_NEW.zip\"\n",
        "HS = 256#350                                                   # half-crop size\n",
        "\n",
        "os.makedirs(PATCH_DIR, exist_ok=True)\n",
        "if os.path.exists(ZIP_PATH):\n",
        "    os.remove(ZIP_PATH)\n",
        "\n",
        "global_idx = 1\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "    for csv_path in sorted(glob.glob(f\"{ORDERED_DIR}/*_ordered*.csv\")):\n",
        "        if \"_6_uscita\" in csv_path:        # still on hold\n",
        "            print(\"‚è©  skipping\", Path(csv_path).name)\n",
        "            continue\n",
        "\n",
        "        stem = Path(csv_path).stem\n",
        "        for suf in (\"_ordered_NEW\", \"_ordered\"):\n",
        "            if stem.endswith(suf):\n",
        "                stem = stem[:-len(suf)]\n",
        "                break\n",
        "        scan_name = stem\n",
        "\n",
        "        img_path = f\"{SCAN_DIR}/{scan_name}.jpg\"\n",
        "        img      = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"‚ö†Ô∏è  missing image {img_path}, skipping\"); continue\n",
        "        H, W = img.shape[:2]\n",
        "\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if \"manual_flag\" in df.columns:\n",
        "            df = df[df.manual_flag != 1]\n",
        "\n",
        "        df = df.sort_values(\"hole_idx\")    #  ‚Üê ensure 1,2,3‚Ä¶\n",
        "\n",
        "        scan_outdir = f\"{PATCH_DIR}/{scan_name}\"\n",
        "        os.makedirs(scan_outdir, exist_ok=True)\n",
        "\n",
        "        for _, r in df.iterrows():\n",
        "            cx = int((r.x1 + r.x2) // 2)\n",
        "            cy = int((r.y1 + r.y2) // 2)\n",
        "            x1, x2 = cx - HS, cx + HS\n",
        "            y1, y2 = cy - HS, cy + HS\n",
        "            x1, y1 = max(0, x1), max(0, y1)\n",
        "            x2, y2 = min(W, x2), min(H, y2)\n",
        "\n",
        "            patch = img[y1:y2, x1:x2]\n",
        "            h, w  = patch.shape[:2]\n",
        "            patch = cv2.copyMakeBorder(patch, 0, 700-h, 0, 700-w,\n",
        "                                       cv2.BORDER_CONSTANT, value=0)\n",
        "\n",
        "            fname = (f\"H{global_idx:03d}_\"\n",
        "                     f\"h{int(r.hole_idx):03d}_{scan_name}.jpg\")\n",
        "            fpath = f\"{scan_outdir}/{fname}\"\n",
        "            cv2.imwrite(fpath, patch)\n",
        "            zf.write(fpath, arcname=f\"{scan_name}/{fname}\")\n",
        "            global_idx += 1\n",
        "\n",
        "print(f\"üéâ  Cropped {global_idx-1} patches to {PATCH_DIR}  (ZIP: {ZIP_PATH})\")\n"
      ],
      "metadata": {
        "id": "WM3diIEni2oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ciKDol5u2pPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PER IL FUTURO CROP EASY DIRETTO"
      ],
      "metadata": {
        "id": "OSxpcWNwtL4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MODIFICA CODICE SOTTO PER RESIZE DELLE PATCH\n",
        "#CREAA I CROP DELLE RADIO EVITANDO DI INSERIRE FORI VICINI\n",
        "#Dobbiamo modificare il tuo script di cropping per renderlo \"intelligente\". Invece di tagliare una finestra di pixel fissa, deve **normalizzare la scala** di ogni patch in modo che il foro al centro abbia sempre la stessa dimensione in pixel.\n",
        "#\n",
        "#Ecco la logica:\n",
        "#1.  **Calcola la Dimensione del Foro:** Per ogni bounding box rilevata da YOLO, calcoliamo la sua dimensione media (es. `(larghezza + altezza) / 2`). Questo ci d√† il diametro del foro in pixel nella scansione originale.\n",
        "#2.  **Definisci una Scala Target:** Decidiamo quale dovrebbe essere la dimensione standard di un foro nelle nostre patch finali. Ad esempio, vogliamo che in una patch finale da 512x512, il foro abbia sempre un diametro di circa 280 pixel.\n",
        "#3.  **Calcola il Fattore di Scala:** Per ogni foro, confrontiamo la sua dimensione reale in pixel con la nostra dimensione target. Il rapporto `(dimensione_target / dimensione_reale)` ci d√† il fattore di scala da applicare.\n",
        "#4.  **Ritaglia e Ridimensiona:**\n",
        "#    *   Calcoliamo quanto grande deve essere l'area da ritagliare dall'immagine originale affinch√©, una volta ridimensionata con il nostro fattore di scala, diventi esattamente 512x512.\n",
        "#    *   Eseguiamo il ritaglio.\n",
        "#    *   Applichiamo il ridimensionamento (`cv2.resize`).\n",
        "#\n",
        "#Il risultato sar√† una cartella di patch dove ogni foro, indipendentemente dalla scansione di provenienza, apparir√† della stessa dimensione, pronto per essere processato dalla \"Mask Factory v5\"."
      ],
      "metadata": {
        "id": "TPM-cowpi2YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# --- IMPOSTAZIONI ---\n",
        "CSV_DIR     = \"/content/NUOVE_CSV/Ordered_radio\"#\"/content/csv\"\n",
        "SCAN_DIR    = \"/content/jpg\"\n",
        "PATCH_DIR   = \"/content/Radio_Patches_Normalized\" # Nuovo nome per chiarezza\n",
        "ZIP_PATH    = \"/content/Radio_Patches_Normalized.zip\"\n",
        "\n",
        "# --- NUOVE IMPOSTAZIONI PER LA NORMALIZZAZIONE DELLA SCALA ---\n",
        "# 1. Dimensione finale della patch in pixel.\n",
        "FINAL_PATCH_SIZE = 512\n",
        "\n",
        "# 2. Dimensione TARGET del diametro del foro all'interno della patch finale.\n",
        "#    Questo √® il parametro pi√π importante da sintonizzare. Un buon punto di partenza\n",
        "#    √® poco pi√π della met√† della dimensione della patch.\n",
        "#    Con questo valore, la \"Mask Factory v5\" dovr√† avere raggi di Hough intorno a 140-150.\n",
        "TARGET_HOLE_DIAMETER_PIXELS = 290\n",
        "\n",
        "# --- SCRIPT ---\n",
        "\n",
        "os.makedirs(PATCH_DIR, exist_ok=True)\n",
        "if os.path.exists(ZIP_PATH):\n",
        "    print(f\"Rimuovo ZIP precedente: {ZIP_PATH}\")\n",
        "    os.remove(ZIP_PATH)\n",
        "\n",
        "global_idx = 1\n",
        "print(\"üöÄ Inizio processo di cropping normalizzato...\")\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    csv_files = sorted(Path(CSV_DIR).glob(\"*.csv\"))\n",
        "    if not csv_files:\n",
        "        print(f\"üõë ERRORE: Nessun file .csv trovato in {CSV_DIR}. Controlla il percorso.\")\n",
        "\n",
        "    for csv_path in csv_files:\n",
        "        print(f\"\\nüìÑ Processo il file CSV: {csv_path.name}\")\n",
        "\n",
        "        raw_stem = csv_path.stem\n",
        "        stem = re.sub(r\"(_fixed|_ordered_NEW|_ordered)$\", \"\", raw_stem).rstrip(\"_\")\n",
        "        img_path = Path(SCAN_DIR) / f\"{stem}.jpg\"\n",
        "\n",
        "        if not img_path.exists():\n",
        "            print(f\"‚ö†Ô∏è  Immagine mancante per '{stem}': {img_path} ‚Äî Salto.\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(str(img_path))\n",
        "        H_img, W_img = img.shape[:2]\n",
        "        print(f\"üñºÔ∏è  Immagine '{img_path.name}' trovata e caricata ({W_img}x{H_img}).\")\n",
        "\n",
        "        df = pd.read_csv(csv_path)\n",
        "        # Assicurati che esista la colonna 'hole_idx', altrimenti ordina in base alla posizione y,x\n",
        "        if 'hole_idx' in df.columns:\n",
        "            df = df.sort_values(\"hole_idx\").reset_index(drop=True)\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Colonna 'hole_idx' non trovata. Ordinamento per y,x.\")\n",
        "            df = df.sort_values(['y1', 'x1']).reset_index(drop=True)\n",
        "            df['hole_idx'] = df.index + 1\n",
        "\n",
        "        scan_outdir = Path(PATCH_DIR) / stem\n",
        "        scan_outdir.mkdir(exist_ok=True)\n",
        "\n",
        "        for _, r in df.iterrows():\n",
        "            # --- INIZIO BLOCCO DI LOGICA PER LA NORMALIZZAZIONE ---\n",
        "\n",
        "            # 1. Calcola il centro e il diametro del foro rilevato in pixel\n",
        "            cx, cy = int((r.x1 + r.x2) / 2), int((r.y1 + r.y2) / 2)\n",
        "            w, h = r.x2 - r.x1, r.y2 - r.y1\n",
        "            detected_diameter = (w + h) / 2\n",
        "\n",
        "            if detected_diameter < 1: # Evita divisione per zero\n",
        "                continue\n",
        "\n",
        "            # 2. Calcola il fattore di scala necessario\n",
        "            scale_factor = TARGET_HOLE_DIAMETER_PIXELS / detected_diameter\n",
        "\n",
        "            # 3. Calcola la dimensione dell'area da ritagliare DALL'IMMAGINE ORIGINALE\n",
        "            #    Questa sar√† un'area pi√π grande o pi√π piccola di 512x512 a seconda dello scale_factor\n",
        "            crop_size_original_img = int(FINAL_PATCH_SIZE / scale_factor)\n",
        "\n",
        "            # Calcola le coordinate per questo crop pi√π grande\n",
        "            hs_original = crop_size_original_img // 2\n",
        "            x1, y1 = cx - hs_original, cy - hs_original\n",
        "            x2, y2 = cx + hs_original, cy + hs_original\n",
        "\n",
        "            # 4. Estrai la patch dall'immagine originale (con padding implicito se esce dai bordi)\n",
        "            #    np.pad gestisce i bordi in modo pulito, evitando errori\n",
        "            pad_left = abs(min(0, x1))\n",
        "            pad_top = abs(min(0, y1))\n",
        "            pad_right = abs(min(0, W_img - x2))\n",
        "            pad_bottom = abs(min(0, H_img - y2))\n",
        "\n",
        "            # Estrai la parte valida dell'immagine\n",
        "            patch_original = img[max(0, y1):min(H_img, y2), max(0, x1):min(W_img, x2)]\n",
        "\n",
        "            # Applica il padding se il crop usciva dai bordi\n",
        "            patch_padded = np.pad(\n",
        "                patch_original,\n",
        "                ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)),\n",
        "                mode='constant',\n",
        "                constant_values=0 # Bordo nero\n",
        "            )\n",
        "\n",
        "            # 5. Ridimensiona la patch estratta alla dimensione finale.\n",
        "            #    Questa operazione normalizza la scala!\n",
        "            patch_normalized = cv2.resize(\n",
        "                patch_padded,\n",
        "                (FINAL_PATCH_SIZE, FINAL_PATCH_SIZE),\n",
        "                interpolation=cv2.INTER_LANCZOS4 # Ottima qualit√† per il down/up-scaling\n",
        "            )\n",
        "\n",
        "            # --- FINE BLOCCO DI LOGICA PER LA NORMALIZZAZIONE ---\n",
        "\n",
        "            fname = f\"H{global_idx:03d}_h{int(r.hole_idx):03d}_{stem}.jpg\"\n",
        "            fpath = scan_outdir / fname\n",
        "            cv2.imwrite(str(fpath), patch_normalized)\n",
        "\n",
        "            zf.write(fpath, arcname=f\"{stem}/{fname}\")\n",
        "            global_idx += 1\n",
        "\n",
        "        print(f\"‚úî  Creati {len(df)} patch normalizzate per '{stem}'.\")\n",
        "\n",
        "print(f\"\\nüéâ  Processo completato! Create {global_idx-1} patch normalizzate in {PATCH_DIR} e zippate in {ZIP_PATH}\")"
      ],
      "metadata": {
        "id": "1Jhf9lH1fSl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Obiettivo: Convertire ogni patch 512x512 in una nuova patch in cui il foro da 6 mm abbia sempre la stessa dimensione in pixel. Questo crea una \"scala canonica\".\n",
        "<details>\n",
        "    Definire una Scala Canonica (Target):\n",
        "\n",
        "        Hai gi√† notato che i fori originali variano da ~120 a ~300 px. Scegliamo una dimensione target ragionevole, ad esempio TARGET_DIAMETER_PX = 280. Questo valore dovrebbe essere scelto per minimizzare l'upscaling (che pu√≤ creare artefatti) e il downscaling (che pu√≤ perdere dettagli del danno). La tua media di 297 px √® un'ottima candidata, ma per questo esempio uso 280.\n",
        "\n",
        "        La tua scala canonica (S_canon) sar√† S_canon = TARGET_DIAMETER_PX / 6.0 mm. Questa √® la costante px/mm che useremo per tutte le immagini dopo la normalizzazione.\n",
        "\n",
        "    Processare Ogni Immagine Individualmente (Ciclo for sui 592 fori):\n",
        "\n",
        "        (a) Misura il diametro del foro attuale: Per ogni patch, esegui la tua funzione (basata su cv2.HoughCircles o simile) per trovare il diametro in pixel del foro (current_diameter_px).\n",
        "\n",
        "        (b) Calcola il Fattore di Ridimensionamento: Calcola scale_factor = TARGET_DIAMETER_PX / current_diameter_px.\n",
        "\n",
        "            Se scale_factor > 1, ingrandirai l'immagine.\n",
        "\n",
        "            Se scale_factor < 1, la rimpicciolirai.\n",
        "\n",
        "        (c) Ridimensiona l'Immagine e la Maschera: Applica questo scale_factor sia all'immagine del patch sia, se la possiedi gi√†, alla sua maschera di segmentazione del danno. Usa cv2.resize. L'interpolazione cv2.INTER_AREA √® buona per rimpicciolire, mentre cv2.INTER_CUBIC o cv2.INTER_LINEAR √® migliore per ingrandire. Per le maschere, usa sempre cv2.INTER_NEAREST per non creare valori intermedi (es. 0.5).\n",
        "\n",
        "        (d) Estrai le Feature Geometriche: Solo ora, sull'immagine normalizzata, esegui il tuo algoritmo per calcolare l'area del danno (A_del_px), il diametro massimo (D_max_px), ecc.\n",
        "\n",
        "        (e) Converti le Feature in Unit√† Fisiche (mm): Usa la scala canonica che hai definito.\n",
        "\n",
        "            A_del [mm^2] = A_del_px / (S_canon)^2\n",
        "\n",
        "            D_MAX [mm] = D_max_px / S_canon\n",
        "            Questo √® il passaggio chiave che corregger√† l'errore fino a √ó70. L'errore nasceva perch√© dividevi un'area in pixel misurata a una scala per un fattore di scala calcolato su un'altra.\n",
        "\n",
        "    Salva i Risultati:\n",
        "\n",
        "        Salva le patch normalizzate in una nuova cartella. Saranno l'input per la tua UNet++.\n",
        "\n",
        "        Salva le feature calcolate (A_del [mm^2], D_MAX [mm], etc.) in un nuovo file CSV, pronte per la LSTM."
      ],
      "metadata": {
        "id": "SQA1elsfJFki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title check metrico delle scale e edeelle nuove patches\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "# --- CONFIGURAZIONE DELL'ANALISI ---\n",
        "\n",
        "# Percorso del file ZIP contenente le patch normalizzate\n",
        "ZIP_TO_ANALYZE = \"/content/Radio_Patches_Normalized.zip\"\n",
        "\n",
        "# Directory dove estrarre le patch per l'analisi\n",
        "PATCHES_DIR_ANALYSIS = \"/content/analysis_patches/\"\n",
        "\n",
        "# Il valore target che ci aspettiamo di trovare (per confronto)\n",
        "TARGET_DIAMETER = 290\n",
        "FINAL_PATCH_SIZE = 512\n",
        "\n",
        "print(\"üöÄ Inizio analisi qualitativa della normalizzazione...\")\n",
        "\n",
        "# --- 1. ESTRAZIONE DEI DATI ---\n",
        "if os.path.exists(PATCHES_DIR_ANALYSIS):\n",
        "    import shutil\n",
        "    shutil.rmtree(PATCHES_DIR_ANALYSIS) # Pulisce la directory se esiste gi√†\n",
        "\n",
        "with zipfile.ZipFile(ZIP_TO_ANALYZE, 'r') as zip_ref:\n",
        "    zip_ref.extractall(PATCHES_DIR_ANALYSIS)\n",
        "print(f\"‚úî Patch estratte in: {PATCHES_DIR_ANALYSIS}\")\n",
        "\n",
        "image_paths = glob.glob(os.path.join(PATCHES_DIR_ANALYSIS, \"**/*.jpg\"), recursive=True)\n",
        "print(f\"Trovate {len(image_paths)} patch da analizzare.\")\n",
        "\n",
        "# --- 2. MISURAZIONE AUTOMATICA ---\n",
        "measurements = []\n",
        "\n",
        "for img_path in image_paths:\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Un leggero blur aiuta HoughCircles a essere pi√π robusto\n",
        "    blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
        "\n",
        "    # HoughCircles per trovare il foro\n",
        "    # I parametri sono \"sintonizzati\" sulla nostra scala normalizzata\n",
        "    circles = cv2.HoughCircles(\n",
        "        blurred,\n",
        "        cv2.HOUGH_GRADIENT,\n",
        "        dp=1.2,             # Rapporto di risoluzione dell'accumulatore\n",
        "        minDist=FINAL_PATCH_SIZE, # Distanza minima tra i centri (ci aspettiamo un solo foro)\n",
        "        param1=50,          # Soglia superiore per Canny edge detector\n",
        "        param2=30,          # Soglia dell'accumulatore (pi√π basso = pi√π cerchi trovati)\n",
        "        minRadius=int(TARGET_DIAMETER / 2 * 0.8), # Raggio min: 80% del raggio target\n",
        "        maxRadius=int(TARGET_DIAMETER / 2 * 1.2)  # Raggio max: 120% del raggio target\n",
        "    )\n",
        "\n",
        "    if circles is not None:\n",
        "        # Arrotonda e prendi il primo (e unico) cerchio trovato\n",
        "        circles = np.round(circles[0, :]).astype(\"int\")\n",
        "        (x, y, r) = circles[0]\n",
        "        diameter = r * 2\n",
        "        measurements.append({'path': img_path, 'measured_diameter': diameter})\n",
        "\n",
        "print(f\"‚úî Misurati i diametri per {len(measurements)} patch.\")\n",
        "\n",
        "# --- 3. ANALISI STATISTICA CON PANDAS ---\n",
        "df_analysis = pd.DataFrame(measurements)\n",
        "\n",
        "print(\"\\nüìä Statistiche Descrittive dei Diametri Misurati:\")\n",
        "print(df_analysis['measured_diameter'].describe())\n",
        "\n",
        "# --- 4. VISUALIZZAZIONE CON MATPLOTLIB ---\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Istogramma\n",
        "ax.hist(df_analysis['measured_diameter'], bins=30, alpha=0.8, label='Distribuzione Diametri Misurati')\n",
        "ax.axvline(TARGET_DIAMETER, color='r', linestyle='--', linewidth=2, label=f'Target Diameter ({TARGET_DIAMETER}px)')\n",
        "ax.axvline(df_analysis['measured_diameter'].mean(), color='g', linestyle=':', linewidth=2, label=f'Media ({df_analysis[\"measured_diameter\"].mean():.2f}px)')\n",
        "\n",
        "ax.set_title(\"Distribuzione dei Diametri dei Fori nelle Patch Normalizzate\", fontsize=16)\n",
        "ax.set_xlabel(\"Diametro Misurato (pixel)\", fontsize=12)\n",
        "ax.set_ylabel(\"Numero di Patch\", fontsize=12)\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- 5. VERIFICA VISIVA (SPOT-CHECK) ---\n",
        "print(\"\\nüñºÔ∏è Esempi di verifica visiva (patch con cerchio rilevato e diametro):\")\n",
        "\n",
        "# Seleziona 9 campioni casuali\n",
        "sample_df = df_analysis.sample(min(9, len(df_analysis)))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i, row in enumerate(sample_df.itertuples()):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    img = cv2.imread(row.path)\n",
        "\n",
        "    # Trova i cerchi\n",
        "    circles = cv2.HoughCircles(cv2.GaussianBlur(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), (9, 9), 2), cv2.HOUGH_GRADIENT, 1.2, FINAL_PATCH_SIZE, 50, 30, int(TARGET_DIAMETER / 2 * 0.8), int(TARGET_DIAMETER / 2 * 1.2))\n",
        "\n",
        "    # --- BLOCCO CORRETTO E ROBUSTO ---\n",
        "    if circles is not None:\n",
        "        circles_squeezed = np.squeeze(circles)\n",
        "\n",
        "        if circles_squeezed.ndim == 1:\n",
        "            circle = circles_squeezed\n",
        "        else:\n",
        "            circle = circles_squeezed[0]\n",
        "\n",
        "        x, y, r = int(circle[0]), int(circle[1]), int(circle[2])\n",
        "\n",
        "        cv2.circle(img, (x, y), r, (0, 255, 0), 4) # Cerchio verde\n",
        "        cv2.circle(img, (x, y), 2, (0, 0, 255), 3) # Punto centrale rosso\n",
        "    # --- FINE BLOCCO ---\n",
        "\n",
        "    # Scrivi il diametro sull'immagine\n",
        "    diameter_text = f\"D: {row.measured_diameter}px\"\n",
        "    cv2.putText(img, diameter_text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 0), 3)\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Patch: ...{os.path.basename(row.path)[-20:]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0-vuvXy_qNPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check normalizzato vs non normalizzato gemini\n"
      ],
      "metadata": {
        "id": "KCrDvQT9OOlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Studio qualit√† e necessit√† della normalizzzazione di scala"
      ],
      "metadata": {
        "id": "5H8zoApmIMGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, os, glob, pandas as pd\n",
        "\n",
        "RAW_DIR  = \"/content/drive/MyDrive/Patches_test/Radio_Patches_Output\"\n",
        "NORM_DIR = \"/content/drive/MyDrive/Patches_test/Radio_Patches_Normalized\"\n",
        "\n",
        "def extract_ids(path: str):\n",
        "    \"\"\"\n",
        "    Restituisce (serie, Hidx<int>, hidx<int>)\n",
        "    compatibile con qualunque stringa tipo:\n",
        "      ‚Ä¢ H355_h001_Carbon Textile 5.jpg\n",
        "      ‚Ä¢ H487_h001_Scan5.jpg\n",
        "      ‚Ä¢ H210_h020_T_0_90_2A.jpg\n",
        "    \"\"\"\n",
        "    name = os.path.splitext(os.path.basename(path))[0]\n",
        "    m = re.match(r'H(\\d{3})_h(\\d{3})_(.*)', name)\n",
        "    if not m:\n",
        "        return None\n",
        "    Hidx, hidx, tail = m.groups()\n",
        "    # serie = prima cifra 1-6 dentro a tail (Scan5 ‚Üí 5, Carbon Textile 4 ‚Üí 4, ...)\n",
        "    m_ser = re.search(r'(\\d)', tail)\n",
        "    if not m_ser:\n",
        "        return None\n",
        "    serie = int(m_ser.group(1))\n",
        "    return serie, int(Hidx), int(hidx)\n",
        "\n",
        "def build_dict(root: str):\n",
        "    d = {}\n",
        "    for p in glob.glob(f\"{root}/**/*.jpg\", recursive=True):\n",
        "        key = extract_ids(p)\n",
        "        if key: d[key] = p\n",
        "    return d\n",
        "\n",
        "raw_paths  = build_dict(RAW_DIR)\n",
        "norm_paths = build_dict(NORM_DIR)\n",
        "print(f\"RAW: {len(raw_paths)}   NORM: {len(norm_paths)}  (chiavi uniche)\")\n"
      ],
      "metadata": {
        "id": "ibWoRlwQryIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# 1) calcola offset Hidx per ogni serie\n",
        "shift = {}\n",
        "for s in range(1,7):\n",
        "    H_raw  = min(k[1] for k in raw_paths  if k[0]==s) or None\n",
        "    H_norm = min(k[1] for k in norm_paths if k[0]==s) or None\n",
        "    if H_raw and H_norm:\n",
        "        shift[s] = H_raw - H_norm        # tip. 0 per CT1-3, -1 per Scan4-6\n",
        "print(\"Shift per serie:\", shift)\n",
        "\n",
        "# 2) ricostruisci dizionario NORM con Hidx compensato\n",
        "norm_shifted = {}\n",
        "for (s,H,h), path in norm_paths.items():\n",
        "    H_adj = H + shift.get(s,0)\n",
        "    norm_shifted[(s,H_adj,h)] = path\n",
        "\n",
        "# 3) accoppia\n",
        "pairs = {k: (raw_paths[k], norm_shifted[k])\n",
        "         for k in raw_paths.keys() & norm_shifted.keys()}\n",
        "\n",
        "print(f\"Patch accoppiate: {len(pairs)} / {len(raw_paths)} RAW  \"\n",
        "      f\"({len(raw_paths)-len(pairs)} non trovate)\")\n",
        "\n",
        "# opzionale: salva CSV con mappa\n",
        "pd.DataFrame(\n",
        "    [(s,H,h, raw, norm) for (s,H,h),(raw,norm) in pairs.items()],\n",
        "    columns=[\"serie\",\"Hidx\",\"hidx\",\"raw_path\",\"norm_path\"]\n",
        ").to_csv(\"/content/patch_match.csv\", index=False)\n",
        "\n",
        "print(\"CSV di accoppiamento scritto in /content/patch_match.csv\")\n"
      ],
      "metadata": {
        "id": "tIwz93CEvV0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, cv2, matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "def hough_diam(path, kind):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None: return np.nan\n",
        "    img = cv2.GaussianBlur(img, (9, 9), 2)\n",
        "    minR, maxR = ((50, 200) if kind=='raw' else (110, 190))\n",
        "    cir = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1.2,\n",
        "                           minDist=img.shape[0], param1=50, param2=30,\n",
        "                           minRadius=minR, maxRadius=maxR)\n",
        "    return cir[0,0,2]*2 if cir is not None else np.nan\n",
        "\n",
        "# ---- misura tutti i diametri (‚âà6‚Äì7 s sui 600 patch) ----\n",
        "rows = []\n",
        "for (serie,H,h), (raw_p, norm_p) in pairs.items():\n",
        "    d_raw  = hough_diam(raw_p,  'raw')\n",
        "    d_norm = hough_diam(norm_p, 'norm')\n",
        "    rows.append((serie, H, h, d_raw, d_norm))\n",
        "\n",
        "df = pd.DataFrame(rows, columns=['serie','H','h','px_raw','px_norm']).dropna()\n",
        "print(f\"{len(df)} coppie con cerchio rilevato\")      # dovrebbe restarne >590\n"
      ],
      "metadata": {
        "id": "bIv69Pv0wpv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, cv2, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "RAW_DIR  = \"/content/drive/MyDrive/Patches_test/Radio_Patches_Output\"\n",
        "NORM_DIR = \"/content/drive/MyDrive/Patches_test/Radio_Patches_Normalized\"\n",
        "TARGET_PX = 290          # diametro obiettivo dopo normalizzazione\n",
        "\n",
        "def hough_px(path, is_raw):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None: return np.nan\n",
        "    img = cv2.GaussianBlur(img, (9,9), 2)\n",
        "    minR, maxR = ((50,200) if is_raw else (110,190))\n",
        "    cir = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1.2,\n",
        "                           minDist=img.shape[0], param1=50, param2=30,\n",
        "                           minRadius=minR, maxRadius=maxR)\n",
        "    return cir[0,0,2]*2 if cir is not None else np.nan\n",
        "\n",
        "# misura diametri\n",
        "raw_px  = np.array([hough_px(p, True)\n",
        "                    for p in glob.glob(f\"{RAW_DIR}/**/*.jpg\", recursive=True)])\n",
        "norm_px = np.array([hough_px(p, False)\n",
        "                    for p in glob.glob(f\"{NORM_DIR}/**/*.jpg\", recursive=True)])\n",
        "\n",
        "raw_px  = raw_px[~np.isnan(raw_px)]\n",
        "norm_px = norm_px[~np.isnan(norm_px)]\n",
        "\n",
        "print(f\"diametri letti: RAW={len(raw_px)}   NORM={len(norm_px)}\")\n",
        "\n",
        "# scatter\n",
        "fig, ax = plt.subplots(1,2, figsize=(12,6))\n",
        "\n",
        "for i,(data,title,color) in enumerate([\n",
        "        (raw_px , \"PRIMA della normalizzazione\", 'steelblue'),\n",
        "        (norm_px, \"DOPO la normalizzazione\"   , 'darkgreen')]):\n",
        "\n",
        "    # ascissa fissa (ma con jitter leggero per separare punti)\n",
        "    jitter = np.random.uniform(-3, 3, len(data))\n",
        "    ax[i].scatter(np.full_like(data, TARGET_PX)+jitter,\n",
        "                  data, alpha=.6, color=color, s=22)\n",
        "\n",
        "    # retta di riferimento\n",
        "    ax[i].plot([TARGET_PX-10, TARGET_PX+10],\n",
        "               [TARGET_PX-10, TARGET_PX+10], 'k--', lw=1.5)\n",
        "\n",
        "    ax[i].set(title=title,\n",
        "              xlabel='Diametro nominale (290 px)',\n",
        "              ylabel='Diametro misurato (px)',\n",
        "              xlim=(TARGET_PX-15, TARGET_PX+15),\n",
        "              ylim=(data.min()-20, data.max()+20))\n",
        "\n",
        "plt.suptitle(\"Confronto distribuzioni diametro foro ‚Äì prima / dopo\", fontsize=16)\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "IpqJTNdRyzod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title istogrammi affiancati a diaetri, mostra effetti normalizzazione su varianza\n",
        "#come si vede i grupppi di fori sono divisi in due gruppi Raw e dopo diventano uno (verde vs blu)\n",
        "\n",
        "bins = np.linspace(100, 350, 40)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.hist(raw_px , bins=bins, alpha=.6, label='RAW',  color='tab:blue')\n",
        "plt.hist(norm_px, bins=bins, alpha=.6, label='NORM', color='tab:green')\n",
        "plt.axvline(NOMINAL_D_PX, ls='--', color='k', lw=1.5, label='Nominale 290 px')\n",
        "plt.xlabel('Diametro foro (px)'); plt.ylabel('Conteggio')\n",
        "plt.title('Istogramma diametri foro'); plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "PeSrWeDn3EWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title A nuvola diagonale statistica con x variabile per vedere bene #Ordini entrambe le liste: ¬´il pi√π piccolo di prima ‚Üî il pi√π piccolo di dopo¬ª; ¬´il 2¬∞ pi√π piccolo ‚Üî il 2¬∞ pi√π piccolo¬ª ‚Ä¶ L‚Äôeffetto visivo √® comunque una nuvola diagonale, perch√© in media i diametri piccoli restano piccoli e i grandi restano grandi ‚Äì ma Y si addensa attorno a ~290 px.\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "# --- assumo che tu abbia gi√† raw_px e norm_px ---\n",
        "# se no ricalcola i diametri con la tua funzione hough_diam_px\n",
        "\n",
        "def make_cloud(data, ax, title, jitter=4, color='tab:blue'):\n",
        "    rng = np.random.default_rng(0)\n",
        "    N   = len(data)\n",
        "    x   = np.sort(data) + rng.uniform(-jitter, jitter, N)\n",
        "    y   = np.sort(data)                     # stesso ordine ‚Üí diagonale\n",
        "    ax.scatter(x, y, alpha=.6, s=22, edgecolors='none', color=color)\n",
        "    lim = y.max()*1.05\n",
        "    ax.plot([0, lim], [0, lim], 'r--', lw=1.4)\n",
        "    ax.set(title=title, xlim=(0, lim), ylim=(0, lim),\n",
        "           xlabel='Diametro (px) ‚Äì asse X jitterato',\n",
        "           ylabel='Diametro (px) ‚Äì asse Y', aspect='equal')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "make_cloud(raw_px , axes[0], 'RAW (pre-normalizzazione)',  jitter=5, color='tab:blue')\n",
        "make_cloud(norm_px, axes[1], 'NORM (post-normalizzazione)', jitter=2, color='tab:green')\n",
        "\n",
        "plt.suptitle('Confronto nuvole diagonali ‚Äì metodo statistico', fontsize=15)\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "YpuslZ0p8f0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title colonne con jitter accentuato\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "nominal_px = 290          # riferimento ideale\n",
        "\n",
        "def jittered_column(data, color, label, jitter=20):\n",
        "    x = nominal_px + np.random.uniform(-jitter, jitter, len(data))\n",
        "    plt.scatter(x, data, alpha=.6, s=22, color=color, label=label)\n",
        "\n",
        "plt.figure(figsize=(6,7))\n",
        "jittered_column(raw_px , 'tab:blue' , 'PRIMA',  25)\n",
        "jittered_column(norm_px, 'tab:green', 'DOPO',    6)\n",
        "plt.axhline(nominal_px, ls='--', color='k', lw=1.2)\n",
        "plt.xlabel('Diametro nominale (pixel) ¬± jitter')\n",
        "plt.ylabel('Diametro misurato (px)')\n",
        "plt.title('Colonne ‚Äúlarghe‚Äù ‚Äì effetto restringimento')\n",
        "plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "zwr9lcfq8t2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "graico a violino"
      ],
      "metadata": {
        "id": "KI1UyYiUBnc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, cv2, numpy as np, pandas as pd\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "RAW_DIR  = \"/content/drive/MyDrive/Patches_test/Radio_Patches_Output\"\n",
        "NORM_DIR = \"/content/drive/MyDrive/Patches_test/Radio_Patches_Normalized\"\n",
        "\n",
        "def hough_px(path, is_raw):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None: return np.nan\n",
        "    img = cv2.GaussianBlur(img, (9,9), 2)\n",
        "    minR, maxR = ((50,200) if is_raw else (110,190))\n",
        "    c = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1.2,\n",
        "                         minDist=img.shape[0], param1=50, param2=30,\n",
        "                         minRadius=minR, maxRadius=maxR)\n",
        "    return c[0,0,2]*2 if c is not None else np.nan\n",
        "\n",
        "def extract_ids(path):                 # stesso helper di prima\n",
        "    import re, os\n",
        "    name = os.path.splitext(os.path.basename(path))[0]\n",
        "    m = re.match(r'H\\d{3}_h\\d{3}_(.*)', name)\n",
        "    if not m: return None\n",
        "    tail = m.group(1)\n",
        "    m_ser = re.search(r'(\\d)', tail)\n",
        "    return int(m_ser.group(1)) if m_ser else None\n",
        "\n",
        "# ---------- misura e costruisci DataFrame unico ----------\n",
        "rows = []\n",
        "for folder, label, is_raw in [(RAW_DIR,'RAW',True), (NORM_DIR,'NORM',False)]:\n",
        "    for p in glob.glob(f\"{folder}/**/*.jpg\", recursive=True):\n",
        "        serie = extract_ids(p)\n",
        "        d_px  = hough_px(p, is_raw)\n",
        "        if not np.isnan(d_px) and serie:          # scarta subito i NaN\n",
        "            rows.append((serie, d_px, label))\n",
        "\n",
        "df_all = pd.DataFrame(rows, columns=['serie','diam_px','stato'])\n",
        "print(df_all.groupby('stato').size())\n"
      ],
      "metadata": {
        "id": "HzYZfYgzBIOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(11,5))\n",
        "sns.violinplot(data=df_all, x='serie', y='diam_px',\n",
        "               hue='stato', split=True, inner='quart',\n",
        "               palette={'RAW':'#1f77b4', 'NORM':'#2ca02c'})\n",
        "plt.axhline(290, ls='--', color='k', lw=1.2)\n",
        "plt.title('Violin-plot diametri per serie (RAW vs NORM)')\n",
        "plt.xlabel('Serie provino'); plt.ylabel('Diametro (px)')\n",
        "plt.legend(title=''); plt.show()\n"
      ],
      "metadata": {
        "id": "C2o6Bp91BMgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jit_raw, jit_norm = 25, 6\n",
        "rng = np.random.default_rng(0)\n",
        "nom_px = 290\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(12,6))\n",
        "for i, (lab, jitter, col) in enumerate([('RAW',jit_raw,'tab:blue'),\n",
        "                                        ('NORM',jit_norm,'tab:green')]):\n",
        "    subset = df_all[df_all['stato']==lab]['diam_px'].to_numpy()\n",
        "    x = nom_px + rng.uniform(-jitter, jitter, len(subset))\n",
        "    ax[i].scatter(x, subset, alpha=.6, color=col, s=20, edgecolors='none')\n",
        "    ax[i].set(title=f'{lab} ‚Äì jitter {jitter}px',\n",
        "              xlabel='X = nominale ¬± jitter', ylabel='Diametro (px)')\n",
        "    ax[i].axhline(nom_px, ls='--', color='k', lw=1.2)\n",
        "plt.suptitle('Distribuzione diametri prima / dopo con jitter', fontsize=15)\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "mDMCIqr_BQLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fase 1: Accoppiamento dei File (il nostro prerequisito)\n",
        "Useremo la logica robusta che abbiamo definito prima per creare la nostra lista di coppie di file.\n",
        "\n",
        "Fase 2: Misurazione dei Diametri\n",
        "Scriveremo una funzione che prende il percorso di un'immagine, la analizza con OpenCV e restituisce il diametro del foro in pixel. Useremo una tecnica standard e molto affidabile chiamata \"Trasformata Circolare di Hough\".\n",
        "\n",
        "Fase 3: Raccolta Dati e Plotting\n",
        "Applicheremo la funzione di misurazione a ogni file di ogni coppia, raccoglieremo i risultati in una tabella e infine useremo questa tabella per creare il nostro grafico \"nuvola diagonale\" (che in realt√† sar√† un grafico di correlazione)."
      ],
      "metadata": {
        "id": "eh5Yvx9CWEiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CODICE GEMINI solo accoppiamento dei file FASE 1\n",
        "import os\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "import re\n",
        "# --- Fase 1: Definire le costanti e le corrispondenze ---\n",
        "\n",
        "PATCH_RAW_DIR  = '/content/drive/MyDrive/Patches_test/Radio_Patches_Output'\n",
        "PATCH_NORM_DIR = '/content/drive/MyDrive/Patches_test/Radio_Patches_Normalized'\n",
        "\n",
        "# Definiamo le corrispondenze tra i nomi delle sottocartelle\n",
        "# La chiave √® il nome nella cartella RAW, il valore √® il nome nella cartella NORMALIZED\n",
        "# NOTA: Adapta questa mappa se i nomi per le prime scan sono diversi\n",
        "FOLDER_MAP = {\n",
        "    \"Carbon Textile 1A\": \"Carbon Textile 1A\", # Esempio, da verificare\n",
        "    \"Carbon Textile 1B\": \"Carbon Textile 1B\",\n",
        "    \"Carbon Textile 2A\": \"Carbon Textile 2A\",\n",
        "    \"Carbon Textile 2B\": \"Carbon Textile 2B\", # Esempio, da verificare\n",
        "    \"Carbon Textile 3A\": \"Carbon Textile 3A\",\n",
        "    \"Carbon Textile 3B\": \"Carbon Textile 3B\", # Esempio, da verificare\n",
        "    \"Carbon Textile 4\": \"Scan4\",\n",
        "    \"Carbon Textile 5\": \"Scan5\",\n",
        "    \"Carbon Textile 6\": \"Scan6\",\n",
        "}\n",
        "\n",
        "# --- Fase 2: Logica di accoppiamento ---\n",
        "\n",
        "matched_pairs = []\n",
        "unmatched_raw = []\n",
        "unmatched_norm = defaultdict(list)\n",
        "\n",
        "# Iteriamo sulla mappa delle cartelle che vogliamo accoppiare\n",
        "for raw_folder_name, norm_folder_name in FOLDER_MAP.items():\n",
        "\n",
        "    raw_subdir = os.path.join(PATCH_RAW_DIR, raw_folder_name)\n",
        "    norm_subdir = os.path.join(PATCH_NORM_DIR, norm_folder_name)\n",
        "\n",
        "    print(f\"\\n--- Processando coppia: '{raw_folder_name}' <--> '{norm_folder_name}' ---\")\n",
        "\n",
        "    # Controlliamo che le cartelle esistano per evitare errori\n",
        "    if not os.path.isdir(raw_subdir):\n",
        "        print(f\"ATTENZIONE: La cartella RAW non esiste: {raw_subdir}\")\n",
        "        continue\n",
        "    if not os.path.isdir(norm_subdir):\n",
        "        print(f\"ATTENZIONE: La cartella NORMALIZED non esiste: {norm_subdir}\")\n",
        "        continue\n",
        "\n",
        "    # Recuperiamo la lista dei file jpg, ORDINATA ALFABETICAMENTE.\n",
        "    # L'ordinamento √® fondamentale.\n",
        "    raw_files = sorted(glob.glob(os.path.join(raw_subdir, '*.jpg')))\n",
        "    norm_files = sorted(glob.glob(os.path.join(norm_subdir, '*.jpg')))\n",
        "\n",
        "    print(f\"Trovati {len(raw_files)} file in RAW e {len(norm_files)} in NORMALIZED.\")\n",
        "\n",
        "    # Adesso la parte cruciale. Usiamo un dizionario per rendere il matching robusto\n",
        "    # La chiave sar√† la parte del nome che DEVE essere uguale (es: h001, h002 etc)\n",
        "\n",
        "    def get_h_key(filepath):\n",
        "        # Estrae qualcosa tipo \"h001\" da \"H488_h001_Carbon Textile 5.jpg\"\n",
        "        match = re.search(r'_h(\\d{3})_', os.path.basename(filepath))\n",
        "        return match.group(1) if match else None\n",
        "\n",
        "    raw_dict = {get_h_key(p): p for p in raw_files if get_h_key(p)}\n",
        "    norm_dict = {get_h_key(p): p for p in norm_files if get_h_key(p)}\n",
        "\n",
        "    # Troviamo le chiavi in comune\n",
        "    common_keys = set(raw_dict.keys()) & set(norm_dict.keys())\n",
        "    print(f\"Accoppiati {len(common_keys)} file basati sulla chiave _hXXX_.\")\n",
        "\n",
        "    for key in sorted(list(common_keys)):\n",
        "        matched_pairs.append((raw_dict[key], norm_dict[key]))\n",
        "\n",
        "# --- Fase 3: Risultati ---\n",
        "print(\"\\n==============================================\")\n",
        "print(f\"TOTALE PATCH ACCOPPIATE: {len(matched_pairs)}\")\n",
        "print(\"==============================================\")\n",
        "\n",
        "# Stampiamo i primi 5 accoppiamenti per verifica\n",
        "print(\"\\nEsempi di accoppiamenti riusciti:\")\n",
        "for i, (raw_p, norm_p) in enumerate(matched_pairs[:5]):\n",
        "    print(f\"Coppia {i+1}:\")\n",
        "    print(f\"  RAW:  {os.path.basename(raw_p)}\")\n",
        "    print(f\"  NORM: {os.path.basename(norm_p)}\")\n",
        "\n",
        "# Stampiamo l'ultimo accoppiamento trovato per vedere i file problematici\n",
        "if matched_pairs:\n",
        "    print(\"\\nUltimo accoppiamento:\")\n",
        "    print(f\"  RAW:  {os.path.basename(matched_pairs[-1][0])}\")\n",
        "    print(f\"  NORM: {os.path.basename(matched_pairs[-1][1])}\")"
      ],
      "metadata": {
        "id": "67H_1zQBDFl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fase 2\n",
        "# ==============================================================================\n",
        "# FASE 2: FUNZIONE DI MISURAZIONE DEL DIAMETRO\n",
        "# ==============================================================================\n",
        "\n",
        "def measure_hole_diameter(image_path: str) -> float | None:\n",
        "    \"\"\"\n",
        "    Carica un'immagine, trova il cerchio pi√π prominente e restituisce il suo diametro in pixel.\n",
        "    Restituisce None se non trova nessun cerchio.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Carica l'immagine in scala di grigi\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            return None\n",
        "\n",
        "        # Applica una sfocatura per ridurre il rumore e migliorare il rilevamento\n",
        "        img_blur = cv2.medianBlur(img, 5)\n",
        "\n",
        "        # Applica la trasformata di Hough per trovare i cerchi\n",
        "        # Questi parametri potrebbero richiedere un po' di tuning\n",
        "        circles = cv2.HoughCircles(\n",
        "            img_blur,\n",
        "            cv2.HOUGH_GRADIENT,\n",
        "            dp=1.2,              # Risoluzione inversa dell'accumulatore\n",
        "            minDist=400,       # Distanza minima tra i centri dei cerchi rilevati (essendocene solo 1, mettiamo un valore alto)\n",
        "            param1=60,         # Valore di soglia superiore per l'algoritmo di Canny\n",
        "            param2=35,         # Soglia per il centro del cerchio\n",
        "            minRadius=30,      # Raggio minimo del cerchio (per evitare falsi positivi)\n",
        "            maxRadius=210      # Raggio massimo (il foro normalizzato √® ~150px di raggio)\n",
        "        )\n",
        "\n",
        "        if circles is not None:\n",
        "            # Arrotonda le coordinate e il raggio all'intero pi√π vicino\n",
        "            circles = np.uint16(np.around(circles))\n",
        "            # Prendiamo solo il primo cerchio trovato (dovrebbe essercene solo uno)\n",
        "            best_circle = circles[0, 0]\n",
        "            # Il raggio √® la terza componente\n",
        "            radius = best_circle[2]\n",
        "            return float(radius * 2) # Ritorna il DIAMETRO\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Errore durante l'analisi di {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "M2nNgMvPEbdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# OBIETTIVO FINALE: GRAFICO A NUVOLA PRE vs POST NORMALIZZAZIONE\n",
        "# ==============================================================================\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Prerequisito: Assicuriamoci che la variabile 'matched_pairs' esista e contenga le 596 coppie.\n",
        "# (Esegui prima la Fase 1 di accoppiamento se non l'hai gi√† fatto)\n",
        "if 'matched_pairs' not in locals() or len(matched_pairs) < 580:\n",
        "    raise ValueError(\"Esegui prima la cella di accoppiamento! 'matched_pairs' non √® pronto.\")\n",
        "\n",
        "\n",
        "def measure_hole_diameter_final(image_path: str) -> float | None:\n",
        "    \"\"\"\n",
        "    Funzione di misura OTTIMIZZATA. Sa distinguere tra file raw e normalizzati\n",
        "    e adatta i parametri di conseguenza.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None: return None\n",
        "\n",
        "        img_blur = cv2.medianBlur(img, 5)\n",
        "\n",
        "        # --- PARAMETRI INTELLIGENTI ---\n",
        "        # Impostiamo parametri di default\n",
        "        hough_param2 = 28  # Soglia di confidenza abbassata per essere pi√π permissivi\n",
        "\n",
        "        # Adattiamo i raggi in base al tipo di file\n",
        "        is_normalized = \"Normalized\" in image_path or \"Scan\" in image_path\n",
        "        if is_normalized:\n",
        "            # Per i file normalizzati, i diametri sono molto consistenti\n",
        "            min_r, max_r = 135, 175 # Range stretto attorno a un diametro di ~300px\n",
        "        else:\n",
        "            # Per i file raw, i diametri variano molto\n",
        "            min_r, max_r = 50, 160  # Range ampio da ~100px a ~320px di diametro\n",
        "        # --- FINE PARAMETRI INTELLIGENTI ---\n",
        "\n",
        "        circles = cv2.HoughCircles(\n",
        "            img_blur, cv2.HOUGH_GRADIENT, dp=1.2, minDist=400,\n",
        "            param1=60, param2=hough_param2,\n",
        "            minRadius=min_r, maxRadius=max_r\n",
        "        )\n",
        "\n",
        "        if circles is not None:\n",
        "            # Ritorna il diametro del primo (e unico) cerchio trovato\n",
        "            return float(np.around(circles[0, 0, 2]) * 2)\n",
        "\n",
        "    except Exception:\n",
        "        return None\n",
        "    return None\n",
        "\n",
        "# --- Misurazione su tutte le coppie ---\n",
        "results = []\n",
        "for raw_path, norm_path in tqdm(matched_pairs, desc=\"Misurazione diametri\"):\n",
        "    raw_diameter = measure_hole_diameter_final(raw_path)\n",
        "    norm_diameter = measure_hole_diameter_final(norm_path)\n",
        "\n",
        "    if raw_diameter is not None and norm_diameter is not None:\n",
        "        results.append({\n",
        "            'raw_diameter_px': raw_diameter,\n",
        "            'norm_diameter_px': norm_diameter,\n",
        "        })\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(f\"\\nMisurazione completata. Trovati diametri per {len(df_results)} coppie su {len(matched_pairs)} totali.\")\n",
        "\n",
        "# --- Creazione del GRAFICO FINALE ---\n",
        "if df_results.empty:\n",
        "    print(\"\\nERRORE: Nessun diametro √® stato misurato. Impossibile creare il grafico.\")\n",
        "    print(\"Consiglio: riesegui la cella di debug e affina i parametri in 'measure_hole_diameter_final'.\")\n",
        "else:\n",
        "    print(\"\\nDati pronti per il grafico. Ecco un'anteprima:\")\n",
        "    print(df_results.describe())\n",
        "\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, ax = plt.subplots(figsize=(11, 11))\n",
        "\n",
        "    # Il grafico a nuvola che volevamo\n",
        "    sns.scatterplot(\n",
        "        data=df_results,\n",
        "        x='raw_diameter_px',      # ASSE X: Diametri originali, disordinati\n",
        "        y='norm_diameter_px',     # ASSE Y: Diametri normalizzati, consistenti\n",
        "        alpha=0.6,\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    # Ora la \"nuvola\" si svilupper√† orizzontalmente invece che verticalmente.\n",
        "    # Evidenziamo la media dei valori normalizzati con una linea ORIZZONTALE\n",
        "    mean_norm = df_results['norm_diameter_px'].mean()\n",
        "    ax.axhline(mean_norm, color='red', linestyle='--', linewidth=2, label=f'Media Normalizzata ({mean_norm:.1f} px)')\n",
        "\n",
        "    ax.set_title('Effetto della Normalizzazione sui Diametri Misurati', fontsize=18, weight='bold')\n",
        "    ax.set_xlabel('Diametro Foro Originale [pixel]', fontsize=14)\n",
        "    ax.set_ylabel('Diametro Foro Normalizzato [pixel]', fontsize=14)\n",
        "    ax.legend(loc='upper left')\n",
        "\n",
        "    # Forza gli assi ad essere uguali per apprezzare la compressione dei valori\n",
        "    ax.axis('equal')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MHGpMLZdEbZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==============================================================================\n",
        "# BLOCCO DI DEBUG INTERATTIVO PER measure_hole_diameter\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Seleziona UNA coppia di immagini di test dalla tua lista di accoppiamenti\n",
        "# Prendi una coppia a met√† lista, che √® pi√π rappresentativa\n",
        "test_raw_path, test_norm_path = matched_pairs[300] # O un altro indice a tua scelta\n",
        "\n",
        "print(f\"File di test RAW: {os.path.basename(test_raw_path)}\")\n",
        "print(f\"File di test NORM: {os.path.basename(test_norm_path)}\")\n",
        "\n",
        "def debug_hole_measurement(image_path: str):\n",
        "    \"\"\"\n",
        "    Questa funzione non solo misura, ma mostra anche le immagini intermedie\n",
        "    per capire perch√© l'algoritmo fallisce o ha successo.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Analizzando: {os.path.basename(image_path)} ---\")\n",
        "\n",
        "    # Carica l'immagine a colori per poter disegnare in rosso\n",
        "    img_color = cv2.imread(image_path)\n",
        "    if img_color is None:\n",
        "        print(\"Errore: Impossibile caricare l'immagine.\")\n",
        "        return\n",
        "\n",
        "    # Converti in scala di grigi per l'elaborazione\n",
        "    img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Applica una sfocatura per ridurre il rumore\n",
        "    img_blur = cv2.medianBlur(img_gray, 5)\n",
        "\n",
        "    # --- INIZIO TUNING PARAMETRI ---\n",
        "    # Questi sono i \"pomelli\" su cui dobbiamo lavorare.\n",
        "    # Prova a cambiare un valore alla volta.\n",
        "    hough_dp = 1.2\n",
        "    hough_param1 = 60  # Aumentalo se hai molti bordi spuri (es. 100), diminuiscilo se non trova il bordo principale.\n",
        "    hough_param2 = 35  # Diminuiscilo se non trova nessun cerchio (es. 25 o 20). √à la \"confidenza\" richiesta.\n",
        "    hough_min_radius = 40  # Imposta un raggio minimo realistico per le immagini RAW\n",
        "    hough_max_radius = 200 # Imposta un raggio massimo realistico per le immagini RAW\n",
        "\n",
        "    # Se stiamo analizzando un'immagine normalizzata, i raggi sono pi√π consistenti\n",
        "    if \"Normalized\" in image_path:\n",
        "        hough_min_radius = 130 # I fori normalizzati sono circa 280-330 px di diametro\n",
        "        hough_max_radius = 170\n",
        "    # --- FINE TUNING PARAMETRI ---\n",
        "\n",
        "    print(f\"Parametri Hough: dp={hough_dp}, param1={hough_param1}, param2={hough_param2}, minR={hough_min_radius}, maxR={hough_max_radius}\")\n",
        "\n",
        "    # Applica la trasformata di Hough\n",
        "    circles = cv2.HoughCircles(\n",
        "        img_blur,\n",
        "        cv2.HOUGH_GRADIENT,\n",
        "        dp=hough_dp,\n",
        "        minDist=400,\n",
        "        param1=hough_param1,\n",
        "        param2=hough_param2,\n",
        "        minRadius=hough_min_radius,\n",
        "        maxRadius=hough_max_radius\n",
        "    )\n",
        "\n",
        "    # Disegna i risultati per vederli\n",
        "    if circles is not None:\n",
        "        print(f\"TROVATI {len(circles[0])} CERCHI!\")\n",
        "        circles = np.uint16(np.around(circles))\n",
        "        for i in circles[0, :]:\n",
        "            # Disegna la circonferenza esterna del cerchio\n",
        "            cv2.circle(img_color, (i[0], i[1]), i[2], (0, 0, 255), 2)  # Rosso\n",
        "            # Disegna il centro del cerchio\n",
        "            cv2.circle(img_color, (i[0], i[1]), 2, (0, 255, 0), 3)   # Verde\n",
        "\n",
        "            diameter = i[2] * 2\n",
        "            print(f\"  - Centro (x,y): ({i[0]},{i[1]}), Diametro: {diameter} px\")\n",
        "    else:\n",
        "        print(\"NESSUN CERCHIO TROVATO con questi parametri.\")\n",
        "\n",
        "    # Mostra l'immagine originale e quella con i cerchi trovati\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
        "    axes[0].set_title('Immagine Originale')\n",
        "    axes[1].imshow(cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB))\n",
        "    axes[1].set_title('Risultato Rilevamento Cerchi')\n",
        "    plt.show()\n",
        "\n",
        "# --- ESEGUIAMO IL DEBUG ---\n",
        "debug_hole_measurement(test_raw_path)\n",
        "debug_hole_measurement(test_norm_path)"
      ],
      "metadata": {
        "id": "vxsQmbpFkN1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
